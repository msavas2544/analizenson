import sys
import os
import cv2
import numpy as np
import math
import subprocess
import shutil
import configparser
import gc
from datetime import datetime

# PyQt5 import'larÄ±
from PyQt5.QtCore import QThread, pyqtSignal, pyqtSlot, Qt, QTimer, QRect, QTime, QUrl
from PyQt5.QtGui import QPainter, QColor, QImage, QPixmap, QTextCursor, QPen, QKeySequence, QFont
from PyQt5.QtWidgets import (QWidget, QMainWindow, QVBoxLayout, QHBoxLayout, 
                             QPushButton, QLabel, QFileDialog, QProgressBar, 
                             QStyle, QFrame, QApplication, QRadioButton, 
                             QButtonGroup, QTextEdit, QGroupBox, QMessageBox, QAbstractButton,
                             QListWidget, QListWidgetItem, QShortcut, QDialog, QCheckBox, 
                             QGridLayout, QScrollArea, QTableWidget, QTableWidgetItem, 
                             QHeaderView, QSplitter, QComboBox, QSpinBox, QSlider, QTabWidget)

# GÃ¼venli import'lar
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("PyTorch bulunamadÄ± - CPU modu kullanÄ±lacak")

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("Ultralytics bulunamadÄ± - lÃ¼tfen 'pip install ultralytics' Ã§alÄ±ÅŸtÄ±rÄ±n")

try:
    import xlsxwriter
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False
    print("Excel desteÄŸi yok - 'pip install xlsxwriter' Ã§alÄ±ÅŸtÄ±rÄ±n")

try:
    import matplotlib
    matplotlib.use('Agg')  # GUI gerektirmeyen backend
    import matplotlib.pyplot as plt
    import numpy as np
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("Grafik desteÄŸi yok - 'pip install matplotlib numpy' Ã§alÄ±ÅŸtÄ±rÄ±n")

try:
    from docx import Document
    from docx.shared import Inches, Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.enum.style import WD_STYLE_TYPE
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("Word desteÄŸi yok - 'pip install python-docx' Ã§alÄ±ÅŸtÄ±rÄ±n")

# YENÄ°: PDF rapor desteÄŸi
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib import colors
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("PDF desteÄŸi yok - 'pip install reportlab' Ã§alÄ±ÅŸtÄ±rÄ±n")

# =============================================================================
# --- UYGULAMA YAPILANDIRMASI VE AYARLAR ---
# =============================================================================

# =============================================================================
# --- YAPILANDIRMA YÃ–NETÄ°CÄ°SÄ° ---
# =============================================================================

class ConfigManager:
    """Config.ini dosyasÄ±nÄ± yÃ¶neten sÄ±nÄ±f"""
    
    def __init__(self, config_path='config.ini'):
        self.config_path = config_path
        self.config = configparser.ConfigParser()
        self.load_config()
    
    def load_config(self):
        """YapÄ±landÄ±rma dosyasÄ±nÄ± yÃ¼kler"""
        try:
            if os.path.exists(self.config_path):
                self.config.read(self.config_path, encoding='utf-8')
            else:
                self.create_default_config()
        except Exception as e:
            print(f"Config yÃ¼kleme hatasÄ±: {e}")
            self.create_default_config()
    
    def create_default_config(self):
        """VarsayÄ±lan yapÄ±landÄ±rma dosyasÄ± oluÅŸturur"""
        self.config['DEFAULT'] = {
            'app_name': 'M.SAVAÅ Video Analiz Sistemi',
            'version': '1.1.0',
            'author': 'M.SAVAÅ'
        }
        
        self.config['VIDEO'] = {
            'supported_formats': 'mp4,avi,mov,mkv,wmv,flv,webm,dav,h264,264,ts,m2ts,mts',
            'max_file_size_mb': '2000',
            'default_fps': '30',
            'security_camera_formats': 'ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8',
            'smart_detection_channels': 'true'
        }
        
        self.config['ANALYSIS'] = {
            'default_sensitivity': 'ULTRA MAX',
            'confidence_threshold': '0.5',
            'iou_threshold': '0.5',
            'max_detections_per_frame': '10'
        }
        
        self.save_config()
    
    def save_config(self):
        """YapÄ±landÄ±rmayÄ± dosyaya kaydeder"""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                self.config.write(f)
        except Exception as e:
            print(f"Config kaydetme hatasÄ±: {e}")
    
    def get_supported_formats(self):
        """Desteklenen video formatlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r"""
        return self.config['VIDEO']['supported_formats'].split(',')
    
    def get_confidence_threshold(self):
        """GÃ¼ven eÅŸiÄŸini dÃ¶ndÃ¼rÃ¼r"""
        return float(self.config['ANALYSIS']['confidence_threshold'])
    
    def get_default_sensitivity(self):
        """VarsayÄ±lan hassasiyet seviyesini dÃ¶ndÃ¼rÃ¼r"""
        return self.config['ANALYSIS']['default_sensitivity']
    
    def get_max_file_size(self):
        """Maksimum dosya boyutunu MB olarak dÃ¶ndÃ¼rÃ¼r"""
        return int(self.config['VIDEO']['max_file_size_mb'])
    
    def is_security_camera_file(self, file_path: str) -> bool:
        """GÃ¼venlik kamerasÄ± dosyasÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
        filename = os.path.basename(file_path).lower()
        
        # Kanal iÅŸaretlerini kontrol et
        security_patterns = [
            '_ch1_', '_ch2_', '_ch3_', '_ch4_', '_ch5_', '_ch6_', '_ch7_', '_ch8_',
            'channel', 'cam01', 'cam02', 'cam03', 'cam04', 'dvr', 'nvr'
        ]
        
        return any(pattern in filename for pattern in security_patterns)
    
    def get_security_camera_settings(self):
        """GÃ¼venlik kamerasÄ± iÃ§in optimize edilmiÅŸ ayarlarÄ± dÃ¶ndÃ¼rÃ¼r"""
        return {
            'enhanced_motion_detection': True,
            'low_light_optimization': True,
            'fixed_camera_mode': True,
            'continuous_monitoring': True,
            'event_merge_gap': 2.0,  # GÃ¼venlik kameralarÄ± iÃ§in daha uzun birleÅŸtirme
            'minimum_event_duration': 3.0  # En az 3 saniye olay
        }

# Global config manager instance
config_manager = ConfigManager()

# =============================================================================
# --- Ã–ZEL HATA SINIFLARI ---
# =============================================================================

class VideoAnalysisError(Exception):
    """Video analizi genel hata sÄ±nÄ±fÄ±"""
    pass

class FileFormatError(VideoAnalysisError):
    """Dosya formatÄ± hatasÄ±"""
    pass

class ModelLoadError(VideoAnalysisError):
    """Model yÃ¼kleme hatasÄ±"""
    pass

class VideoLoadError(VideoAnalysisError):
    """Video yÃ¼kleme hatasÄ±"""
    pass

class GPUError(VideoAnalysisError):
    """GPU kullanÄ±m hatasÄ±"""
    pass

# Performans ve doÄŸruluk iÃ§in analiz edilecek karelerin geniÅŸliÄŸi
ANALYSIS_FRAME_WIDTH = 320  # 416'dan 320'ye dÃ¼ÅŸÃ¼rdÃ¼k - %50 daha hÄ±zlÄ±

# Ultra performanslÄ± analiz iÃ§in ek ayarlar
PERFORMANCE_SETTINGS = {
    "batch_size": 8,           # Batch processing iÃ§in
    "max_det": 50,             # Maksimum tespit sayÄ±sÄ±
    "iou_threshold": 0.5,      # IoU eÅŸiÄŸi
    "agnostic_nms": True,      # SÄ±nÄ±f baÄŸÄ±msÄ±z NMS
    "half_precision": True,    # FP16 kullan
    "dynamic_skip": True,      # Dinamik kare atlama
    "smart_crop": True,        # AkÄ±llÄ± kÄ±rpma
    "motion_based_roi": True   # Hareket bazlÄ± ROI
}

# Hassasiyet seviyeleri ve karÅŸÄ±lÄ±k gelen eÅŸik deÄŸerleri
SENSITIVITY_LEVELS = {
    "ğŸš€ Ultra HÄ±zlÄ±": {
        "motion": 45,           # Sadece bÃ¼yÃ¼k hareketler
        "conf": 0.3,            # YÃ¼ksek gÃ¼ven - sadece net tespitler
        "frame_skip": 8,        # Her 9. kareyi analiz et (hÄ±zlÄ±)
        "min_area_ratio": 0.005,   # BÃ¼yÃ¼k nesneler (insan boyutu+)
        "roi_expand": 0.9,      # ROI daraltma
        "temporal_smooth": 1,   # Minimal yumuÅŸatma
        "description": "HÄ±zlÄ± tarama - sadece bÃ¼yÃ¼k hareketler"
    },
    "âš¡ HÄ±zlÄ±": {
        "motion": 35,           # Orta-bÃ¼yÃ¼k hareketler
        "conf": 0.2,            # Orta-yÃ¼ksek gÃ¼ven eÅŸiÄŸi
        "frame_skip": 4,        # Her 5. kareyi analiz et
        "min_area_ratio": 0.002,   # Orta boy nesneler
        "roi_expand": 1.0,      # Normal ROI
        "temporal_smooth": 1,   # Az yumuÅŸatma
        "description": "HÄ±zlÄ± analiz - orta boy nesneler"
    },
    "ğŸ¯ Normal": {
        "motion": 25,           # Dengeli hassasiyet
        "conf": 0.1,            # Dengeli gÃ¼ven eÅŸiÄŸi
        "frame_skip": 2,        # Her 3. kareyi analiz et
        "min_area_ratio": 0.0008,  # Ä°nsan odaklÄ± boyut
        "roi_expand": 1.1,      # Hafif ROI geniÅŸletme
        "temporal_smooth": 2,   # Normal yumuÅŸatma
        "description": "Dengeli analiz - insan odaklÄ±"
    },
    "ğŸ” DetaylÄ±": {
        "motion": 15,           # Hassas tespit
        "conf": 0.05,           # DÃ¼ÅŸÃ¼k gÃ¼ven eÅŸiÄŸi
        "frame_skip": 1,        # Her 2. kareyi analiz et
        "min_area_ratio": 0.0002,  # KÃ¼Ã§Ã¼k detaylar
        "roi_expand": 1.25,     # ROI geniÅŸletme
        "temporal_smooth": 3,   # Ä°yi yumuÅŸatma
        "description": "Hassas analiz - ince detaylar"
    },
    "ğŸ”¬ Ultra DetaylÄ±": {
        "motion": 8,            # Mikroskobik hareketler
        "conf": 0.02,           # En dÃ¼ÅŸÃ¼k gÃ¼ven eÅŸiÄŸi
        "frame_skip": 0,        # Her kareyi analiz et
        "min_area_ratio": 0.00005, # En kÃ¼Ã§Ã¼k hareketler
        "roi_expand": 1.5,      # Maksimum ROI geniÅŸletme
        "temporal_smooth": 4,   # Maksimum yumuÅŸatma
        "description": "Maksimum hassasiyet - en kÃ¼Ã§Ã¼k detaylar"
    },
    "ğŸ¢ GÃ¼venlik KamerasÄ±": {
        "motion": 20,           # GÃ¼venlik optimumu
        "conf": 0.08,           # GÃ¼venlik odaklÄ± gÃ¼ven
        "frame_skip": 1,        # GÃ¼venlik iÃ§in sÄ±k analiz
        "min_area_ratio": 0.001,   # Ä°nsan boyutu odaklÄ±
        "roi_expand": 1.2,      # GÃ¼venlik ROI
        "temporal_smooth": 2,   # GÃ¼rÃ¼ltÃ¼ azaltma
        "description": "GÃ¼venlik kamerasÄ± optimizasyonu",
        "low_light_mode": True, # DÃ¼ÅŸÃ¼k Ä±ÅŸÄ±k optimizasyonu
        "fixed_camera": True,   # Sabit kamera modu
        "continuous_mode": True # SÃ¼rekli izleme modu
    }
}

# VarsayÄ±lan ayarlar
DEFAULT_SENSITIVITY = "ğŸ¯ Normal"  # Dengeli analiz - insan odaklÄ±

# YENÄ°: Ã‡oklu nesne tespiti - YOLO sÄ±nÄ±flarÄ±
TARGET_CLASSES = {
    'person': 0,        # Ä°nsan (varsayÄ±lan)
    'bicycle': 1,       # Bisiklet  
    'car': 2,           # Araba
    'motorbike': 3,     # Motosiklet
    'bus': 5,           # OtobÃ¼s
    'truck': 7,         # Kamyon
    'cat': 15,          # Kedi
    'dog': 16,          # KÃ¶pek
    'horse': 17,        # At
    'bird': 14,         # KuÅŸ
    'backpack': 24,     # SÄ±rt Ã§antasÄ±
    'suitcase': 28,     # Valiz
    'sports ball': 32,  # Spor topu
    'bottle': 39,       # ÅiÅŸe
    'wine glass': 40,   # Åarap kadehi
    'cup': 41,          # Fincan
    'knife': 43,        # BÄ±Ã§ak
    'cell phone': 67,   # Cep telefonu
    'laptop': 63,       # Laptop
    'mouse': 64,        # Fare
    'remote': 65,       # Kumanda
    'keyboard': 66,     # Klavye
    'book': 73,         # Kitap
    'clock': 74,        # Saat
    'scissors': 76,     # Makas
    'toothbrush': 79    # DiÅŸ fÄ±rÃ§asÄ±
}

# Aktif tespit sÄ±nÄ±flarÄ± (varsayÄ±lan sadece insan)
ACTIVE_CLASSES = [0]  # BaÅŸlangÄ±Ã§ta sadece person

EVENT_MERGE_GAP_SECONDS = 1.5  # Daha hÄ±zlÄ± birleÅŸtirme
EXPORT_BUFFER_SECONDS = 0.5  # Daha kÄ±sa buffer
TEMP_CLIP_DIR = "msavas_temp_clips"

# Ã‡oklu iÅŸlem ayarlarÄ±
MULTIPROCESSING_ENABLED = True
MAX_WORKERS = 4  # Paralel iÅŸlem sayÄ±sÄ±


# =============================================================================
# --- GEREKLÄ° KÃœTÃœPHANE KONTROLÃœ ---
# =============================================================================
# --- PERFORMANS VE BELLEK YÃ–NETÄ°MÄ° ---
# =============================================================================

def detect_gpu_capability():
    """GPU varlÄ±ÄŸÄ±nÄ± ve kapasitesini kontrol eder"""
    try:
        if TORCH_AVAILABLE and torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
            gpu_name = torch.cuda.get_device_name(0)
            return {
                'available': True, 
                'count': gpu_count, 
                'memory_gb': gpu_memory,
                'name': gpu_name
            }
    except Exception as e:
        print(f"GPU kontrol hatasÄ±: {e}")
    
    return {'available': False}

def cleanup_memory():
    """Bellek temizleme fonksiyonu"""
    gc.collect()
    
    try:
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
    except Exception as e:
        print(f"GPU bellek temizleme hatasÄ±: {e}")

def optimize_batch_size(video_resolution):
    """Video Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ne gÃ¶re batch size optimizasyonu"""
    if not video_resolution or len(video_resolution) < 2:
        return 8  # VarsayÄ±lan
    
    total_pixels = video_resolution[0] * video_resolution[1]
    
    if total_pixels > 1920 * 1080:  # 4K+
        return 4
    elif total_pixels > 1280 * 720:  # HD
        return 8
    else:  # SD
        return 16

# =============================================================================
# --- BAÄIMLILIK KONTROLÃœ ---
# =============================================================================
def check_dependencies():
    """Gerekli kÃ¼tÃ¼phaneleri ve FFmpeg'i kontrol eder."""
    print("ğŸ” BaÄŸÄ±mlÄ±lÄ±klar kontrol ediliyor...")
    missing = []
    warnings = []
    
    # Temel kÃ¼tÃ¼phaneler
    try:
        import cv2
        print(f"âœ… OpenCV: {cv2.__version__}")
    except ImportError:
        missing.append("opencv-python")
        print("âŒ OpenCV eksik")
    
    # PyQt5 zaten import edilmiÅŸ, kontrol etmeye gerek yok
    print("âœ… PyQt5 yÃ¼klÃ¼")
    
    try:
        import numpy as np
        print(f"âœ… NumPy: {np.__version__}")
    except ImportError:
        missing.append("numpy")
        print("âŒ NumPy eksik")
    
    # Ä°steÄŸe baÄŸlÄ± kÃ¼tÃ¼phaneler
    if not ULTRALYTICS_AVAILABLE:
        warnings.append("ultralytics (YOLO desteÄŸi iÃ§in)")
        print("âš ï¸ Ultralytics eksik - temel tespit kullanÄ±lacak")
    else:
        print("âœ… Ultralytics yÃ¼klÃ¼")
    
    if not EXCEL_AVAILABLE:
        warnings.append("openpyxl (Excel raporu iÃ§in)")
        print("âš ï¸ OpenPyXL eksik - Excel raporu kullanÄ±lamaz")
    else:
        print("âœ… OpenPyXL yÃ¼klÃ¼")
    
    if not MATPLOTLIB_AVAILABLE:
        warnings.append("matplotlib (grafik raporu iÃ§in)")
        print("âš ï¸ Matplotlib eksik - grafik raporu kullanÄ±lamaz")
    else:
        print("âœ… Matplotlib yÃ¼klÃ¼")
    
    if not DOCX_AVAILABLE:
        warnings.append("python-docx (Word raporu iÃ§in)")
        print("âš ï¸ Python-docx eksik - Word raporu kullanÄ±lamaz")
    else:
        print("âœ… Python-docx yÃ¼klÃ¼")
    
    if not MATPLOTLIB_AVAILABLE:
        warnings.append("matplotlib (grafik raporu iÃ§in)")
        print("âš ï¸ Matplotlib eksik - grafik raporu kullanÄ±lamaz")
    else:
        print("âœ… Matplotlib yÃ¼klÃ¼")
    
    # FFmpeg kontrolÃ¼
    try:
        _ = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, check=True, 
                      creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)
        print("âœ… FFmpeg yÃ¼klÃ¼")
    except (FileNotFoundError, subprocess.CalledProcessError):
        warnings.append("ffmpeg (video iÅŸleme iÃ§in)")
        print("âš ï¸ FFmpeg eksik - video dÄ±ÅŸa aktarma sÄ±nÄ±rlÄ±")
    
    if missing:
        error_message = (
            f"âŒ Kritik eksiklikler: {', '.join(missing)}\n\n"
            "Bu kÃ¼tÃ¼phaneler olmadan uygulama Ã§alÄ±ÅŸmaz:\n"
            "pip install opencv-python PyQt5 numpy\n\n"
            "UygulamayÄ± baÅŸlatmak iÃ§in Ã¶nce bu kÃ¼tÃ¼phaneleri yÃ¼kleyin."
        )
        print(error_message)
        return False
    
    if warnings:
        print(f"\nğŸ’¡ Ä°steÄŸe baÄŸlÄ± eksiklikler: {len(warnings)} adet")
        print("Bu Ã¶zellikler kullanÄ±lamayacak ama uygulama Ã§alÄ±ÅŸacak:")
        for warning in warnings:
            print(f"  â€¢ {warning}")
        print("\nEksik kÃ¼tÃ¼phaneleri yÃ¼klemek iÃ§in:")
        print("pip install ultralytics openpyxl matplotlib python-docx Pillow")
    
    print("\nğŸš€ Temel gereksinimler karÅŸÄ±landÄ± - uygulama baÅŸlatÄ±labilir!")
    return True
    
    return True

# =============================================================================
# --- GPU VE PERFORMANS AYARLARI ---
# =============================================================================

def get_optimal_device():
    """En iyi cihazÄ± seÃ§er (GPU varsa GPU, yoksa CPU)."""
    try:
        if TORCH_AVAILABLE and torch.cuda.is_available():
            return 'cuda'
        else:
            return 'cpu'
    except Exception:
        return 'cpu'

def optimize_yolo_model(model):
    """YOLO modelini performans iÃ§in optimize eder."""
    try:
        # Half precision (FP16) kullan - %40 daha hÄ±zlÄ±
        if get_optimal_device() == 'cuda':
            model.half()
        return model
    except Exception as e:
        print(f"Model optimizasyonu baÅŸarÄ±sÄ±z: {e}")
        return model

# =============================================================================
# --- VÄ°DEO Ä°ÅLEME THREAD'Ä° ---
# =============================================================================

class VideoProcessor(QThread):
    """Video analizini arka planda yÃ¼rÃ¼ten iÅŸ parÃ§acÄ±ÄŸÄ±."""
    progress_updated = pyqtSignal(int)
    # DeÄŸiÅŸiklik: analysis_complete sinyali artÄ±k tespit edilen nesnelerin koordinatlarÄ±nÄ± da taÅŸÄ±yacak
    analysis_complete = pyqtSignal(dict, list, dict) # detected_objects, events, video_info
    status_updated = pyqtSignal(str)
    error_occurred = pyqtSignal(str)

    def __init__(self, video_path: str, sensitivity: str):
        super().__init__()
        self.video_path = video_path
        self.sensitivity_settings = SENSITIVITY_LEVELS[sensitivity]
        self.stop_requested = False

    def run(self):
        try:
            self.status_updated.emit("ğŸš€ ULTRA PERFORMANS MOD - Video aÃ§Ä±lÄ±yor...")
            cap = cv2.VideoCapture(self.video_path)
            if not cap.isOpened():
                raise IOError("Video dosyasÄ± aÃ§Ä±lamadÄ± veya bozuk.")

            video_info = self._get_video_info(cap)
            
            # GPU/CPU otomatik seÃ§im
            device = get_optimal_device()
            self.status_updated.emit(f"ğŸ¯ Analiz motoru yÃ¼kleniyor... ({device.upper()})")
            
            # Model yÃ¼kleme ve optimizasyon
            if not ULTRALYTICS_AVAILABLE:
                raise ModelLoadError("YOLO modeli yÃ¼klenemedi - ultralytics kÃ¼tÃ¼phanesi bulunamadÄ±")
            
            try:
                model = YOLO("yolov8n.pt")
                model.to(device)
                model = optimize_yolo_model(model)
            except Exception as e:
                raise ModelLoadError(f"YOLO modeli yÃ¼klenirken hata: {e}")
            
            self.status_updated.emit(f"âš¡ ULTRA HIZLI analiz baÅŸladÄ±... ({video_info['total_frames']} kare)")
            
            # GeliÅŸmiÅŸ analiz
            detected_objects, detected_frames_list = self._ultra_analyze_frames(cap, model, video_info)

            cap.release()
            
            if self.stop_requested:
                self.status_updated.emit("âŒ Analiz kullanÄ±cÄ± tarafÄ±ndan durduruldu.")
                self.analysis_complete.emit({}, [], video_info)
                return

            self.status_updated.emit("ğŸ”„ AkÄ±llÄ± olay birleÅŸtirme...")
            events = self._smart_merge_events(detected_frames_list, video_info['fps'])
            
            self.progress_updated.emit(100)
            self.status_updated.emit(f"âœ… ULTRA analiz tamamlandÄ±! {len(events)} olay bulundu.")
            self.analysis_complete.emit(detected_objects, events, video_info)

        except Exception as e:
            self.error_occurred.emit(f"âŒ Analiz hatasÄ±: {e}")

    def _get_video_info(self, cap: cv2.VideoCapture) -> dict:
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps <= 0 or total_frames <= 0:
            raise ValueError("Video bilgileri okunamadÄ± (FPS/kare sayÄ±sÄ± sÄ±fÄ±r).")
        return {'fps': fps, 'total_frames': total_frames, 'duration': total_frames / fps}

    def _ultra_analyze_frames(self, cap: cv2.VideoCapture, model: YOLO, video_info: dict) -> tuple[dict, list]:
        """ULTRA PERFORMANSLI kare analizi - GPU optimizasyonu ile."""
        detected_objects = {}
        total_frames = video_info['total_frames']
        detected_frames_list = []
        
        # Performans ayarlarÄ±
        frame_skip = self.sensitivity_settings['frame_skip']
        batch_size = PERFORMANCE_SETTINGS['batch_size']
        
        # Batch processing iÃ§in frame buffer
        frame_buffer = []
        frame_numbers = []
        
        frame_count = 0
        processed_frames = 0
        
        while True:
            if self.stop_requested:
                break
                
            ret, frame = cap.read()
            if not ret:
                break
            
            # Frame atlama kontrolÃ¼
            if frame_count % (frame_skip + 1) != 0:
                frame_count += 1
                continue
            
            # Frame'i buffer'a ekle
            frame_buffer.append(frame)
            frame_numbers.append(frame_count)
            
            # Batch dolu olduÄŸunda veya son frame'de process et
            if len(frame_buffer) >= batch_size or frame_count >= total_frames - 1:
                batch_results = self._process_batch(frame_buffer, frame_numbers, model)
                
                # SonuÃ§larÄ± birleÅŸtir
                for frame_num, detections in batch_results.items():
                    if detections:
                        detected_objects[frame_num] = detections
                        detected_frames_list.append(frame_num)
                
                # Buffer'Ä± temizle
                frame_buffer.clear()
                frame_numbers.clear()
            
            processed_frames += 1
            frame_count += 1
            
            # Progress gÃ¼ncelle ve UI'Ä± responsive tut
            if processed_frames % 10 == 0:
                progress = min(int((frame_count / total_frames) * 100), 100)
                self.progress_updated.emit(progress)
                
                # UI thread'ini bloke etmemek iÃ§in processEvents Ã§aÄŸÄ±r
                QApplication.processEvents()
                
            # Her 50 frame'de bir kÄ±sa bekle (mouse cursor sorunu iÃ§in)
            if processed_frames % 50 == 0:
                self.msleep(1)  # 1ms bekle
        
        return detected_objects, detected_frames_list
    
    def _process_batch(self, frames: list, frame_numbers: list, model: YOLO) -> dict:
        """Batch olarak frame'leri iÅŸler - geliÅŸmiÅŸ filtreleme ile."""
        batch_results = {}
        
        try:
            # UI responsive tutmak iÃ§in
            QApplication.processEvents()
            
            # Frames'i resize et ve batch haline getir
            resized_frames = []
            original_frames = []
            for frame in frames:
                original_frames.append(frame)
                resized = cv2.resize(frame, (ANALYSIS_FRAME_WIDTH, 
                                           int(frame.shape[0] * ANALYSIS_FRAME_WIDTH / frame.shape[1])))
                resized_frames.append(resized)
            
            # YOLO batch inference
            results = model(resized_frames, 
                          conf=self.sensitivity_settings['conf'],
                          iou=PERFORMANCE_SETTINGS['iou_threshold'],
                          max_det=PERFORMANCE_SETTINGS['max_det'],
                          classes=TARGET_CLASSES,
                          verbose=False)
            
            # SonuÃ§larÄ± parse et
            for result, frame_num, original_frame in zip(results, frame_numbers, original_frames):
                detections = []
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    
                    # Orijinal frame boyutlarÄ±
                    original_height, original_width = original_frame.shape[:2]
                    
                    # Ã–lÃ§ekleme faktÃ¶rleri
                    scale_x = original_width / ANALYSIS_FRAME_WIDTH
                    scale_y = original_height / int(original_frame.shape[0] * ANALYSIS_FRAME_WIDTH / original_frame.shape[1])
                    
                    # GeÃ§erli tespitler iÃ§in liste
                    valid_detections = []
                    
                    for box, conf in zip(boxes, confidences):
                        x1, y1, x2, y2 = box
                        
                        # Orijinal boyutlara dÃ¶nÃ¼ÅŸtÃ¼r
                        orig_x1 = int(x1 * scale_x)
                        orig_y1 = int(y1 * scale_y)
                        orig_x2 = int(x2 * scale_x)
                        orig_y2 = int(y2 * scale_y)
                        
                        # x, y, w, h formatÄ±na Ã§evir
                        orig_x = orig_x1
                        orig_y = orig_y1
                        orig_w = orig_x2 - orig_x1
                        orig_h = orig_y2 - orig_y1
                        
                        # SÄ±nÄ±rlarÄ± kontrol et
                        orig_x = max(0, min(orig_x, original_width - orig_w))
                        orig_y = max(0, min(orig_y, original_height - orig_h))
                        orig_w = min(orig_w, original_width - orig_x)
                        orig_h = min(orig_h, original_height - orig_y)
                        
                        # AKILLI FÄ°LTRELEME - YanlÄ±ÅŸ tespitleri elemek iÃ§in
                        if self._is_valid_person_detection(orig_x, orig_y, orig_w, orig_h, conf, original_width, original_height):
                            valid_detections.append({
                                'box': [orig_x, orig_y, orig_w, orig_h],
                                'conf': conf,
                                'area': orig_w * orig_h
                            })
                    
                    # Ã‡akÄ±ÅŸan/benzer tespitleri birleÅŸtir
                    filtered_detections = self._merge_overlapping_detections(valid_detections)
                    
                    # Sadece kutu bilgilerini al
                    detections = [det['box'] for det in filtered_detections]
                
                batch_results[frame_num] = detections
        
        except Exception as e:
            self.error_occurred.emit(f"Batch processing hatasÄ±: {e}")
        
        return batch_results
    
    def _is_valid_person_detection(self, x: int, y: int, w: int, h: int, conf: float, frame_width: int, frame_height: int) -> bool:
        """Tespitin gerÃ§ekten bir kiÅŸi olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
        
        # 1. Minimum boyut kontrolÃ¼
        min_person_area = (frame_width * frame_height) * self.sensitivity_settings['min_area_ratio']
        if w * h < min_person_area:
            return False
        
        # 2. Aspect ratio kontrolÃ¼ (insan vÃ¼cut oranlarÄ±)
        aspect_ratio = h / w if w > 0 else 0
        if aspect_ratio < 0.8 or aspect_ratio > 4.0:  # Ä°nsanlar genelde daha uzun
            return False
        
        # 3. Ã‡ok bÃ¼yÃ¼k tespit kontrolÃ¼ (muhtemelen hatalÄ±)
        max_person_area = (frame_width * frame_height) * 0.8  # Frame'in %80'inden bÃ¼yÃ¼k olamaz
        if w * h > max_person_area:
            return False
        
        # 4. GÃ¼ven skoru kontrolÃ¼
        min_confidence = max(self.sensitivity_settings['conf'], 0.3)  # Minimum %30
        if conf < min_confidence:
            return False
        
        # 5. Ã‡ok dar veya Ã§ok geniÅŸ tespit kontrolÃ¼
        if w < 20 or h < 40:  # Ã‡ok kÃ¼Ã§Ã¼k
            return False
        
        if w > frame_width * 0.8 or h > frame_height * 0.9:  # Ã‡ok bÃ¼yÃ¼k
            return False
        
        # 6. Kenar kontrolÃ¼ - frame kenarlarÄ±ndaki yarÄ±m tespitleri ele
        edge_threshold = 10
        if x < edge_threshold or y < edge_threshold:
            if w * h < min_person_area * 2:  # Kenar tespitleri iÃ§in daha sÄ±kÄ± kontrol
                return False
        
        return True
    
    def _merge_overlapping_detections(self, detections: list) -> list:
        """Ã‡akÄ±ÅŸan tespitleri birleÅŸtirir ve en gÃ¼venilir olanÄ± tutar."""
        if len(detections) <= 1:
            return detections
        
        # GÃ¼ven skoruna gÃ¶re sÄ±rala
        detections.sort(key=lambda x: x['conf'], reverse=True)
        
        merged = []
        for detection in detections:
            box = detection['box']
            x, y, w, h = box
            
            # Mevcut merged listesindeki tespitlerle Ã§akÄ±ÅŸma kontrolÃ¼
            overlap_found = False
            for merged_detection in merged:
                merged_box = merged_detection['box']
                mx, my, mw, mh = merged_box
                
                # IoU (Intersection over Union) hesapla
                iou = self._calculate_iou(x, y, w, h, mx, my, mw, mh)
                
                if iou > 0.5:  # %50'den fazla Ã§akÄ±ÅŸma
                    overlap_found = True
                    # Daha gÃ¼venilir olanÄ± tut (zaten sÄ±ralÄ±)
                    if detection['conf'] > merged_detection['conf']:
                        merged.remove(merged_detection)
                        merged.append(detection)
                    break
            
            if not overlap_found:
                merged.append(detection)
        
        return merged
    
    def _calculate_iou(self, x1: int, y1: int, w1: int, h1: int, x2: int, y2: int, w2: int, h2: int) -> float:
        """Ä°ki kutunun IoU (Intersection over Union) deÄŸerini hesaplar."""
        
        # KesiÅŸim alanÄ±nÄ± hesapla
        x_left = max(x1, x2)
        y_top = max(y1, y2)
        x_right = min(x1 + w1, x2 + w2)
        y_bottom = min(y1 + h1, y2 + h2)
        
        if x_right < x_left or y_bottom < y_top:
            return 0.0
        
        intersection_area = (x_right - x_left) * (y_bottom - y_top)
        
        # BirleÅŸim alanÄ±nÄ± hesapla
        box1_area = w1 * h1
        box2_area = w2 * h2
        union_area = box1_area + box2_area - intersection_area
        
        if union_area == 0:
            return 0.0
        
        return intersection_area / union_area
    
    def _smart_merge_events(self, detected_frames: list, fps: float) -> list:
        """AkÄ±llÄ± olay birleÅŸtirme algoritmasÄ±."""
        if not detected_frames:
            return []
        
        events = []
        detected_frames.sort()
        
        current_start = detected_frames[0] / fps
        current_end = detected_frames[0] / fps
        
        for i in range(1, len(detected_frames)):
            current_time = detected_frames[i] / fps
            
            # EÄŸer frame'ler arasÄ±ndaki gap EVENT_MERGE_GAP_SECONDS'den az ise birleÅŸtir
            if current_time - current_end <= EVENT_MERGE_GAP_SECONDS:
                current_end = current_time
            else:
                # Yeni event baÅŸlat
                events.append((current_start, current_end + EXPORT_BUFFER_SECONDS))
                current_start = current_time
                current_end = current_time
        
        # Son event'i ekle
        events.append((current_start, current_end + EXPORT_BUFFER_SECONDS))
        
        return events
    
    def request_stop(self):
        """Analizi durdur."""
        self.stop_requested = True
    
    def stop(self):
        """Analizi durdur."""
        self.stop_requested = True

# =============================================================================
# --- VÄ°DEO DIÅA AKTARMA THREAD'Ä° ---
# =============================================================================

class VideoExporter(QThread):
    """Video dÄ±ÅŸa aktarma iÅŸlemini yÃ¼rÃ¼ten iÅŸ parÃ§acÄ±ÄŸÄ±."""
    export_progress = pyqtSignal(int, str)
    export_complete = pyqtSignal(str, str) # path, message
    error_occurred = pyqtSignal(str)

    def __init__(self, video_path: str, events: list, video_info: dict, output_path: str):
        super().__init__()
        self.video_path = video_path
        self.events = events
        self.video_duration = video_info['duration']
        self.output_path = output_path

    def run(self):
        try:
            temp_dir = self._create_temp_dir()
            clip_files = self._create_clips(temp_dir)
            
            if not clip_files:
                raise ValueError("DÄ±ÅŸa aktarÄ±lacak klip oluÅŸturulamadÄ±.")

            self._concatenate_clips(clip_files, temp_dir)
            self.export_complete.emit(self.output_path, "Ã–zet video baÅŸarÄ±yla kaydedildi.")

        except Exception as e:
            self.error_occurred.emit(f"DÄ±ÅŸa aktarma hatasÄ±: {e}")
        finally:
            self._cleanup()

    def _create_temp_dir(self) -> str:
        temp_dir = os.path.abspath(TEMP_CLIP_DIR)
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir)
        return temp_dir

    def _create_clips(self, temp_dir: str) -> list:
        clip_files = []
        total_events = len(self.events)
        for i, (start, end) in enumerate(self.events):
            start_buffered = max(0, start - EXPORT_BUFFER_SECONDS)
            end_buffered = min(self.video_duration, end + EXPORT_BUFFER_SECONDS)
            duration = end_buffered - start_buffered

            progress = int(((i + 1) / total_events) * 50)
            self.export_progress.emit(progress, f"Klip {i+1}/{total_events} oluÅŸturuluyor...")

            clip_path = os.path.join(temp_dir, f"clip_{i:03d}.mp4")
            
            command = [
                'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
                '-ss', str(start_buffered), '-i', self.video_path,
                '-t', str(duration), '-c:v', 'libx264', '-preset', 'fast', 
                '-crf', '23', '-c:a', 'aac', '-b:a', '128k', clip_path
            ]
            
            try:
                subprocess.run(command, check=True, capture_output=True, text=True, creationflags=subprocess.CREATE_NO_WINDOW)
                clip_files.append(clip_path)
            except subprocess.CalledProcessError as e:
                self.error_occurred.emit(f"UyarÄ±: Klip {i+1} oluÅŸturulamadÄ±. Hata: {e.stderr}")
                continue
        
        return clip_files

    def _concatenate_clips(self, clip_files: list, temp_dir: str):
        self.export_progress.emit(75, "Klipler birleÅŸtiriliyor...")
        
        file_list_path = os.path.join(temp_dir, "mylist.txt")
        with open(file_list_path, "w", encoding='utf-8') as f:
            for clip_path in clip_files:
                f.write(f"file '{clip_path.replace(os.sep, '/')}'\n")

        concat_command = [
            'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
            '-f', 'concat', '-safe', '0', '-i', file_list_path,
            '-c', 'copy', self.output_path
        ]
        
        subprocess.run(concat_command, check=True, capture_output=True, text=True, creationflags=subprocess.CREATE_NO_WINDOW)
        self.export_progress.emit(100, "BirleÅŸtirme tamamlandÄ±.")

    def _cleanup(self):
        temp_dir = os.path.abspath(TEMP_CLIP_DIR)
        if os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except Exception as e:
                self.error_occurred.emit(f"UyarÄ±: GeÃ§ici dosyalar temizlenemedi: {e}")

# =============================================================================
# --- ZAMAN Ã‡Ä°ZELGESÄ° WIDGET'I ---
# =============================================================================

class TimelineWidget(QWidget):
    """Video olaylarÄ±nÄ± gÃ¶steren etkileÅŸimli zaman Ã§izelgesi."""
    seek_requested = pyqtSignal(float)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMinimumHeight(40)
        self.setCursor(Qt.PointingHandCursor)
        self.duration = 0.0
        self.events = []
        self.progress = 0.0
        self.hover_pos = -1
        self.setMouseTracking(True)

    def set_duration(self, duration: float):
        self.duration = duration
        self.update()

    def set_events(self, events: list):
        self.events = events
        self.update()
        
    def set_progress(self, progress: float):
        self.progress = max(0.0, min(1.0, progress))
        self.update()

    def paintEvent(self, event):
        super().paintEvent(event)
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        
        painter.fillRect(self.rect(), QColor("#2c3e50"))
        timeline_rect = self.rect().adjusted(5, 5, -5, -5)
        painter.fillRect(timeline_rect, QColor("#34495e"))

        if self.duration > 0:
            for start, end in self.events:
                x_start = timeline_rect.left() + int((start / self.duration) * timeline_rect.width())
                x_end = timeline_rect.left() + int((end / self.duration) * timeline_rect.width())
                event_rect = QRect(x_start, timeline_rect.top(), max(1, x_end - x_start), timeline_rect.height())
                painter.fillRect(event_rect, QColor("#e74c3c"))

            progress_x = timeline_rect.left() + int(self.progress * timeline_rect.width())
            painter.setPen(QPen(QColor("#3498db"), 2))
            painter.drawLine(progress_x, timeline_rect.top(), progress_x, timeline_rect.bottom())

        if self.hover_pos != -1:
            painter.fillRect(timeline_rect.left() + self.hover_pos, timeline_rect.top(), 1, timeline_rect.height(), QColor(255, 255, 255, 40))

    def mousePressEvent(self, event):
        if self.duration > 0 and event.button() == Qt.LeftButton:
            self._emit_seek_request(event.pos().x())

    def mouseMoveEvent(self, event):
        timeline_rect = self.rect().adjusted(5, 5, -5, -5)
        if timeline_rect.contains(event.pos()):
            self.hover_pos = event.pos().x() - timeline_rect.left()
            self.update()
        else:
            self.leaveEvent(event)

    def leaveEvent(self, event):
        self.hover_pos = -1
        self.update()

    def _emit_seek_request(self, x_pos: int):
        timeline_rect = self.rect().adjusted(5, 5, -5, -5)
        if timeline_rect.width() > 0:
            relative_pos = (x_pos - timeline_rect.left()) / timeline_rect.width()
            seek_time = max(0, min(self.duration, relative_pos * self.duration))
            self.seek_requested.emit(seek_time)

# =============================================================================
# --- ANA ARAYÃœZ PENCERESÄ° ---
# =============================================================================

class AdvancedObjectSelectionDialog(QDialog):
    """GeliÅŸmiÅŸ nesne seÃ§im dialogu"""
    
    def __init__(self, target_classes, active_classes, parent=None):
        super().__init__(parent)
        self.target_classes = target_classes
        self.active_classes = active_classes
        self.init_ui()
    
    def init_ui(self):
        """UI'Ä± baÅŸlat"""
        self.setWindowTitle("GeliÅŸmiÅŸ Nesne SeÃ§imi")
        self.setModal(True)
        self.resize(500, 400)
        
        layout = QVBoxLayout()
        
        # AÃ§Ä±klama
        description = QLabel("Analiz edilecek nesne tÃ¼rlerini seÃ§in:")
        description.setFont(QFont("Arial", 10, QFont.Bold))
        layout.addWidget(description)
        
        # Scroll area for checkboxes
        scroll = QScrollArea()
        scroll_widget = QWidget()
        scroll_layout = QGridLayout(scroll_widget)
        
        self.checkboxes = {}
        row, col = 0, 0
        
        for category, objects in self.target_classes.items():
            # Kategori baÅŸlÄ±ÄŸÄ±
            category_label = QLabel(f"ğŸ“‚ {category.upper()}")
            category_label.setFont(QFont("Arial", 9, QFont.Bold))
            category_label.setStyleSheet("color: #2196F3; margin: 5px 0;")
            scroll_layout.addWidget(category_label, row, 0, 1, 3)
            row += 1
            
            # Nesneler
            for obj in objects:
                checkbox = QCheckBox(obj)
                if obj in self.active_classes:
                    checkbox.setChecked(True)
                
                self.checkboxes[obj] = checkbox
                scroll_layout.addWidget(checkbox, row, col)
                
                col += 1
                if col >= 3:
                    col = 0
                    row += 1
            
            if col != 0:
                row += 1
                col = 0
        
        scroll.setWidget(scroll_widget)
        layout.addWidget(scroll)
        
        # Butonlar
        button_layout = QHBoxLayout()
        
        select_all_btn = QPushButton("TÃ¼mÃ¼nÃ¼ SeÃ§")
        select_all_btn.clicked.connect(self.select_all)
        button_layout.addWidget(select_all_btn)
        
        deselect_all_btn = QPushButton("TÃ¼mÃ¼nÃ¼ KaldÄ±r")
        deselect_all_btn.clicked.connect(self.deselect_all)
        button_layout.addWidget(deselect_all_btn)
        
        button_layout.addStretch()
        
        ok_btn = QPushButton("Tamam")
        ok_btn.clicked.connect(self.accept)
        ok_btn.setDefault(True)
        button_layout.addWidget(ok_btn)
        
        cancel_btn = QPushButton("Ä°ptal")
        cancel_btn.clicked.connect(self.reject)
        button_layout.addWidget(cancel_btn)
        
        layout.addLayout(button_layout)
        self.setLayout(layout)
    
    def select_all(self):
        """TÃ¼mÃ¼nÃ¼ seÃ§"""
        for checkbox in self.checkboxes.values():
            checkbox.setChecked(True)
    
    def deselect_all(self):
        """TÃ¼mÃ¼nÃ¼ kaldÄ±r"""
        for checkbox in self.checkboxes.values():
            checkbox.setChecked(False)
    
    def get_selected_classes(self):
        """SeÃ§ili sÄ±nÄ±flarÄ± dÃ¶ndÃ¼r"""
        selected = []
        for obj, checkbox in self.checkboxes.items():
            if checkbox.isChecked():
                selected.append(obj)
        return selected

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self._setup_ui()
        self._connect_signals()
        self._setup_shortcuts()  # Yeni: Klavye kÄ±sayollarÄ±
        self._initialize_state()

    def _setup_ui(self):
        self.setWindowTitle("M.SAVAÅ - Motion Surveillance and Video Analysis System")
        self.setGeometry(50, 50, 1870, 1150)  # Ä°ÅŸlem geÃ§miÅŸi iÃ§in daha da bÃ¼yÃ¼k (1850x1150 -> 1870x1150)
        self.setStyleSheet(self.get_stylesheet())

        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)
        self.main_layout = QHBoxLayout(self.central_widget)

        # Sol Panel - Tamamen sabit boyut ve daha gÃ¼zel tasarÄ±m
        left_panel_widget = QWidget()
        left_panel_widget.setFixedSize(420, 1080)  # Ä°ÅŸlem geÃ§miÅŸi iÃ§in daha fazla yer (400x1020 -> 420x1080)
        left_panel_widget.setMaximumSize(420, 1080)
        left_panel_widget.setMinimumSize(420, 1080)
        left_panel_layout = QVBoxLayout(left_panel_widget)
        left_panel_layout.setSpacing(5)  # Daha az boÅŸluk
        left_panel_layout.setContentsMargins(5, 5, 5, 5)  # Daha az margin
        
        # Video dosyalarÄ± grubu - kompakt
        video_group = QGroupBox("ğŸ“ Video DosyalarÄ±")
        video_layout = QVBoxLayout()
        video_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        video_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        
        # Video butonlarÄ± - 2x2 dÃ¼zen, kompakt ve gÃ¼zel
        video_btn_layout1 = QHBoxLayout()
        video_btn_layout1.setSpacing(3)  # Minimum boÅŸluk
        self.btn_add_video = QPushButton("â• Video Ekle")
        self.btn_add_video.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        self.btn_load = QPushButton("ğŸ“‚ Tek Video YÃ¼kle")
        self.btn_load.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        video_btn_layout1.addWidget(self.btn_add_video)
        video_btn_layout1.addWidget(self.btn_load)
        
        video_btn_layout2 = QHBoxLayout()
        video_btn_layout2.setSpacing(3)  # Minimum boÅŸluk
        self.btn_remove_video = QPushButton("â– KaldÄ±r")
        self.btn_remove_video.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        self.btn_clear_videos = QPushButton("ğŸ—‘ï¸ Temizle")
        self.btn_clear_videos.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        video_btn_layout2.addWidget(self.btn_remove_video)
        video_btn_layout2.addWidget(self.btn_clear_videos)
        
        # CanlÄ± kamera butonlarÄ± - YENÄ° Ã–ZELLÄ°K
        video_btn_layout3 = QHBoxLayout()
        video_btn_layout3.setSpacing(3)  # Minimum boÅŸluk
        self.btn_start_camera = QPushButton("ğŸ“¹ CanlÄ± Kamera")
        self.btn_start_camera.setFixedSize(200, 28)
        self.btn_stop_camera = QPushButton("ğŸ›‘ KamerayÄ± Durdur")
        self.btn_stop_camera.setFixedSize(200, 28)
        self.btn_stop_camera.setEnabled(False)
        video_btn_layout3.addWidget(self.btn_start_camera)
        video_btn_layout3.addWidget(self.btn_stop_camera)
        
        # Video listesi
        self.video_list = QListWidget()
        self.video_list.setFixedSize(410, 80)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 390->410
        self.video_list.setMaximumSize(410, 80)
        self.video_list.setMinimumSize(410, 80)
        
        # Video bilgi paneli
        self.video_info_label = QLabel("ğŸ“¹ Video seÃ§ilmedi")
        self.video_info_label.setFixedHeight(50)
        self.video_info_label.setWordWrap(True)
        self.video_info_label.setStyleSheet("""
            QLabel {
                background-color: #34495e;
                color: #ecf0f1;
                border: 1px solid #3498db;
                border-radius: 5px;
                padding: 5px;
                font-size: 11px;
                font-weight: bold;
            }
        """)
        
        video_layout.addLayout(video_btn_layout1)
        video_layout.addLayout(video_btn_layout2)
        video_layout.addLayout(video_btn_layout3)  # YENÄ°: CanlÄ± kamera butonlarÄ±
        video_layout.addWidget(self.video_list)
        video_layout.addWidget(self.video_info_label)
        video_group.setLayout(video_layout)
        
        # Video dÃ¶ndÃ¼rme grubu - kompakt
        rotation_group = QGroupBox("ğŸ”„ Video DÃ¶ndÃ¼rme")
        rotation_layout = QVBoxLayout()
        rotation_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        rotation_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        
        # DÃ¶ndÃ¼rme butonlarÄ± - 2x2 dÃ¼zen, kompakt
        rotation_btn_layout1 = QHBoxLayout()
        rotation_btn_layout1.setSpacing(3)  # Minimum boÅŸluk
        self.btn_rotate_90 = QPushButton("â†» 90Â°")
        self.btn_rotate_90.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        self.btn_rotate_180 = QPushButton("â†» 180Â°")
        self.btn_rotate_180.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        rotation_btn_layout1.addWidget(self.btn_rotate_90)
        rotation_btn_layout1.addWidget(self.btn_rotate_180)
        
        rotation_btn_layout2 = QHBoxLayout()
        rotation_btn_layout2.setSpacing(3)  # Minimum boÅŸluk
        self.btn_rotate_270 = QPushButton("â†» 270Â°")
        self.btn_rotate_270.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        self.btn_rotate_reset = QPushButton("ğŸ”„ SÄ±fÄ±rla")
        self.btn_rotate_reset.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        rotation_btn_layout2.addWidget(self.btn_rotate_270)
        rotation_btn_layout2.addWidget(self.btn_rotate_reset)
        
        rotation_layout.addLayout(rotation_btn_layout1)
        rotation_layout.addLayout(rotation_btn_layout2)
        rotation_group.setLayout(rotation_layout)
        
        # Analiz kontrolleri grubu - kompakt
        controls_group = QGroupBox("âš¡ Analiz Kontrolleri")
        controls_layout = QVBoxLayout()
        controls_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        controls_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        
        # Analiz butonlarÄ± - 2x1 dÃ¼zen, gÃ¼zel ve kompakt
        analyze_btn_layout = QHBoxLayout()
        analyze_btn_layout.setSpacing(3)  # Minimum boÅŸluk
        self.btn_analyze = QPushButton("ğŸš€ Analiz Et")
        self.btn_analyze.setFixedSize(200, 35)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        self.btn_stop_analysis = QPushButton("ğŸ›‘ Analizi Durdur")
        self.btn_stop_analysis.setFixedSize(200, 35)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 190->200
        analyze_btn_layout.addWidget(self.btn_analyze)
        analyze_btn_layout.addWidget(self.btn_stop_analysis)
        
        # Video dÄ±ÅŸa aktarma
        self.btn_export = QPushButton("ğŸ“¹ Ã–zet Video OluÅŸtur")
        self.btn_export.setFixedSize(410, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 390->410
        
        controls_layout.addLayout(analyze_btn_layout)
        controls_layout.addWidget(self.btn_export)
        controls_group.setLayout(controls_layout)
        
        # Rapor butonlarÄ± grubu - kompakt
        reports_group = QGroupBox("ğŸ“Š Rapor OluÅŸtur")
        reports_layout = QVBoxLayout()
        reports_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        reports_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        
        # Rapor butonlarÄ± - sadece Word ve Grafik kalsÄ±n
        report_btn_layout1 = QHBoxLayout()
        report_btn_layout1.setSpacing(3)  # Minimum boÅŸluk
        self.btn_export_word = QPushButton("ï¿½ Word Raporu")
        self.btn_export_word.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±
        self.btn_export_charts = QPushButton("ï¿½ Grafik Raporu")
        self.btn_export_charts.setFixedSize(200, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±
        report_btn_layout1.addWidget(self.btn_export_word)
        report_btn_layout1.addWidget(self.btn_export_charts)
        
        # TÃ¼m raporlar butonu tek satÄ±rda
        self.btn_export_all = QPushButton("ğŸ¯ TÃ¼m Raporlar (Word + Grafik)")
        self.btn_export_all.setFixedSize(410, 28)  # GeniÅŸlik artÄ±rÄ±ldÄ±
        
        reports_layout.addLayout(report_btn_layout1)
        reports_layout.addWidget(self.btn_export_all)
        reports_group.setLayout(reports_layout)

        # Hassasiyet grubu - kompakt
        sensitivity_group = QGroupBox("ğŸ¯ Analiz Hassasiyeti")
        sensitivity_layout = QVBoxLayout()
        sensitivity_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        sensitivity_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        self.sensitivity_buttons = QButtonGroup()
        
        # Hassasiyet butonlarÄ± - 2 sÃ¼tun, kompakt
        sensitivity_grid = QVBoxLayout()
        levels = list(SENSITIVITY_LEVELS.keys())
        for i in range(0, len(levels), 2):
            row_layout = QHBoxLayout()
            row_layout.setSpacing(3)  # Minimum boÅŸluk
            
            # Sol sÃ¼tun
            radio1 = QRadioButton(levels[i])
            radio1.setFixedSize(190, 25)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 180->190
            if levels[i] == DEFAULT_SENSITIVITY:
                radio1.setChecked(True)
            self.sensitivity_buttons.addButton(radio1, i)
            row_layout.addWidget(radio1)
            
            # SaÄŸ sÃ¼tun (varsa)
            if i + 1 < len(levels):
                radio2 = QRadioButton(levels[i + 1])
                radio2.setFixedSize(190, 25)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 180->190
                if levels[i + 1] == DEFAULT_SENSITIVITY:
                    radio2.setChecked(True)
                self.sensitivity_buttons.addButton(radio2, i + 1)
                row_layout.addWidget(radio2)
            
            sensitivity_grid.addLayout(row_layout)
        
        sensitivity_layout.addLayout(sensitivity_grid)
        sensitivity_group.setLayout(sensitivity_layout)

        # YENÄ°: Nesne Tespiti SeÃ§imi - kompakt
        objects_group = QGroupBox("ğŸ¯ Tespit Edilecek Nesneler")
        objects_layout = QVBoxLayout()
        objects_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        objects_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        
        # Nesne seÃ§imi iÃ§in checkboxlar
        self.object_checkboxes = {}
        object_grid = QVBoxLayout()
        
        # Ana kategoriler
        main_objects = [
            ('ğŸ‘¤ Ä°nsan', 'person', True),  # VarsayÄ±lan aÃ§Ä±k
            ('ğŸš— AraÃ§', 'car', False),
            ('ğŸš² Bisiklet', 'bicycle', False),
            ('ğŸï¸ Motosiklet', 'motorbike', False)
        ]
        
        for i in range(0, len(main_objects), 2):
            row_layout = QHBoxLayout()
            row_layout.setSpacing(3)
            
            # Sol checkbox
            emoji, class_name, default_checked = main_objects[i]
            checkbox1 = QPushButton(emoji)
            checkbox1.setCheckable(True)
            checkbox1.setChecked(default_checked)
            checkbox1.setFixedSize(190, 25)
            checkbox1.setObjectName(f"obj_{class_name}")
            self.object_checkboxes[class_name] = checkbox1
            row_layout.addWidget(checkbox1)
            
            # SaÄŸ checkbox (varsa)
            if i + 1 < len(main_objects):
                emoji2, class_name2, default_checked2 = main_objects[i + 1]
                checkbox2 = QPushButton(emoji2)
                checkbox2.setCheckable(True)
                checkbox2.setChecked(default_checked2)
                checkbox2.setFixedSize(190, 25)
                checkbox2.setObjectName(f"obj_{class_name2}")
                self.object_checkboxes[class_name2] = checkbox2
                row_layout.addWidget(checkbox2)
            
            object_grid.addLayout(row_layout)
        
        # GeliÅŸmiÅŸ seÃ§enekler butonu
        self.btn_advanced_objects = QPushButton("âš™ï¸ GeliÅŸmiÅŸ Nesne SeÃ§imi")
        self.btn_advanced_objects.setFixedSize(390, 25)
        object_grid.addWidget(self.btn_advanced_objects)
        
        objects_layout.addLayout(object_grid)
        objects_group.setLayout(objects_layout)

        # Tespit Edilen Olaylar Listesi - kompakt
        events_group = QGroupBox("ğŸ¯ Tespit Edilen Olaylar")
        events_layout = QVBoxLayout()
        events_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        events_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        self.event_list_widget = QListWidget()
        self.event_list_widget.setObjectName("eventList")
        self.event_list_widget.setFixedSize(390, 100)  # GeniÅŸlik artÄ±rÄ±ldÄ±: 370->390
        self.event_list_widget.setMaximumSize(390, 100)
        self.event_list_widget.setMinimumSize(390, 100)
        events_layout.addWidget(self.event_list_widget)
        events_group.setLayout(events_layout)

        # Ä°ÅŸlem GeÃ§miÅŸi - geliÅŸmiÅŸ ve daha bÃ¼yÃ¼k
        log_group = QGroupBox("ğŸ“‹ Ä°ÅŸlem GeÃ§miÅŸi & Sistem MesajlarÄ±")
        log_group.setStyleSheet("""
            QGroupBox {
                font-weight: bold;
                color: white;
                border: 2px solid #34495e;
                border-radius: 8px;
                margin: 3px;
                padding-top: 15px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #34495e, stop:1 #2c3e50);
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
                color: white;
                font-size: 12px;
            }
        """)
        log_layout = QVBoxLayout()
        log_layout.setSpacing(2)  # Ä°Ã§erideki boÅŸluÄŸu azalt
        log_layout.setContentsMargins(5, 5, 5, 5)  # Kenar boÅŸluklarÄ±nÄ± azalt
        self.log_display = QTextEdit()
        self.log_display.setReadOnly(True)
        self.log_display.setFixedSize(390, 320)  # Daha da bÃ¼yÃ¼k yapÄ±ldÄ±: 280->320, geniÅŸlik: 370->390
        self.log_display.setMaximumSize(390, 320)
        self.log_display.setMinimumSize(390, 320)
        self.log_display.setStyleSheet("""
            QTextEdit {
                background-color: #2c3e50;
                color: white;
                border: 1px solid #34495e;
                border-radius: 5px;
                font-size: 11px;
                font-family: 'Segoe UI';
                padding: 8px;
                selection-background-color: #3498db;
                line-height: 1.4;
            }
            QScrollBar:vertical {
                background-color: #34495e;
                width: 12px;
                border-radius: 6px;
            }
            QScrollBar::handle:vertical {
                background-color: #3498db;
                border-radius: 6px;
                min-height: 20px;
            }
            QScrollBar::handle:vertical:hover {
                background-color: #2980b9;
            }
            QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
                height: 0px;
            }
        """)
        log_layout.addWidget(self.log_display)
        log_group.setLayout(log_layout)

        # Sol panel dÃ¼zeni - minimum spacing
        left_panel_layout.setSpacing(2)  # Gruplar arasÄ± boÅŸluÄŸu azalt
        left_panel_layout.addWidget(video_group)
        left_panel_layout.addWidget(rotation_group)
        left_panel_layout.addWidget(controls_group)  
        left_panel_layout.addWidget(reports_group)
        left_panel_layout.addWidget(sensitivity_group)
        left_panel_layout.addWidget(objects_group)  # YENÄ°: Nesne seÃ§imi
        left_panel_layout.addWidget(events_group)
        left_panel_layout.addWidget(log_group)
        # Stretch kaldÄ±rÄ±ldÄ± - iÅŸlem geÃ§miÅŸine daha fazla alan

        # SaÄŸ Panel - daha bÃ¼yÃ¼k video gÃ¶rÃ¼ntÃ¼sÃ¼
        right_panel = QVBoxLayout()
        self.video_display_label = QLabel("LÃ¼tfen bir video dosyasÄ± yÃ¼kleyin.")
        self.video_display_label.setAlignment(Qt.AlignCenter)
        self.video_display_label.setMinimumSize(800, 600)  # Daha bÃ¼yÃ¼k
        self.video_display_label.setFrameShape(QFrame.StyledPanel)
        self.video_display_label.setObjectName("videoDisplay")

        # Oynatma kontrolleri
        playback_layout = QHBoxLayout()
        self.btn_play_pause = QPushButton()
        self.btn_play_pause.setIcon(self.style().standardIcon(QStyle.SP_MediaPlay))
        self.btn_play_pause.setObjectName("playPauseButton")
        self.timeline_widget = TimelineWidget()
        playback_layout.addWidget(self.btn_play_pause)
        playback_layout.addWidget(self.timeline_widget, 1)

        # Durum bilgileri
        status_layout = QVBoxLayout()
        self.progress_bar = QProgressBar()
        self.progress_bar.setMinimumHeight(25)  # Daha kalÄ±n
        self.status_label = QLabel("Durum: HazÄ±r")
        
        info_layout = QHBoxLayout()
        self.info_label_original = QLabel("<b>Orijinal Video:</b> -")
        self.info_label_summary = QLabel("<b>Ã–zet Video:</b> -")
        info_layout.addWidget(self.info_label_original)
        info_layout.addWidget(self.info_label_summary)
        
        status_layout.addLayout(info_layout)
        status_layout.addWidget(self.progress_bar)
        status_layout.addWidget(self.status_label)

        right_panel.addWidget(self.video_display_label, 1)
        right_panel.addLayout(playback_layout)
        right_panel.addLayout(status_layout)

        self.main_layout.addWidget(left_panel_widget)
        self.main_layout.addLayout(right_panel, 1)

    def _connect_signals(self):
        self.btn_load.clicked.connect(self.load_video)
        self.btn_add_video.clicked.connect(self.add_video_file)
        self.btn_remove_video.clicked.connect(self.remove_video_file)
        self.btn_clear_videos.clicked.connect(self.clear_all_videos)
        self.video_list.itemSelectionChanged.connect(self.on_video_selection_changed)
        self.btn_analyze.clicked.connect(self.analyze_video)
        self.btn_stop_analysis.clicked.connect(self.stop_analysis)
        self.btn_export.clicked.connect(self.export_video)
        self.btn_export_charts.clicked.connect(self.export_charts_report)
        self.btn_export_word.clicked.connect(self.export_word_report)
        self.btn_export_all.clicked.connect(self.export_all_reports)  # Yeni
        self.btn_play_pause.clicked.connect(self.toggle_playback)
        self.timeline_widget.seek_requested.connect(self.seek_video)
        self.sensitivity_buttons.buttonClicked.connect(self.sensitivity_changed)
        self.event_list_widget.itemClicked.connect(self.on_event_item_clicked)
        
        # Video dÃ¶ndÃ¼rme butonlarÄ±
        self.btn_rotate_90.clicked.connect(lambda: self.rotate_video(90))
        self.btn_rotate_180.clicked.connect(lambda: self.rotate_video(180))
        self.btn_rotate_270.clicked.connect(lambda: self.rotate_video(270))
        self.btn_rotate_reset.clicked.connect(lambda: self.rotate_video(0))
        
        # YENÄ°: CanlÄ± kamera butonlarÄ±
        self.btn_start_camera.clicked.connect(self.start_live_camera)
        self.btn_stop_camera.clicked.connect(self.stop_live_camera)
        
        # YENÄ°: Nesne seÃ§imi butonlarÄ±
        for class_name, checkbox in self.object_checkboxes.items():
            checkbox.clicked.connect(self.update_active_classes)
        self.btn_advanced_objects.clicked.connect(self.open_advanced_selection)
    
    def _setup_shortcuts(self):
        """Klavye kÄ±sayollarÄ±nÄ± ayarlar"""
        
        # Dosya iÅŸlemleri
        self.shortcut_open = QShortcut(QKeySequence("Ctrl+O"), self)
        self.shortcut_open.activated.connect(self.load_video)
        
        # Analiz iÅŸlemleri
        self.shortcut_analyze = QShortcut(QKeySequence("F5"), self)
        self.shortcut_analyze.activated.connect(self.analyze_video)
        
        self.shortcut_stop = QShortcut(QKeySequence("Esc"), self)
        self.shortcut_stop.activated.connect(self.stop_analysis)
        
        # Video kontrolleri
        self.shortcut_play_pause = QShortcut(QKeySequence("Space"), self)
        self.shortcut_play_pause.activated.connect(self.toggle_playback)
        
        # Rapor kaydetme
        self.shortcut_save_word = QShortcut(QKeySequence("Ctrl+W"), self)
        self.shortcut_save_word.activated.connect(self.export_word_report)
        
        # Video dÃ¶ndÃ¼rme
        self.shortcut_rotate_90 = QShortcut(QKeySequence("Ctrl+R"), self)
        self.shortcut_rotate_90.activated.connect(lambda: self.rotate_video(90))
        
        # TÃ¼m raporlarÄ± kaydet
        self.shortcut_save_all = QShortcut(QKeySequence("Ctrl+Shift+S"), self)
        self.shortcut_save_all.activated.connect(self.export_all_reports)
        
        self.log_message("âŒ¨ï¸ Klavye kÄ±sayollarÄ± aktif: Ctrl+O (AÃ§), F5 (Analiz), Space (Oynat/Duraklat)", "info")

    def _initialize_state(self):
        self.video_path = None
        self.video_paths = []  # Ã‡oklu video desteÄŸi
        self.current_video_index = 0  # Åu anki video indeksi
        self.video_capture = None
        self.video_info = {}
        self.detected_events = []
        self.detected_objects = {} # Yeni: Nesne koordinatlarÄ±nÄ± saklamak iÃ§in
        self.is_playing = False
        self.current_sensitivity = DEFAULT_SENSITIVITY
        self.playback_timer = QTimer(self)
        self.playback_timer.timeout.connect(self.update_frame)
        self.processor_thread = None
        self.exporter_thread = None
        self.current_rotation = 0  # Video dÃ¶ndÃ¼rme aÃ§Ä±sÄ± (0, 90, 180, 270)
        
        # Nesne tespit sÄ±nÄ±flarÄ±
        self.TARGET_CLASSES = {
            'Ä°nsan ve Hayvan': ['person', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe'],
            'TaÅŸÄ±t': ['bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat'],
            'Elektronik': ['tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone'],
            'Spor': ['sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket'],
            'GÃ¼nlÃ¼k EÅŸya': ['bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich'],
            'Mobilya': ['chair', 'sofa', 'bed', 'dining table', 'toilet'],
            'DiÄŸer': ['umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'clock', 'vase', 'scissors']
        }
        
        # VarsayÄ±lan aktif sÄ±nÄ±flar
        self.ACTIVE_CLASSES = ['person']
        
        # YOLO modeli yÃ¼kle
        try:
            from ultralytics import YOLO
            self.model = YOLO('yolov8n.pt')  # Nano model (hÄ±zlÄ±)
            self.log_message("ğŸ¤– YOLO modeli baÅŸarÄ±yla yÃ¼klendi!", "success")
        except Exception as e:
            self.log_message(f"âš ï¸ YOLO modeli yÃ¼klenemedi: {e}", "warning")
            self.model = None
        
        # Live camera variables
        self.live_camera = None
        self.live_timer = QTimer()
        self.live_timer.timeout.connect(self.update_live_camera_frame)
        self.live_detection_count = 0
        
        # YENÄ°: CanlÄ± kamera Ã¶zellikleri
        self.is_live_camera = False
        self.camera_capture = None
        self.live_camera_timer = QTimer(self)
        self.live_camera_timer.timeout.connect(self.update_live_camera_frame)
        self.live_detection_enabled = False
        
        self.update_ui_state()
        
        # GPU/CUDA durumu kontrolÃ¼
        device_info = detect_gpu_capability()
        if device_info['available']:
            self.log_message(f"ğŸš€ M.SAVAÅ ULTRA PERFORMANS modu baÅŸlatÄ±ldÄ±! GPU: {device_info['name']} ({device_info['memory_gb']:.1f}GB)", "success")
        else:
            self.log_message("ğŸš€ M.SAVAÅ ULTRA PERFORMANS modu baÅŸlatÄ±ldÄ±! CPU optimizasyonu aktif (CUDA bulunamadÄ±)", "success")
        
        self.log_message("ğŸ“‹ Yeni: Sadece Word ve Grafik raporlarÄ± kullanÄ±labilir. Video seÃ§ince detaylar gÃ¶rÃ¼necek.", "info")
    
    def validate_video_file(self, file_path: str) -> bool:
        """Video dosyasÄ±nÄ±n gÃ¼venliÄŸini ve geÃ§erliliÄŸini kontrol eder"""
        try:
            # Dosya varlÄ±ÄŸÄ± kontrolÃ¼
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Dosya bulunamadÄ±: {file_path}")
            
            # Dosya boyutu kontrolÃ¼
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            max_size = config_manager.get_max_file_size()
            if file_size_mb > max_size:
                raise FileFormatError(f"Dosya boyutu Ã§ok bÃ¼yÃ¼k: {file_size_mb:.1f}MB (Max: {max_size}MB)")
            
            # Dosya uzantÄ±sÄ± kontrolÃ¼
            _, ext = os.path.splitext(file_path)
            supported_formats = config_manager.get_supported_formats()
            if ext.lower().replace('.', '') not in supported_formats:
                raise FileFormatError(f"Desteklenmeyen format: {ext}")
            
            # Video dosyasÄ± geÃ§erlilik kontrolÃ¼
            cap = cv2.VideoCapture(file_path)
            if not cap.isOpened():
                cap.release()
                raise VideoLoadError("Video dosyasÄ± aÃ§Ä±lamadÄ±")
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
            cap.release()
            
            if fps <= 0 or frame_count <= 0:
                raise VideoLoadError("GeÃ§ersiz video metadata")
            
            return True
            
        except (FileNotFoundError, FileFormatError, VideoLoadError) as e:
            self.show_error_message(str(e))
            return False
        except Exception as e:
            self.show_error_message(f"Video doÄŸrulama hatasÄ±: {e}")
            return False
    
    def cleanup_temp_files(self, temp_dir: str):
        """GeÃ§ici dosyalarÄ± gÃ¼venli ÅŸekilde temizler"""
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                self.log_message(f"GeÃ§ici dosyalar temizlendi: {temp_dir}", "info")
        except Exception as e:
            self.log_message(f"GeÃ§ici dosya temizleme hatasÄ±: {e}", "warning")
    
    def _apply_security_camera_settings(self):
        """GÃ¼venlik kamerasÄ± iÃ§in optimum ayarlarÄ± uygular"""
        try:
            # Hassasiyet seviyesini gÃ¼venlik kamerasÄ± moduna ayarla
            for button in self.sensitivity_buttons.buttons():
                if button.text() == "ğŸ¢ GÃ¼venlik KamerasÄ±":
                    button.setChecked(True)
                    self.current_sensitivity = "ğŸ¢ GÃ¼venlik KamerasÄ±"
                    break
            
            # EÄŸer gÃ¼venlik kamerasÄ± modu yoksa DETAYLI kullan
            if self.current_sensitivity != "ğŸ¢ GÃ¼venlik KamerasÄ±":
                for button in self.sensitivity_buttons.buttons():
                    if button.text() == "ğŸ” DetaylÄ±":
                        button.setChecked(True)
                        self.current_sensitivity = "ğŸ” DetaylÄ±"
                        break
            
            # Ã–zel log mesajÄ±
            self.log_message("ğŸ¯ GÃ¼venlik kamerasÄ± optimizasyonlarÄ± uygulandÄ±:", "success")
            self.log_message("  â€¢ DÃ¼ÅŸÃ¼k Ä±ÅŸÄ±k optimizasyonu aktif", "info")
            self.log_message("  â€¢ SÃ¼rekli izleme modu etkin", "info")
            self.log_message("  â€¢ GeliÅŸmiÅŸ hareket tespiti aÃ§Ä±k", "info")
            self.log_message("  â€¢ Sabit kamera optimizasyonu aktif", "info")
            
        except Exception as e:
            self.log_message(f"GÃ¼venlik kamerasÄ± ayarlarÄ± uygulanamadÄ±: {e}", "warning")
    
    def detect_video_type(self, file_path: str) -> str:
        """Video tipini tespit eder (gÃ¼venlik kamerasÄ±, mobil, drone vb.)"""
        filename = os.path.basename(file_path).lower()
        
        # GÃ¼venlik kamerasÄ± patterns
        if any(pattern in filename for pattern in ['_ch', 'channel', 'cam0', 'dvr', 'nvr', 'hikvision', 'dahua']):
            return "security_camera"
        
        # Mobil telefon patterns
        if any(pattern in filename for pattern in ['img_', 'vid_', 'mov_', 'whatsapp', 'telegram']):
            return "mobile_phone"
        
        # Drone patterns
        if any(pattern in filename for pattern in ['dji_', 'drone_', 'aerial_', 'phantom']):
            return "drone"
        
        # VarsayÄ±lan
        return "standard"

    def update_ui_state(self, is_analyzing=False, is_exporting=False):
        is_video_loaded = self.video_path is not None
        has_videos = bool(self.video_paths)
        has_events = bool(self.detected_events)
        
        # Video yÃ¶netimi butonlarÄ±
        self.btn_add_video.setEnabled(not is_analyzing and not is_exporting)
        self.btn_remove_video.setEnabled(has_videos and not is_analyzing and not is_exporting)
        self.btn_clear_videos.setEnabled(has_videos and not is_analyzing and not is_exporting)
        
        # Analiz butonlarÄ± - tek video veya Ã§oklu video varsa etkin
        can_analyze = (is_video_loaded or has_videos) and not is_analyzing and not is_exporting
        
        self.btn_load.setEnabled(not is_analyzing and not is_exporting)
        self.btn_analyze.setEnabled(can_analyze)
        
        # Analiz buton metni gÃ¼ncelle
        if is_analyzing:
            self.btn_analyze.setText("ğŸ›‘ Analizi Durdur")
        else:
            self.btn_analyze.setText("ğŸš€ Analiz Et")
        
        self.btn_stop_analysis.setEnabled(is_analyzing)
        self.btn_export.setEnabled(has_events and not is_analyzing and not is_exporting)
        self.btn_export_charts.setEnabled(has_events and not is_analyzing and not is_exporting)
        self.btn_export_word.setEnabled(has_events and not is_analyzing and not is_exporting)
        self.btn_export_all.setEnabled(has_events and not is_analyzing and not is_exporting)  # Yeni
        self.btn_play_pause.setEnabled(is_video_loaded and not is_analyzing and not is_exporting)
        self.timeline_widget.setEnabled(is_video_loaded and not is_analyzing)
        
        # Video dÃ¶ndÃ¼rme butonlarÄ±
        self.btn_rotate_90.setEnabled(is_video_loaded and not is_analyzing and not is_exporting)
        self.btn_rotate_180.setEnabled(is_video_loaded and not is_analyzing and not is_exporting)
        self.btn_rotate_270.setEnabled(is_video_loaded and not is_analyzing and not is_exporting)
        self.btn_rotate_reset.setEnabled(is_video_loaded and not is_analyzing and not is_exporting)
        
        for button in self.sensitivity_buttons.buttons():
            button.setEnabled(not is_analyzing and not is_exporting)

    @pyqtSlot()
    def load_video(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Video DosyasÄ± SeÃ§", "", 
            "TÃ¼m Video DosyalarÄ± (*.mp4 *.avi *.mkv *.mov *.wmv *.flv *.webm *.dav *.h264 *.264 *.ts *.m2ts *.mts);;"
            "Standart Videolar (*.mp4 *.avi *.mkv *.mov *.wmv);;"
            "GÃ¼venlik KamerasÄ± (*.dav *.h264 *.264 *.ts *.m2ts);;"
            "CanlÄ± YayÄ±n (*.flv *.webm *.ts);;"
            "TÃ¼m Dosyalar (*.*)")
        if not file_path:
            return

        try:
            self.video_path = file_path
            self.log_message(f"Video yÃ¼kleniyor: {os.path.basename(file_path)}", "info")
            self._reset_for_new_video()

            # Video capture nesnesini oluÅŸtur - farklÄ± backend'leri dene
            backends_to_try = [
                cv2.CAP_FFMPEG,    # FFmpeg backend (en uyumlu)
                cv2.CAP_DSHOW,     # DirectShow (Windows)
                cv2.CAP_MSMF,      # Microsoft Media Foundation
                cv2.CAP_ANY        # Herhangi bir backend
            ]
            
            self.video_capture = None
            for backend in backends_to_try:
                try:
                    self.video_capture = cv2.VideoCapture(self.video_path, backend)
                    if self.video_capture.isOpened():
                        self.log_message(f"Video backend: {backend}", "info")
                        break
                    else:
                        self.video_capture.release()
                        self.video_capture = None
                except Exception as e:
                    self.log_message(f"Backend {backend} hatasÄ±: {e}", "warning")
                    continue
            
            if not self.video_capture or not self.video_capture.isOpened():
                raise VideoLoadError(f"HiÃ§bir backend ile video aÃ§Ä±lamadÄ±: {file_path}")

            # Video Ã¶zelliklerini al
            fps = self.video_capture.get(cv2.CAP_PROP_FPS)
            total_frames = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(self.video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Video Ã¶zelliklerini doÄŸrula
            if fps <= 0 or total_frames <= 0 or width <= 0 or height <= 0:
                self.show_error_message(f"Video dosyasÄ± geÃ§ersiz bilgiler iÃ§eriyor:\nFPS: {fps}, Kareler: {total_frames}, Boyut: {width}x{height}")
                self._reset_for_new_video()
                self.video_path = None
                self.update_ui_state()
                return
                
            duration = total_frames / fps
            self.video_info = {
                'fps': fps, 
                'total_frames': total_frames, 
                'duration': duration,
                'width': width,
                'height': height
            }

            # Ä°lk frame'i test et
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, test_frame = self.video_capture.read()
            if not ret or test_frame is None:
                self.show_error_message("Video frame'leri okunamÄ±yor. Dosya bozuk olabilir.")
                self._reset_for_new_video()
                self.video_path = None
                self.update_ui_state()
                return
            
            # Frame formatÄ±nÄ± kontrol et
            if len(test_frame.shape) not in [2, 3]:
                self.show_error_message(f"Desteklenmeyen video formatÄ±: {test_frame.shape}")
                self._reset_for_new_video()
                self.video_path = None
                self.update_ui_state()
                return

            file_size_mb = os.path.getsize(self.video_path) / (1024 * 1024)
            self.info_label_original.setText(f"<b>Orijinal Video:</b> {self.format_duration(duration)} | {file_size_mb:.2f} MB | {width}x{height}")

            self.timeline_widget.set_duration(duration)
            
            # Ä°lk frame'i gÃ¶ster
            self.show_frame(0)
            
            # GÃ¼venlik kamerasÄ± tespiti ve otomatik ayar
            if config_manager.is_security_camera_file(self.video_path):
                self.log_message("ğŸ”’ GÃ¼venlik kamerasÄ± dosyasÄ± tespit edildi! Otomatik optimizasyon uygulanÄ±yor...", "info")
                self._apply_security_camera_settings()
            
            self.log_message(f"âœ… Video baÅŸarÄ±yla yÃ¼klendi: {os.path.basename(file_path)}", "success")
            self.log_message(f"   â€¢ Boyut: {width}x{height}", "info")
            self.log_message(f"   â€¢ SÃ¼re: {self.format_duration(duration)}", "info")
            self.log_message(f"   â€¢ FPS: {fps:.2f}", "info")
            self.log_message(f"   â€¢ Toplam Kare: {total_frames:,}", "info")
                
        except VideoLoadError as e:
            self.show_error_message(f"Video yÃ¼klenemedi: {e}")
            self.log_message(f"âŒ Video yÃ¼kleme hatasÄ±: {e}", "error")
            self._reset_for_new_video()
            self.video_path = None
        except Exception as e:
            self.show_error_message(f"Beklenmeyen hata: {e}")
            self.log_message(f"âŒ Beklenmeyen hata: {e}", "error")
            self._reset_for_new_video()
            self.video_path = None
        finally:
            self.update_ui_state()

    def _reset_for_new_video(self):
        if self.is_playing: self.toggle_playback()
        if self.video_capture: self.video_capture.release()
        self.detected_events = []
        self.detected_objects = {} # Yeni: Nesneleri de sÄ±fÄ±rla
        self.current_rotation = 0  # Video dÃ¶ndÃ¼rme sÄ±fÄ±rla
        self.info_label_summary.setText("<b>Ã–zet Video:</b> -")
        self.progress_bar.setValue(0)
        self.status_label.setText("Durum: HazÄ±r")
        self.timeline_widget.set_duration(0)
        self.timeline_widget.set_events([])
        self.timeline_widget.set_progress(0)
        self.video_display_label.setText("LÃ¼tfen bir video dosyasÄ± yÃ¼kleyin.")
        self.event_list_widget.clear() # Yeni: Olay listesini temizle

    def add_video_file(self):
        """Yeni video dosyasÄ± ekler."""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self, 
            "Video DosyalarÄ± SeÃ§", 
            "", 
            "TÃ¼m Video DosyalarÄ± (*.mp4 *.avi *.mkv *.mov *.wmv *.flv *.webm *.dav *.h264 *.264 *.ts *.m2ts *.mts);;"
            "Standart Videolar (*.mp4 *.avi *.mkv *.mov *.wmv);;"
            "GÃ¼venlik KamerasÄ± (*.dav *.h264 *.264 *.ts *.m2ts);;"
            "CanlÄ± YayÄ±n (*.flv *.webm *.ts);;"
            "TÃ¼m Dosyalar (*.*)"
        )
        
        for file_path in file_paths:
            if file_path and file_path not in self.video_paths:
                # Video tipini tespit et ve log'a yaz
                video_type = self.detect_video_type(file_path)
                type_names = {
                    "security_camera": "ğŸ”’ GÃ¼venlik KamerasÄ±",
                    "mobile_phone": "ğŸ“± Mobil Telefon", 
                    "drone": "ğŸš Drone",
                    "standard": "ğŸ¬ Standart Video"
                }
                
                self.video_paths.append(file_path)
                # Liste widget'Ä±na ekle
                filename = os.path.basename(file_path)
                type_icon = type_names.get(video_type, "ğŸ“¹")
                item_text = f"{type_icon} {filename}"
                self.video_list.addItem(item_text)
                
                # Ã–zel log mesajÄ±
                self.log_message(f"Video eklendi: {filename} ({type_names.get(video_type, 'Bilinmeyen tip')})", "success")
                
                # GÃ¼venlik kamerasÄ± ise Ã¶zel bilgi ver
                if video_type == "security_camera":
                    self.log_message("  ğŸ’¡ Ä°pucu: Bu dosya iÃ§in 'GÃœVENLÄ°K KAMERASI' hassasiyet seviyesi Ã¶nerilir", "info")
                self.video_paths.append(file_path)
                # Liste widget'Ä±na ekle
                item_text = f"ğŸ“¹ {os.path.basename(file_path)}"
                self.video_list.addItem(item_text)
                self.log_message(f"Video eklendi: {os.path.basename(file_path)}", "success")
        
        self.update_ui_state()
    
    def remove_video_file(self):
        """SeÃ§ili video dosyasÄ±nÄ± kaldÄ±rÄ±r."""
        current_row = self.video_list.currentRow()
        if current_row >= 0:
            removed_video = self.video_paths.pop(current_row)
            self.video_list.takeItem(current_row)
            self.log_message(f"Video kaldÄ±rÄ±ldÄ±: {os.path.basename(removed_video)}", "success")
            
            # EÄŸer ÅŸu anki video kaldÄ±rÄ±ldÄ±ysa
            if current_row == self.current_video_index:
                self.video_path = None
                self.video_capture = None
                self.current_video_index = 0
                self._reset_for_new_video()
            elif current_row < self.current_video_index:
                self.current_video_index -= 1
        
        self.update_ui_state()
    
    def clear_all_videos(self):
        """TÃ¼m video dosyalarÄ±nÄ± temizler."""
        self.video_paths.clear()
        self.video_list.clear()
        self.video_path = None
        self.video_capture = None
        self.current_video_index = 0
        self.detected_events.clear()
        self.detected_objects.clear()
        self._reset_for_new_video()
        self.update_ui_state()
        self.log_message("TÃ¼m videolar temizlendi.", "info")
    
    def on_video_selection_changed(self):
        """Video seÃ§imi deÄŸiÅŸtiÄŸinde Ã§aÄŸrÄ±lÄ±r."""
        current_row = self.video_list.currentRow()
        if current_row >= 0 and current_row < len(self.video_paths):
            self.current_video_index = current_row
            self.video_path = self.video_paths[current_row]
            self.load_selected_video()
    
    def load_selected_video(self):
        """SeÃ§ili videoyu yÃ¼kler."""
        if not self.video_path:
            return
        
        try:
            if self.video_capture:
                self.video_capture.release()
            
            self.video_capture = cv2.VideoCapture(self.video_path)
            if not self.video_capture.isOpened():
                self.log_message(f"âŒ Video aÃ§Ä±lamadÄ±: {os.path.basename(self.video_path)}", "error")
                return
            
            # Video bilgilerini al
            fps = self.video_capture.get(cv2.CAP_PROP_FPS)
            frame_count = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(self.video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            
            # Dosya boyutunu al
            file_size = os.path.getsize(self.video_path)
            file_size_mb = file_size / (1024 * 1024)
            
            self.video_info = {
                'fps': fps,
                'total_frames': frame_count,
                'width': width,
                'height': height,
                'duration': duration
            }
            
            # Video bilgi panelini gÃ¼ncelle
            video_name = os.path.basename(self.video_path)
            self.video_info_label.setText(
                f"ğŸ“¹ {video_name}\n"
                f"ğŸ“ {width}x{height} | â±ï¸ {duration:.1f}s | ğŸ’¾ {file_size_mb:.1f}MB"
            )
            
            # Timeline'Ä± gÃ¼ncelle
            self.timeline_widget.set_duration(duration)
            self.timeline_widget.set_events([])
            
            # Ä°lk kareyi gÃ¶ster
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = self.video_capture.read()
            if ret:
                self.display_cv_frame(frame, 0)
            
            # UI'Ä± gÃ¼ncelle
            self.update_ui_state()
            
            video_name = os.path.basename(self.video_path)
            self.log_message(f"Video yÃ¼klendi: {video_name} ({duration:.1f}s, {frame_count} kare)", "success")
            
        except Exception as e:
            self.log_message(f"Video yÃ¼kleme hatasÄ±: {str(e)}", "error")

    def update_active_classes(self):
        """Aktif sÄ±nÄ±flarÄ± gÃ¼ncelle"""
        self.ACTIVE_CLASSES = []
        for checkbox in self.object_checkboxes:
            if checkbox.isChecked():
                self.ACTIVE_CLASSES.append(checkbox.text())
        
        # EÄŸer hiÃ§ seÃ§ili deÄŸilse, varsayÄ±lan olarak person ekle
        if not self.ACTIVE_CLASSES:
            self.ACTIVE_CLASSES = ['person']
    
    def open_advanced_selection(self):
        """GeliÅŸmiÅŸ nesne seÃ§im dialogunu aÃ§"""
        dialog = AdvancedObjectSelectionDialog(self.TARGET_CLASSES, self.ACTIVE_CLASSES, self)
        if dialog.exec_() == QDialog.Accepted:
            selected_classes = dialog.get_selected_classes()
            if selected_classes:
                self.ACTIVE_CLASSES = selected_classes
                self.log_message(f"{len(selected_classes)} nesne tÃ¼rÃ¼ seÃ§ildi!", "success")
            else:
                self.ACTIVE_CLASSES = ['person']
                self.log_message("HiÃ§ nesne seÃ§ilmediÄŸi iÃ§in 'person' varsayÄ±lan olarak seÃ§ildi.", "info")

    def start_live_camera(self):
        """Live kamera baÅŸlatma"""
        try:
            # Kamera baÅŸlatma
            self.live_camera = cv2.VideoCapture(0)
            
            if not self.live_camera.isOpened():
                self.log_message("Kamera bulunamadÄ±!", "error")
                return
            
            # FPS ayarÄ±
            self.live_camera.set(cv2.CAP_PROP_FPS, 30)
            
            # Timer baÅŸlat
            self.live_timer = QTimer()
            self.live_timer.timeout.connect(self.update_live_camera_frame)
            self.live_timer.start(33)  # ~30 FPS
            
            # UI gÃ¼ncelle
            self.btn_start_camera.setEnabled(False)
            self.btn_stop_camera.setEnabled(True)
            self.live_detection_count = 0
            
            self.log_message("Kamera baÅŸlatÄ±ldÄ±!", "success")
            
        except Exception as e:
            self.log_error("Kamera baÅŸlatma hatasÄ±", e)
    
    def stop_live_camera(self):
        """Live kamera durdurma"""
        try:
            if hasattr(self, 'live_timer'):
                self.live_timer.stop()
            
            if hasattr(self, 'live_camera'):
                self.live_camera.release()
            
            # Video display'i temizle
            if hasattr(self, 'video_display_label'):
                self.video_display_label.setText("LÃ¼tfen bir video dosyasÄ± yÃ¼kleyin veya canlÄ± kamerayÄ± baÅŸlatÄ±n.")
            
            # UI gÃ¼ncelle
            self.btn_start_camera.setEnabled(True)
            self.btn_stop_camera.setEnabled(False)
            
            self.log_message("Kamera durduruldu!", "info")
            
        except Exception as e:
            self.log_message(f"Kamera durdurma hatasÄ±: {e}", "warning")
    
    def update_live_camera_frame(self):
        """Live kamera frame'ini gÃ¼ncelle"""
        try:
            if not hasattr(self, 'live_camera') or self.live_camera is None:
                return
                
            ret, frame = self.live_camera.read()
            
            if not ret:
                return
            
            # Nesne tespiti yap
            frame = self.detect_live_objects(frame)
            
            # Frame'i Qt formatÄ±na Ã§evir
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb_frame.shape
            bytes_per_line = ch * w
            qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            
            # Video display'de gÃ¶ster
            if hasattr(self, 'video_display_label'):
                pixmap = QPixmap.fromImage(qt_image)
                scaled_pixmap = pixmap.scaled(
                    self.video_display_label.size(), 
                    Qt.KeepAspectRatio, 
                    Qt.SmoothTransformation
                )
                self.video_display_label.setPixmap(scaled_pixmap)
            
        except Exception as e:
            self.log_message(f"Live frame gÃ¼ncelleme hatasÄ±: {e}", "warning")

    def detect_live_objects(self, frame):
        """Live kamera gÃ¶rÃ¼ntÃ¼sÃ¼nde nesne tespiti yap"""
        try:
            if self.model is None:
                return frame
                
            # YOLO modeli ile nesne tespiti
            results = self.model(frame)
            
            # Tespit edilen nesneleri Ã§iz
            annotated_frame = results[0].plot()
            
            # Aktif nesneleri say
            detected_count = 0
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        class_id = int(box.cls[0])
                        class_name = self.model.names[class_id]
                        if class_name in self.ACTIVE_CLASSES:
                            detected_count += 1
            
            # Count'u gÃ¼ncelle
            self.live_detection_count += detected_count
            if hasattr(self, 'status_label'):
                self.status_label.setText(f"ğŸ”´ AnlÄ±k Tespit: {detected_count} | Toplam: {self.live_detection_count}")
            
            return annotated_frame
            
        except Exception as e:
            self.log_message(f"Live detection error: {e}", "warning")
            return frame
            
        except Exception as e:
            self.log_error("Live detection error", e)
            return frame

    def analyze_video(self):
        """Ana video analiz fonksiyonu - buton tÄ±klamasÄ±nda Ã§aÄŸrÄ±lÄ±r"""
        if not self.video_paths and not self.video_path:
            QMessageBox.warning(self, "UyarÄ±", "LÃ¼tfen analiz edilecek video(lar) seÃ§in!")
            return
        
        # Analiz durumunu kontrol et
        if hasattr(self, 'processor_thread') and self.processor_thread and self.processor_thread.isRunning():
            self.stop_analysis()
        else:
            self.start_analysis()
    
    def stop_analysis(self):
        """Analizi durdurur"""
        if hasattr(self, 'processor_thread') and self.processor_thread:
            self.processor_thread.stop()
            self.processor_thread.wait(3000)  # 3 saniye bekle
            self.log_message("Analiz durduruldu", "warning")
        
        self.update_ui_state(is_analyzing=False)

    def start_analysis(self):
        # Ã‡oklu video desteÄŸi
        if self.video_paths:
            self.start_batch_analysis()
        elif self.video_path:
            self.start_single_analysis()
        else:
            self.log_message("âš ï¸ LÃ¼tfen analiz edilecek video(lar) seÃ§in.", "warning")
    
    def start_single_analysis(self):
        """Tek video analizi baÅŸlatÄ±r."""
        if not self.video_path: 
            return
        
        self.update_ui_state(is_analyzing=True)
        self.progress_bar.setValue(0)
        self.log_message(f"Analiz baÅŸlatÄ±lÄ±yor (Hassasiyet: {self.current_sensitivity})...", "info")
        
        self.processor_thread = VideoProcessor(self.video_path, self.current_sensitivity)
        self.processor_thread.progress_updated.connect(self.progress_bar.setValue)
        self.processor_thread.status_updated.connect(self.update_status)
        self.processor_thread.analysis_complete.connect(self.on_analysis_complete)
        self.processor_thread.error_occurred.connect(self.on_thread_error)
        self.processor_thread.start()
    
    def start_batch_analysis(self):
        """ğŸš€ ULTRA HIZLI Ã§oklu video analizi."""
        if not self.video_paths:
            return
        
        self.update_ui_state(is_analyzing=True)
        self.progress_bar.setValue(0)
        self.current_batch_index = 0
        self.batch_results = []
        
        total_videos = len(self.video_paths)
        self.log_message(f"ğŸš€ ULTRA HIZLI toplu analiz baÅŸlÄ±yor: {total_videos} video (Hassasiyet: {self.current_sensitivity})", "success")
        
        # Paralel iÅŸlem desteÄŸi
        if MULTIPROCESSING_ENABLED and total_videos > 1:
            self.log_message("âš¡ Paralel iÅŸlem modu aktif", "info")
        
        self.analyze_next_video()
    
    def analyze_next_video(self):
        """ğŸ¯ Toplu analizde sÄ±radaki videoyu ULTRA HIZLI analiz eder."""
        if self.current_batch_index >= len(self.video_paths):
            self.on_batch_analysis_complete()
            return
        
        current_video = self.video_paths[self.current_batch_index]
        video_name = os.path.basename(current_video)
        
        # Dosya boyutu bilgisi
        try:
            file_size = os.path.getsize(current_video) / (1024 * 1024)  # MB
            self.log_message(f"âš¡ Analiz [{self.current_batch_index + 1}/{len(self.video_paths)}]: {video_name} ({file_size:.1f} MB)", "info")
        except:
            self.log_message(f"âš¡ Analiz [{self.current_batch_index + 1}/{len(self.video_paths)}]: {video_name}", "info")
        
        self.processor_thread = VideoProcessor(current_video, self.current_sensitivity)
        self.processor_thread.progress_updated.connect(self.on_batch_progress_updated)
        self.processor_thread.analysis_complete.connect(self.on_batch_video_complete)
        self.processor_thread.error_occurred.connect(self.on_batch_error)
        self.processor_thread.start()
    
    def on_batch_progress_updated(self, progress):
        """Toplu analiz ilerlemesini gÃ¼nceller."""
        total_progress = (self.current_batch_index * 100 + progress) / len(self.video_paths)
        self.progress_bar.setValue(int(total_progress))
    
    def on_batch_video_complete(self, detected_objects, events, video_info):
        """Toplu analizde bir video tamamlandÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r."""
        video_path = self.video_paths[self.current_batch_index]
        video_name = os.path.basename(video_path)
        
        # SonuÃ§larÄ± sakla
        result = {
            'video_path': video_path,
            'video_name': video_name,
            'detected_objects': detected_objects,
            'events': events,
            'video_info': video_info,
            'event_count': len(events),
            'detection_count': len(detected_objects)
        }
        self.batch_results.append(result)
        
        event_count = len(events)
        detection_count = len(detected_objects)
        self.log_message(f"âœ… TamamlandÄ±: {video_name} ({event_count} olay, {detection_count} tespit)", "success")
        
        self.current_batch_index += 1
        self.analyze_next_video()
    
    def on_batch_error(self, error_msg):
        """Toplu analizde hata oluÅŸtuÄŸunda Ã§aÄŸrÄ±lÄ±r."""
        video_path = self.video_paths[self.current_batch_index]
        video_name = os.path.basename(video_path)
        
        self.log_message(f"âŒ Hata: {video_name} - {error_msg}", "error")
        
        self.current_batch_index += 1
        self.analyze_next_video()
    
    def on_batch_analysis_complete(self):
        """Toplu analiz tamamlandÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r."""
        self.update_ui_state(is_analyzing=False)
        
        total_videos = len(self.batch_results)
        total_events = sum(result['event_count'] for result in self.batch_results)
        total_detections = sum(result['detection_count'] for result in self.batch_results)
        
        self.log_message(f"ğŸ‰ Toplu analiz tamamlandÄ±! {total_videos} video, {total_events} olay, {total_detections} tespit", "success")
        
        # SonuÃ§larÄ± birleÅŸtir veya Ã¶zet gÃ¶ster
        self.show_batch_results_summary()
    
    def show_batch_results_summary(self):
        """Toplu analiz sonuÃ§larÄ±nÄ±n Ã¶zetini gÃ¶sterir."""
        if not hasattr(self, 'batch_results') or not self.batch_results:
            return
        
        # Event listesini temizle ve toplu sonuÃ§larÄ± ekle
        self.event_list_widget.clear()
        
        for result in self.batch_results:
            video_name = result['video_name']
            event_count = result['event_count']
            detection_count = result['detection_count']
            
            item_text = f"ğŸ“¹ {video_name} | {event_count} olay | {detection_count} tespit"
            item = QListWidgetItem(item_text)
            item.setData(Qt.UserRole, result)  # Sonucu item'a baÄŸla
            self.event_list_widget.addItem(item)

    @pyqtSlot(dict, list, dict)
    def on_analysis_complete(self, detected_objects, events, video_info):
        # detected_objects'in doÄŸru tipte olduÄŸunu kontrol et
        if isinstance(detected_objects, dict):
            self.detected_objects = detected_objects
        else:
            print(f"UYARI: detected_objects list olarak geldi: {type(detected_objects)}")
            # List'i dict'e dÃ¶nÃ¼ÅŸtÃ¼r
            converted_objects = {}
            for i, obj in enumerate(detected_objects):
                if isinstance(obj, dict):
                    converted_objects[i] = [obj]
                else:
                    converted_objects[i] = obj
            self.detected_objects = converted_objects
            
        self.detected_events = events
        self.video_info = video_info
        self.timeline_widget.set_events(events)
        
        msg = f"âœ… Analiz tamamlandÄ±. {len(events)} olay bulundu."
        self.log_message(msg, "success" if events else "warning")
        
        self.event_list_widget.clear()
        if events:
            for i, (start, end) in enumerate(events):
                log_msg = f"Olay {i+1}: {self.format_duration(start)} - {self.format_duration(end)}"
                self.log_message(f"  {log_msg}", "info")
                # Listeye tÄ±klanabilir Ã¶ÄŸe ekle
                item = QListWidgetItem(log_msg)
                item.setData(Qt.UserRole, start) # BaÅŸlangÄ±Ã§ zamanÄ±nÄ± sakla
                self.event_list_widget.addItem(item)
        
        self.update_status(msg)
        self.update_ui_state()

    @pyqtSlot()
    def export_video(self):
        if not self.detected_events:
            self.show_error_message("DÄ±ÅŸa aktarÄ±lacak olay bulunamadÄ±.")
            return

        output_path, _ = QFileDialog.getSaveFileName(self, "Ã–zet Videoyu Kaydet", "V.E.R.A_Ã–zet.mp4", "MP4 DosyasÄ± (*.mp4)")
        if not output_path: return

        self.update_ui_state(is_exporting=True)
        self.progress_bar.setValue(0)
        self.log_message("Ã–zet video oluÅŸturuluyor...", "info")

        self.exporter_thread = VideoExporter(self.video_path, self.detected_events, self.video_info, output_path)
        self.exporter_thread.export_progress.connect(self.on_export_progress)
        self.exporter_thread.export_complete.connect(self.on_export_complete)
        self.exporter_thread.error_occurred.connect(self.on_thread_error)
        self.exporter_thread.start()

    @pyqtSlot(int, str)
    def on_export_progress(self, value, message):
        self.progress_bar.setValue(value)
        self.update_status(message)

    @pyqtSlot(str, str)
    def on_export_complete(self, path, message):
        self.log_message(message, "success")
        self.update_status("Ã–zet video oluÅŸturuldu.")
        self.update_ui_state()
        
        try:
            summary_size_mb = os.path.getsize(path) / (1024 * 1024)
            summary_cap = cv2.VideoCapture(path)
            s_fps = summary_cap.get(cv2.CAP_PROP_FPS)
            s_frames = summary_cap.get(cv2.CAP_PROP_FRAME_COUNT)
            summary_duration = s_frames / s_fps if s_fps > 0 else 0
            summary_cap.release()
            self.info_label_summary.setText(f"<b>Ã–zet Video:</b> {self.format_duration(summary_duration)} | {summary_size_mb:.2f} MB")
        except Exception as e:
            self.log_message(f"Ã–zet video bilgileri okunamadÄ±: {e}", "error")

        reply = QMessageBox.question(self, 'BaÅŸarÄ±lÄ±', "Ã–zet video oluÅŸturuldu. DosyayÄ± aÃ§mak ister misiniz?", QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
        if reply == QMessageBox.Yes:
            from PyQt5.QtGui import QDesktopServices
            QDesktopServices.openUrl(QUrl.fromLocalFile(path))

    @pyqtSlot(str)
    def on_thread_error(self, error_message):
        self.show_error_message(error_message)
        self.update_status("Bir hata oluÅŸtu. Detaylar iÃ§in iÅŸlem geÃ§miÅŸine bakÄ±n.")
        self.update_ui_state()

    @pyqtSlot()
    def toggle_playback(self):
        if not self.video_capture: return
        self.is_playing = not self.is_playing
        if self.is_playing:
            self.btn_play_pause.setIcon(self.style().standardIcon(QStyle.SP_MediaPause))
            self.playback_timer.start(int(1000 / self.video_info.get('fps', 30)))
        else:
            self.btn_play_pause.setIcon(self.style().standardIcon(QStyle.SP_MediaPlay))
            self.playback_timer.stop()

    @pyqtSlot()
    def update_frame(self):
        if not self.video_capture or not self.is_playing:
            return
            
        if not self.video_capture.isOpened():
            self.log_message("Video capture kapalÄ± - oynatma durduruluyor", "warning")
            self.is_playing = False
            self.playback_timer.stop()
            return
            
        try:
            ret, frame = self.video_capture.read()
            if ret and frame is not None:
                current_frame_num = int(self.video_capture.get(cv2.CAP_PROP_POS_FRAMES))
                self.display_cv_frame(frame, current_frame_num)
                
                # Timeline progress gÃ¼ncelle
                total_frames = self.video_info.get('total_frames', 1)
                if total_frames > 0:
                    self.timeline_widget.set_progress(current_frame_num / total_frames)
            else:
                # Video sonu - oynatmayÄ± durdur
                self.is_playing = False
                self.playback_timer.stop()
                self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
                self.btn_play_pause.setIcon(self.style().standardIcon(QStyle.SP_MediaPlay))
                self.timeline_widget.set_progress(0)
                self.log_message("Video sonu - oynatma durduruldu", "info")
                
        except Exception as e:
            self.log_message(f"Frame update hatasÄ±: {e}", "error")
            self.is_playing = False
            self.playback_timer.stop()

    @pyqtSlot(float)
    def seek_video(self, time_sec):
        if self.video_capture:
            frame_num = int(time_sec * self.video_info.get('fps', 30))
            self.show_frame(frame_num)
            if self.is_playing:
                self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)

    def show_frame(self, frame_number):
        if not self.video_capture or not self.video_capture.isOpened():
            self.log_message("Video capture nesnesi kullanÄ±lamÄ±yor", "warning")
            return
            
        try:
            # Frame numarasÄ±nÄ± sÄ±nÄ±rlar iÃ§inde tut
            max_frames = self.video_info.get('total_frames', 0)
            frame_number = max(0, min(frame_number, max_frames - 1))
            
            # Frame pozisyonunu ayarla
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            ret, frame = self.video_capture.read()
            
            if ret and frame is not None:
                self.display_cv_frame(frame, frame_number)
                # Timeline progress gÃ¼ncelle
                if max_frames > 0:
                    self.timeline_widget.set_progress(frame_number / max_frames)
            else:
                self.log_message(f"Frame {frame_number} okunamadÄ±", "warning")
                # Hata durumunda varsayÄ±lan mesaj gÃ¶ster
                self.video_display_label.setText(f"Frame {frame_number} gÃ¶rÃ¼ntÃ¼lenemiyor")
                
        except Exception as e:
            self.log_message(f"Frame gÃ¶sterme hatasÄ±: {e}", "error")
            self.video_display_label.setText("Video frame hatasÄ±")

    def rotate_video(self, rotation):
        """Video dÃ¶ndÃ¼rme fonksiyonu"""
        self.current_rotation = rotation
        self.log_message(f"Video dÃ¶ndÃ¼rme: {rotation}Â°", "info")
        
        # Åu anki frame'i tekrar gÃ¶ster
        if self.video_capture:
            current_frame = int(self.video_capture.get(cv2.CAP_PROP_POS_FRAMES))
            self.show_frame(current_frame)
    
    def apply_rotation(self, frame, rotation):
        """Frame'e dÃ¶ndÃ¼rme uygular"""
        if rotation == 0:
            return frame
        elif rotation == 90:
            return cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        elif rotation == 180:
            return cv2.rotate(frame, cv2.ROTATE_180)
        elif rotation == 270:
            return cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        else:
            return frame

    def adjust_coordinates_for_rotation(self, x, y, w, h, rotation, frame_shape):
        """DÃ¶ndÃ¼rme iÃ§in koordinatlarÄ± ayarlar"""
        if rotation == 0:
            return x, y, w, h
        
        original_height, original_width = frame_shape[:2]
        
        if rotation == 90:
            # 90Â° saat yÃ¶nÃ¼nde: (x,y) -> (y, width-x-w)
            new_x = y
            new_y = original_width - x - w
            new_w = h
            new_h = w
        elif rotation == 180:
            # 180Â°: (x,y) -> (width-x-w, height-y-h)
            new_x = original_width - x - w
            new_y = original_height - y - h
            new_w = w
            new_h = h
        elif rotation == 270:
            # 270Â° saat yÃ¶nÃ¼nde: (x,y) -> (height-y-h, x)
            new_x = original_height - y - h
            new_y = x
            new_w = h
            new_h = w
        else:
            return x, y, w, h
        
        return new_x, new_y, new_w, new_h

    def enhance_frame_quality(self, frame):
        """Frame kalitesini iyileÅŸtir - Ã¶zellikle gÃ¼venlik kamerasÄ± videolarÄ± iÃ§in"""
        try:
            if frame is None or frame.size == 0:
                return frame
            
            # Frame'in ortalama parlaklÄ±ÄŸÄ±nÄ± kontrol et
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            mean_brightness = np.mean(gray)
            
            # DÃ¼ÅŸÃ¼k Ä±ÅŸÄ±k koÅŸullarÄ± iÃ§in iyileÅŸtirme (ortalama parlaklÄ±k < 80)
            if mean_brightness < 80:
                # Histogram eÅŸitleme uygula
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                
                # Her kanal iÃ§in ayrÄ± ayrÄ± iyileÅŸtir
                if len(frame.shape) == 3:
                    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                    lab[:,:,0] = clahe.apply(lab[:,:,0])
                    frame = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
                else:
                    frame = clahe.apply(frame)
            
            # Ã‡ok koyu veya Ã§ok parlak videolarÄ± ayarla
            if mean_brightness < 50:  # Ã‡ok koyu
                frame = cv2.convertScaleAbs(frame, alpha=1.3, beta=20)
            elif mean_brightness > 200:  # Ã‡ok parlak
                frame = cv2.convertScaleAbs(frame, alpha=0.9, beta=-10)
            
            return frame
            
        except Exception as e:
            self.log_message(f"Frame kalitesi iyileÅŸtirme hatasÄ±: {e}", "warning")
            return frame
    
    def display_cv_frame(self, frame, frame_number):
        try:
            # Frame'in geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            if frame is None or frame.size == 0:
                self.log_message("GeÃ§ersiz frame - boÅŸ veri", "warning")
                return
            
            # Frame'in boyutlarÄ±nÄ± kontrol et
            if len(frame.shape) != 3 or frame.shape[2] != 3:
                self.log_message(f"GeÃ§ersiz frame formatÄ±: {frame.shape}", "warning")
                return
            
            # Frame kalitesini iyileÅŸtir (Ã¶zellikle gÃ¼venlik kamerasÄ± videolarÄ± iÃ§in)
            frame = self.enhance_frame_quality(frame)
            
            # DÃ¶ndÃ¼rme uygula
            if self.current_rotation != 0:
                frame = self.apply_rotation(frame, self.current_rotation)
            
            # O anki karede tespit edilen nesne varsa kutu Ã§iz
            if frame_number in self.detected_objects:
                for i, (x, y, w, h) in enumerate(self.detected_objects[frame_number]):
                    # DÃ¶ndÃ¼rme durumuna gÃ¶re koordinatlarÄ± ayarla
                    if self.current_rotation != 0:
                        x, y, w, h = self.adjust_coordinates_for_rotation(x, y, w, h, self.current_rotation, frame.shape)
                    
                    # KoordinatlarÄ± frame sÄ±nÄ±rlarÄ± iÃ§inde tut
                    x = max(0, min(x, frame.shape[1] - 1))
                    y = max(0, min(y, frame.shape[0] - 1))
                    w = max(1, min(w, frame.shape[1] - x))
                    h = max(1, min(h, frame.shape[0] - y))
                    
                    # YeÅŸil Ã§erÃ§eve Ã§iz
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
                    
                    # Nesne numarasÄ± ve "PERSON" etiketi ekle
                    label = f"PERSON {i+1}"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                    
                    # Etiket arka planÄ±
                    cv2.rectangle(frame, (x, y - label_size[1] - 10), 
                                 (x + label_size[0] + 10, y), (0, 255, 0), -1)
                    
                    # Etiket metni
                    cv2.putText(frame, label, (x + 5, y - 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
                    
                    # Merkez noktasÄ± iÅŸaretle
                    center_x = x + w // 2
                    center_y = y + h // 2
                    cv2.circle(frame, (center_x, center_y), 5, (0, 255, 0), -1)

            # Frame'i gÃ¼venli bir ÅŸekilde RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r
            try:
                # BGR'den RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r (OpenCV BGR formatÄ±nda yÃ¼kler)
                if len(frame.shape) == 3 and frame.shape[2] == 3:
                    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                else:
                    # Gri renk veya diÄŸer formatlar iÃ§in
                    if len(frame.shape) == 2:
                        rgb_image = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
                    else:
                        rgb_image = frame.copy()
                
                # QImage oluÅŸtur
                h, w, ch = rgb_image.shape
                bytes_per_line = ch * w
                qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
                
                # QImage'Ä±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                if qt_image.isNull():
                    self.log_message("QImage oluÅŸturulamadÄ±", "warning")
                    return
                
                # Pixmap oluÅŸtur ve gÃ¶ster
                pixmap = QPixmap.fromImage(qt_image)
                if not pixmap.isNull():
                    # Video gÃ¶rÃ¼ntÃ¼ alanÄ±nÄ±n boyutuna uygun olarak Ã¶lÃ§eklendir
                    label_size = self.video_display_label.size()
                    scaled_pixmap = pixmap.scaled(label_size, Qt.KeepAspectRatio, Qt.SmoothTransformation)
                    self.video_display_label.setPixmap(scaled_pixmap)
                else:
                    self.log_message("Pixmap oluÅŸturulamadÄ±", "warning")
                    
            except Exception as color_error:
                self.log_message(f"Renk dÃ¶nÃ¼ÅŸÃ¼mÃ¼ hatasÄ±: {color_error}", "error")
                # Hata durumunda frame'i doÄŸrudan gÃ¶stermeyi dene
                try:
                    h, w = frame.shape[:2]
                    if len(frame.shape) == 3:
                        ch = frame.shape[2]
                        bytes_per_line = ch * w
                        qt_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
                    else:
                        bytes_per_line = w
                        qt_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_Grayscale8)
                    
                    if not qt_image.isNull():
                        pixmap = QPixmap.fromImage(qt_image)
                        if not pixmap.isNull():
                            label_size = self.video_display_label.size()
                            scaled_pixmap = pixmap.scaled(label_size, Qt.KeepAspectRatio, Qt.SmoothTransformation)
                            self.video_display_label.setPixmap(scaled_pixmap)
                except Exception as backup_error:
                    self.log_message(f"Yedek gÃ¶rÃ¼ntÃ¼leme hatasÄ±: {backup_error}", "error")
                
        except Exception as e:
            self.log_message(f"Frame gÃ¶rÃ¼ntÃ¼leme genel hatasÄ±: {str(e)}", "error")

    @pyqtSlot(QListWidgetItem)
    def on_event_item_clicked(self, item):
        """Olay listesindeki bir Ã¶ÄŸeye tÄ±klandÄ±ÄŸÄ±nda videoyu o ana sarar."""
        start_time = item.data(Qt.UserRole)
        if start_time is not None:
            self.seek_video(start_time)

    @pyqtSlot(QAbstractButton)
    def sensitivity_changed(self, button):
        self.current_sensitivity = button.text()
        self.log_message(f"Hassasiyet seviyesi deÄŸiÅŸtirildi: {self.current_sensitivity}", "info")

    @pyqtSlot()
    def export_excel_report(self):
        """Excel raporu dÄ±ÅŸa aktarÄ±r."""
        if not self.detected_events:
            self.show_error_message("Rapor oluÅŸturmak iÃ§in Ã¶nce analiz yapmalÄ±sÄ±nÄ±z.")
            return

        output_path, _ = QFileDialog.getSaveFileName(
            self, "Excel Raporu Kaydet", 
            f"V.E.R.A_Rapor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", 
            "Excel DosyasÄ± (*.xlsx)"
        )
        if not output_path:
            return

        try:
            self.log_message("Excel raporu oluÅŸturuluyor...", "info")
            
            # Excel dosyasÄ± oluÅŸtur
            import xlsxwriter
            
            workbook = xlsxwriter.Workbook(output_path)
            worksheet = workbook.add_worksheet('Analiz Raporu')
            
            # Formatlar
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#3498db',
                'font_color': 'white',
                'align': 'center'
            })
            
            cell_format = workbook.add_format({
                'align': 'center',
                'border': 1
            })
            
            # BaÅŸlÄ±klar
            worksheet.write(0, 0, 'Olay No', header_format)
            worksheet.write(0, 1, 'Zaman', header_format)
            worksheet.write(0, 2, 'Tespit Tipi', header_format)
            worksheet.write(0, 3, 'GÃ¼ven OranÄ±', header_format)
            worksheet.write(0, 4, 'Koordinatlar', header_format)
            
            # Verileri yaz
            for i, event in enumerate(self.detected_events):
                worksheet.write(i + 1, 0, i + 1, cell_format)
                
                # Event'in tuple mi yoksa dict mi olduÄŸunu kontrol et
                if isinstance(event, tuple) and len(event) >= 2:
                    # Tuple formatÄ±: (baÅŸlangÄ±Ã§, bitiÅŸ)
                    start_time, end_time = event[0], event[1]
                    worksheet.write(i + 1, 1, f"{self.format_duration(start_time)} - {self.format_duration(end_time)}", cell_format)
                    worksheet.write(i + 1, 2, 'Hareket Tespiti', cell_format)
                    worksheet.write(i + 1, 3, "100%", cell_format)
                    worksheet.write(i + 1, 4, '-', cell_format)
                elif isinstance(event, dict):
                    # Dictionary formatÄ±
                    worksheet.write(i + 1, 1, event.get('time', ''), cell_format)
                    worksheet.write(i + 1, 2, event.get('type', 'Ä°nsan Tespiti'), cell_format)
                    worksheet.write(i + 1, 3, f"{event.get('confidence', 0.0):.2f}", cell_format)
                    
                    # KoordinatlarÄ± formatla
                    if 'coordinates' in event:
                        coords = event['coordinates']
                        coord_str = f"({coords.get('x', 0)}, {coords.get('y', 0)}, {coords.get('w', 0)}, {coords.get('h', 0)})"
                        worksheet.write(i + 1, 4, coord_str, cell_format)
                    else:
                        worksheet.write(i + 1, 4, '-', cell_format)
                else:
                    # Bilinmeyen format
                    worksheet.write(i + 1, 1, str(event), cell_format)
                    worksheet.write(i + 1, 2, 'Tespit', cell_format)
                    worksheet.write(i + 1, 3, "N/A", cell_format)
                    worksheet.write(i + 1, 4, '-', cell_format)
            
            # SÃ¼tun geniÅŸliklerini ayarla
            worksheet.set_column(0, 0, 10)
            worksheet.set_column(1, 1, 20)
            worksheet.set_column(2, 2, 15)
            worksheet.set_column(3, 3, 12)
            worksheet.set_column(4, 4, 25)
            
            workbook.close()
            
            self.log_message("âœ… Excel raporu baÅŸarÄ±yla oluÅŸturuldu!", "success")
            
            reply = QMessageBox.question(
                self, 'BaÅŸarÄ±lÄ±', 
                "Excel raporu oluÅŸturuldu. DosyayÄ± aÃ§mak ister misiniz?", 
                QMessageBox.Yes | QMessageBox.No, QMessageBox.No
            )
            if reply == QMessageBox.Yes:
                from PyQt5.QtGui import QDesktopServices
                QDesktopServices.openUrl(QUrl.fromLocalFile(output_path))
                
        except ImportError:
            self.show_error_message("Excel raporu iÃ§in xlsxwriter kÃ¼tÃ¼phanesi gerekli. 'pip install xlsxwriter' komutu ile yÃ¼kleyin.")
        except Exception as e:
            self.show_error_message(f"Excel raporu oluÅŸturma hatasÄ±: {e}")

    @pyqtSlot()
    def export_charts_report(self):
        """Grafik raporu dÄ±ÅŸa aktarÄ±r."""
        if not self.detected_events:
            self.show_error_message("Rapor oluÅŸturmak iÃ§in Ã¶nce analiz yapmalÄ±sÄ±nÄ±z.")
            return

        output_dir = QFileDialog.getExistingDirectory(
            self, "Grafik Raporu KlasÃ¶rÃ¼ SeÃ§", 
            os.path.expanduser("~/Desktop")
        )
        if not output_dir:
            return

        # Rapor klasÃ¶rÃ¼ oluÅŸtur
        report_folder = os.path.join(output_dir, f"V.E.R.A_Grafik_Raporu_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        os.makedirs(report_folder, exist_ok=True)

        try:
            self.log_message("Grafik raporu oluÅŸturuluyor...", "info")
            
            # detected_objects'in doÄŸru formatta olduÄŸunu kontrol et
            if isinstance(self.detected_objects, list):
                # List'i dict'e dÃ¶nÃ¼ÅŸtÃ¼r
                converted_objects = {}
                for i, obj in enumerate(self.detected_objects):
                    converted_objects[i] = [obj] if isinstance(obj, dict) else obj
                detected_objects = converted_objects
            else:
                detected_objects = self.detected_objects
                
            report_gen = ReportGenerator(
                self.video_path, self.detected_events, detected_objects, 
                self.video_info, self.current_sensitivity
            )
            
            if report_gen.generate_charts(report_folder):
                # Ã–zet metin dosyasÄ± da oluÅŸtur
                summary_path = os.path.join(report_folder, "analiz_ozeti.txt")
                with open(summary_path, 'w', encoding='utf-8') as f:
                    f.write("V.E.R.A. - Video Analiz Ã–zeti\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Video: {os.path.basename(self.video_path)}\n")
                    f.write(f"Analiz Tarihi: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
                    f.write(f"Hassasiyet: {self.current_sensitivity}\n")
                    f.write(f"Video SÃ¼resi: {self.format_duration(self.video_info['duration'])}\n")
                    f.write(f"Toplam Olay: {len(self.detected_events)}\n")
                    f.write(f"Toplam Tespit: {len(self.detected_objects)}\n\n")
                    
                    if self.detected_events:
                        total_duration = sum([end - start for start, end in self.detected_events])
                        f.write(f"Toplam Olay SÃ¼resi: {self.format_duration(total_duration)}\n")
                        f.write(f"Olay YoÄŸunluÄŸu: {(total_duration / self.video_info['duration'] * 100):.1f}%\n\n")
                        
                        f.write("DetaylÄ± Olaylar:\n")
                        f.write("-" * 30 + "\n")
                        for i, (start, end) in enumerate(self.detected_events, 1):
                            f.write(f"Olay {i}: {self.format_duration(start)} - {self.format_duration(end)} ({end-start:.1f}s)\n")
                
                self.log_message(f"Grafik raporu baÅŸarÄ±yla oluÅŸturuldu: {report_folder}", "success")
                
                reply = QMessageBox.question(
                    self, 'BaÅŸarÄ±lÄ±', 
                    "Grafik raporu oluÅŸturuldu. KlasÃ¶rÃ¼ aÃ§mak ister misiniz?", 
                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No
                )
                if reply == QMessageBox.Yes:
                    from PyQt5.QtGui import QDesktopServices
                    QDesktopServices.openUrl(QUrl.fromLocalFile(report_folder))
            else:
                self.show_error_message("Grafik raporu oluÅŸturulamadÄ±. matplotlib kÃ¼tÃ¼phanesi yÃ¼klÃ¼ mÃ¼?")
                
        except Exception as e:
            self.show_error_message(f"Grafik raporu oluÅŸturma hatasÄ±: {e}")

    @pyqtSlot()
    def export_word_report(self):
        """Word raporu dÄ±ÅŸa aktarÄ±r - hareket tespiti gÃ¶rselleri ile."""
        if not self.detected_events:
            self.show_error_message("Rapor oluÅŸturmak iÃ§in Ã¶nce analiz yapmalÄ±sÄ±nÄ±z.")
            return

        output_path, _ = QFileDialog.getSaveFileName(
            self, "Word Raporu Kaydet", 
            f"V.E.R.A_Rapor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx", 
            "Word DosyasÄ± (*.docx)"
        )
        if not output_path:
            return

        try:
            self.log_message("Word raporu oluÅŸturuluyor (hareket tespiti gÃ¶rselleri ile)...", "info")
            
            # Word belgesini oluÅŸtur
            if not DOCX_AVAILABLE:
                self.show_error_message("Word desteÄŸi yok! 'pip install python-docx' Ã§alÄ±ÅŸtÄ±rÄ±n")
                return
            
            # GeÃ§ici klasÃ¶r oluÅŸtur ve hareket tespiti gÃ¶rsellerini kaydet
            temp_dir = os.path.join(os.path.dirname(output_path), "temp_word_images")
            os.makedirs(temp_dir, exist_ok=True)
            
            self.log_message("Hareket tespiti gÃ¶rselleri oluÅŸturuluyor...", "info")
            saved_images = self._save_detection_frames(temp_dir)
            
            doc = Document()
            
            # BaÅŸlÄ±k ekle
            doc.add_heading('M.SAVAÅ Video Analiz Raporu', 0)
            
            # Genel bilgiler
            doc.add_heading('Genel Bilgiler', level=1)
            p = doc.add_paragraph()
            p.add_run('Rapor Tarihi: ').bold = True
            p.add_run(datetime.now().strftime('%d.%m.%Y %H:%M:%S'))
            
            p = doc.add_paragraph()
            p.add_run('Video DosyasÄ±: ').bold = True
            p.add_run(os.path.basename(self.video_path) if self.video_path else '-')
            
            p = doc.add_paragraph()
            p.add_run('Hassasiyet Seviyesi: ').bold = True
            p.add_run(self.current_sensitivity)
            
            p = doc.add_paragraph()
            p.add_run('Toplam Tespit: ').bold = True
            p.add_run(str(len(self.detected_events)))
            
            # Video bilgileri
            if self.video_info:
                doc.add_heading('Video Ã–zellikleri', level=1)
                p = doc.add_paragraph()
                p.add_run('SÃ¼re: ').bold = True
                p.add_run(self.format_duration(self.video_info.get('duration', 0)))
                
                p = doc.add_paragraph()
                p.add_run('FPS: ').bold = True
                p.add_run(f"{self.video_info.get('fps', 0):.2f}")
                
                p = doc.add_paragraph()
                p.add_run('Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: ').bold = True
                p.add_run(f"{self.video_info.get('width', 0)}x{self.video_info.get('height', 0)}")
            
            # Tespit edilen olaylar
            if self.detected_events:
                doc.add_heading('Tespit Edilen Olaylar', level=1)
                
                # Tablo oluÅŸtur
                table = doc.add_table(rows=1, cols=4)
                table.style = 'Light Grid Accent 1'
                
                # BaÅŸlÄ±k satÄ±rÄ±
                hdr_cells = table.rows[0].cells
                hdr_cells[0].text = 'Olay No'
                hdr_cells[1].text = 'Zaman'
                hdr_cells[2].text = 'Tespit Tipi'
                hdr_cells[3].text = 'GÃ¼ven OranÄ±'
                
                # Verileri ekle
                for i, event in enumerate(self.detected_events):
                    row_cells = table.add_row().cells
                    row_cells[0].text = str(i + 1)
                    
                    # Event'in tuple mi yoksa dict mi olduÄŸunu kontrol et
                    if isinstance(event, tuple) and len(event) >= 2:
                        # Tuple formatÄ±: (baÅŸlangÄ±Ã§, bitiÅŸ)
                        start_time, end_time = event[0], event[1]
                        row_cells[1].text = f"{self.format_duration(start_time)} - {self.format_duration(end_time)}"
                        row_cells[2].text = 'Hareket Tespiti'
                        row_cells[3].text = "100%"
                    elif isinstance(event, dict):
                        # Dictionary formatÄ±
                        row_cells[1].text = event.get('time', '')
                        row_cells[2].text = event.get('type', 'Ä°nsan Tespiti')
                        row_cells[3].text = f"{event.get('confidence', 0.0):.2f}"
                    else:
                        # Bilinmeyen format
                        row_cells[1].text = str(event)
                        row_cells[2].text = 'Tespit'
                        row_cells[3].text = "N/A"
            
            # Hareket tespiti gÃ¶rselleri ekleme
            if saved_images:
                doc.add_page_break()
                doc.add_heading('ğŸ¯ Hareket Tespiti GÃ¶rselleri', level=1)
                
                doc.add_paragraph('AÅŸaÄŸÄ±da videoda tespit edilen hareketlerin karÅŸÄ±laÅŸtÄ±rmalÄ± gÃ¶rÃ¼ntÃ¼leri yer almaktadÄ±r. '
                                 'Sol tarafta orijinal gÃ¶rÃ¼ntÃ¼, saÄŸ tarafta hareket tespiti uygulanmÄ±ÅŸ hali gÃ¶sterilmektedir.')
                
                self.log_message(f"Word raporuna {len(saved_images)} gÃ¶rsel ekleniyor...", "info")
                
                for i, img_info in enumerate(saved_images):
                    # Debug: gÃ¶rsel dosya bilgilerini logla
                    self.log_message(f"GÃ¶rsel {i+1}: {img_info.get('path', 'N/A')}", "info")
                    self.log_message(f"Orijinal {i+1}: {img_info.get('original_path', 'N/A')}", "info")
                    
                    # Dosya varlÄ±ÄŸÄ±nÄ± kontrol et
                    original_exists = os.path.exists(img_info.get('original_path', ''))
                    detection_exists = os.path.exists(img_info.get('path', ''))
                    self.log_message(f"Dosya kontrolÃ¼ {i+1}: Orijinal={original_exists}, Tespit={detection_exists}", "info")
                    
                    # Her gÃ¶rsel iÃ§in baÅŸlÄ±k
                    time_str = self.format_duration(img_info['time'])
                    doc.add_heading(f"Tespit {i+1}: {time_str} ({img_info['detections']} kiÅŸi)", level=2)
                    
                    # Basit yaklaÅŸÄ±m: Her gÃ¶rseli ayrÄ± ayrÄ± ekle (tablo yerine)
                    try:
                        # Orijinal gÃ¶rÃ¼ntÃ¼ baÅŸlÄ±ÄŸÄ± ve gÃ¶rseli
                        doc.add_paragraph("ğŸ“· Orijinal GÃ¶rÃ¼ntÃ¼:", style='Intense Quote')
                        if original_exists:
                            original_para = doc.add_paragraph()
                            original_run = original_para.add_run()
                            original_run.add_picture(img_info['original_path'], width=Inches(4))
                            self.log_message(f"âœ… Orijinal gÃ¶rsel {i+1} eklendi", "success")
                        else:
                            doc.add_paragraph("âŒ Orijinal gÃ¶rsel dosyasÄ± bulunamadÄ±")
                            self.log_message(f"âŒ Orijinal gÃ¶rsel {i+1} dosyasÄ± yok", "error")
                        
                        # Tespit gÃ¶rseli baÅŸlÄ±ÄŸÄ± ve gÃ¶rseli  
                        doc.add_paragraph("ğŸ¯ Hareket Tespiti:", style='Intense Quote')
                        if detection_exists:
                            detection_para = doc.add_paragraph()
                            detection_run = detection_para.add_run()
                            detection_run.add_picture(img_info['path'], width=Inches(4))
                            self.log_message(f"âœ… Tespit gÃ¶rseli {i+1} eklendi", "success")
                        else:
                            doc.add_paragraph("âŒ Tespit gÃ¶rsel dosyasÄ± bulunamadÄ±")
                            self.log_message(f"âŒ Tespit gÃ¶rseli {i+1} dosyasÄ± yok", "error")
                            
                    except Exception as e:
                        self.log_message(f"âŒ GÃ¶rsel {i+1} ekleme hatasÄ±: {str(e)}", "error")
                        # Hata durumunda da bilgi ver
                        doc.add_paragraph(f"GÃ¶rsel {i+1} eklenirken hata oluÅŸtu: {str(e)}")
                    
                    # AyÄ±rÄ±cÄ± ekle
                    if i < len(saved_images) - 1:
                        doc.add_paragraph("â”€" * 50)
                        doc.add_paragraph()
                
                self.log_message(f"âœ… {len(saved_images)} hareket tespiti gÃ¶rseli iÅŸlendi", "success")
            else:
                self.log_message("âš ï¸ KaydedilmiÅŸ gÃ¶rsel bulunamadÄ±", "warning")
            
            # Belgeyi kaydet
            doc.save(output_path)
            
            # GeÃ§ici dosyalarÄ± temizle
            try:
                import shutil
                shutil.rmtree(temp_dir)
                self.log_message("GeÃ§ici dosyalar temizlendi", "info")
            except Exception as e:
                self.log_message(f"GeÃ§ici dosya temizleme hatasÄ±: {e}", "warning")
            
            self.log_message("âœ… Word raporu baÅŸarÄ±yla oluÅŸturuldu!", "success")
            
            reply = QMessageBox.question(
                self, 'BaÅŸarÄ±lÄ±', 
                "Word raporu oluÅŸturuldu. DosyayÄ± aÃ§mak ister misiniz?", 
                QMessageBox.Yes | QMessageBox.No, QMessageBox.No
            )
            if reply == QMessageBox.Yes:
                from PyQt5.QtGui import QDesktopServices
                QDesktopServices.openUrl(QUrl.fromLocalFile(output_path))
                
        except ImportError:
            self.show_error_message("Word raporu iÃ§in python-docx kÃ¼tÃ¼phanesi gerekli. 'pip install python-docx' komutu ile yÃ¼kleyin.")
        except Exception as e:
            self.show_error_message(f"Word raporu oluÅŸturma hatasÄ±: {e}")
            self.log_message(f"Word raporu hatasÄ±: {str(e)}", "error")

    @pyqtSlot()
    def export_all_reports(self):
        """TÃ¼m raporlarÄ± tek seferde oluÅŸturur."""
        if not self.detected_events:
            self.show_error_message("Rapor oluÅŸturmak iÃ§in Ã¶nce analiz yapmalÄ±sÄ±nÄ±z.")
            return

        # KlasÃ¶r seÃ§
        output_dir = QFileDialog.getExistingDirectory(
            self, "TÃ¼m Raporlar KlasÃ¶rÃ¼ SeÃ§", 
            os.path.expanduser("~/Desktop")
        )
        if not output_dir:
            return

        # Rapor klasÃ¶rÃ¼ oluÅŸtur
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_folder = os.path.join(output_dir, f"M.SAVAS_Tum_Raporlar_{timestamp}")
        os.makedirs(report_folder, exist_ok=True)

        try:
            self.log_message("ğŸ¯ TÃ¼m raporlar oluÅŸturuluyor...", "info")
            
            # detected_objects'in doÄŸru formatta olduÄŸunu kontrol et
            if isinstance(self.detected_objects, list):
                # List'i dict'e dÃ¶nÃ¼ÅŸtÃ¼r
                converted_objects = {}
                for i, obj in enumerate(self.detected_objects):
                    converted_objects[i] = [obj] if isinstance(obj, dict) else obj
                detected_objects = converted_objects
            else:
                detected_objects = self.detected_objects
            
            # Rapor generator
            report_gen = ReportGenerator(
                self.video_path, self.detected_events, detected_objects, 
                self.video_info, self.current_sensitivity
            )
            
            reports_created = []
            
            # 1. Excel Raporu
            excel_path = os.path.join(report_folder, f"Excel_Rapor_{timestamp}.xlsx")
            if report_gen.generate_excel_report(excel_path):
                reports_created.append("ğŸ“ˆ Excel Raporu")
                self.log_message("âœ… Excel raporu oluÅŸturuldu", "success")
            
            # 2. Word Raporu
            word_path = os.path.join(report_folder, f"Word_Rapor_{timestamp}.docx")
            temp_dir = os.path.join(report_folder, "temp_images")
            os.makedirs(temp_dir, exist_ok=True)
            saved_images = self._save_detection_frames(temp_dir)
            
            if report_gen.generate_word_report(word_path, saved_images):
                reports_created.append("ğŸ“„ Word Raporu")
                self.log_message("âœ… Word raporu oluÅŸturuldu", "success")
            
            # 3. Grafik Raporu
            chart_folder = os.path.join(report_folder, "Grafik_Raporu")
            os.makedirs(chart_folder, exist_ok=True)
            
            if report_gen.generate_charts(chart_folder):
                reports_created.append("ğŸ“Š Grafik Raporu")
                self.log_message("âœ… Grafik raporu oluÅŸturuldu", "success")
            
            # 4. Ã–zet dosyasÄ± oluÅŸtur
            summary_path = os.path.join(report_folder, "Rapor_Ozeti.txt")
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("M.SAVAÅ - KapsamlÄ± Rapor Paketi\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"OluÅŸturulma Tarihi: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
                f.write(f"Video: {os.path.basename(self.video_path)}\n")
                f.write(f"Hassasiyet: {self.current_sensitivity}\n")
                f.write(f"Toplam Olay: {len(self.detected_events)}\n")
                f.write(f"Toplam Tespit: {len(self.detected_objects)}\n\n")
                f.write("OluÅŸturulan Raporlar:\n")
                f.write("-" * 30 + "\n")
                for report in reports_created:
                    f.write(f"âœ… {report}\n")
                f.write(f"\nToplam {len(reports_created)} rapor baÅŸarÄ±yla oluÅŸturuldu.\n")
            
            # GeÃ§ici dosyalarÄ± temizle
            try:
                shutil.rmtree(temp_dir)
            except:
                pass
            
            self.log_message(f"ğŸ‰ TÃ¼m raporlar oluÅŸturuldu: {len(reports_created)} rapor", "success")
            
            # BaÅŸarÄ± mesajÄ±
            reply = QMessageBox.question(
                self, 'BaÅŸarÄ±lÄ±', 
                f"TÃ¼m raporlar oluÅŸturuldu!\n\n"
                f"OluÅŸturulan raporlar:\n" + "\n".join(reports_created) + 
                f"\n\nKlasÃ¶rÃ¼ aÃ§mak ister misiniz?", 
                QMessageBox.Yes | QMessageBox.No, QMessageBox.No
            )
            if reply == QMessageBox.Yes:
                from PyQt5.QtGui import QDesktopServices
                QDesktopServices.openUrl(QUrl.fromLocalFile(report_folder))
                
        except Exception as e:
            self.show_error_message(f"Toplu rapor oluÅŸturma hatasÄ±: {e}")

    def _save_detection_frames(self, temp_dir: str) -> list:
        """Tespit edilen kareleri resim olarak kaydeder - her saniye iÃ§in detaylÄ±."""
        saved_images = []
        
        if not self.video_capture or not self.detected_objects:
            print("âŒ Video capture veya detected_objects bulunamadÄ±")
            return saved_images

        print(f"ğŸ¯ GÃ¶rsel kaydetme baÅŸlÄ±yor: {len(self.detected_objects)} tespit karesi var")
        print(f"ğŸ“ Hedef klasÃ¶r: {temp_dir}")
        
        try:
            # TÃ¼m tespit edilen kareleri al
            detection_frames = list(self.detected_objects.keys())
            fps = self.video_info.get('fps', 30)
            
            print(f"ğŸ“Š FPS: {fps}, Tespit kareleri: {len(detection_frames)}")
            
            # Her saniye iÃ§in en az bir gÃ¶rÃ¼ntÃ¼ olsun
            second_based_frames = {}
            for frame_num in detection_frames:
                second = int(frame_num / fps)
                if second not in second_based_frames:
                    second_based_frames[second] = []
                second_based_frames[second].append(frame_num)
            
            print(f"ğŸ“ˆ {len(second_based_frames)} farklÄ± saniyede tespit var")            # Her saniye iÃ§in en iyi kareler
            selected_frames = []
            for second in sorted(second_based_frames.keys()):
                frames_in_second = second_based_frames[second]
                # En Ã§ok tespit iÃ§eren kareyi seÃ§
                best_frame = max(frames_in_second, key=lambda f: len(self.detected_objects[f]))
                selected_frames.append(best_frame)
            
            # Maksimum 30 gÃ¶rÃ¼ntÃ¼ ile sÄ±nÄ±rla (Ã§ok uzun olmasÄ±n)
            if len(selected_frames) > 30:
                step = len(selected_frames) // 30
                selected_frames = selected_frames[::step]
            
            for i, frame_num in enumerate(selected_frames):
                # Kareyi oku
                self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = self.video_capture.read()
                
                if ret:
                    # Orijinal frame'i de kaydet (karÅŸÄ±laÅŸtÄ±rma iÃ§in)
                    original_frame = frame.copy()
                    
                    # DÃ¶ndÃ¼rme uygula (Word raporunda da aynÄ± gÃ¶rÃ¼nsÃ¼n)
                    if hasattr(self, 'current_rotation') and self.current_rotation != 0:
                        frame = self.apply_rotation(frame, self.current_rotation)
                    
                    # Tespit kutularÄ±nÄ± Ã§iz (dÃ¶ndÃ¼rme sonrasÄ± koordinatlara gÃ¶re)
                    detection_count = 0
                    for j, (x, y, w, h) in enumerate(self.detected_objects[frame_num]):
                        # KoordinatlarÄ± dÃ¶ndÃ¼rmeye gÃ¶re ayarla
                        if hasattr(self, 'current_rotation') and self.current_rotation != 0:
                            adjusted_coords = self.adjust_coordinates_for_rotation(x, y, w, h, self.current_rotation, frame.shape)
                            x, y, w, h = adjusted_coords
                        
                        # YeÅŸil Ã§erÃ§eve (kalÄ±n)
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 4)
                        
                        # Etiket arka planÄ±
                        label = f"PERSON {j+1}"
                        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
                        cv2.rectangle(frame, (x, y - label_size[1] - 15), 
                                     (x + label_size[0] + 10, y - 5), (0, 255, 0), -1)
                        
                        # Etiket metni
                        cv2.putText(frame, label, (x + 5, y - 10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
                        
                        # Merkez noktasÄ± (daha bÃ¼yÃ¼k)
                        cv2.circle(frame, (x + w // 2, y + h // 2), 8, (0, 255, 0), -1)
                        cv2.circle(frame, (x + w // 2, y + h // 2), 12, (0, 255, 0), 2)
                        
                        detection_count += 1
                    
                    # Zaman ve tespit bilgisi
                    time_sec = frame_num / fps
                    time_text = f"Zaman: {self.format_duration(time_sec)}"
                    detection_text = f"Tespit: {detection_count} kisi"
                    frame_text = f"Kare: {frame_num}"
                    
                    # Bilgi kutusu arka planÄ±
                    info_height = 100
                    cv2.rectangle(frame, (10, 10), (400, info_height), (0, 0, 0), -1)
                    cv2.rectangle(frame, (10, 10), (400, info_height), (255, 255, 255), 2)
                    
                    # Bilgi metinleri
                    cv2.putText(frame, time_text, (20, 35), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                    cv2.putText(frame, detection_text, (20, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                    cv2.putText(frame, frame_text, (20, 85), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
                    
                    # Resmi kaydet - hata kontrolÃ¼ ile
                    image_path = os.path.join(temp_dir, f"tespit_{i+1:03d}.jpg")
                    success1 = cv2.imwrite(image_path, frame)
                    
                    # Orijinal karÅŸÄ±laÅŸtÄ±rma iÃ§in
                    if hasattr(self, 'current_rotation') and self.current_rotation != 0:
                        original_frame = self.apply_rotation(original_frame, self.current_rotation)
                    
                    original_path = os.path.join(temp_dir, f"orijinal_{i+1:03d}.jpg")
                    success2 = cv2.imwrite(original_path, original_frame)
                    
                    # Dosya kaydetme kontrolÃ¼
                    if success1 and success2 and os.path.exists(image_path) and os.path.exists(original_path):
                        saved_images.append({
                            'path': image_path,
                            'original_path': original_path,
                            'frame': frame_num,
                            'time': time_sec,
                            'detections': detection_count,
                            'second': int(time_sec)
                        })
                        print(f"âœ… GÃ¶rsel {i+1} kaydedildi: {image_path}")
                    else:
                        print(f"âŒ GÃ¶rsel {i+1} kaydedilemedi - CV2 write baÅŸarÄ±sÄ±z")
                else:
                    print(f"âŒ Frame {frame_num} okunamadÄ±")
                    
        except Exception as e:
            print(f"âŒ GÃ¶rsel kaydetme hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"âœ… Toplam {len(saved_images)} gÃ¶rsel kaydedildi")
        return saved_images

    @pyqtSlot(str)
    def update_status(self, message):
        self.status_label.setText(f"Durum: {message}")

    def log_message(self, message: str, level: str = "info"):
        """GeliÅŸmiÅŸ log mesajÄ± - renk kodlamasÄ± ve otomatik kaydÄ±rma"""
        color_map = {
            "info": "#ecf0f1", 
            "success": "#2ecc71", 
            "warning": "#f39c12", 
            "error": "#e74c3c"
        }
        
        # Emoji haritasÄ±
        emoji_map = {
            "info": "â„¹ï¸",
            "success": "âœ…", 
            "warning": "âš ï¸",
            "error": "âŒ"
        }
        
        color = color_map.get(level, "#ecf0f1")
        emoji = emoji_map.get(level, "ğŸ“")
        timestamp = QTime.currentTime().toString("HH:mm:ss")
        
        # HTML formatÄ±nda mesaj oluÅŸtur
        formatted_message = f'<font color="{color}"><b>[{timestamp}]</b> {emoji} {message}</font>'
        self.log_display.append(formatted_message)
        
        # Otomatik kaydÄ±rma - en alta git
        scrollbar = self.log_display.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())
        
        # Ã‡ok fazla log varsa eski mesajlarÄ± temizle (performans iÃ§in)
        if self.log_display.document().blockCount() > 1000:
            cursor = self.log_display.textCursor()
            cursor.movePosition(cursor.Start)
            cursor.movePosition(cursor.Down, cursor.KeepAnchor, 100)
            cursor.removeSelectedText()

    def show_error_message(self, message: str):
        self.log_message(message, "error")
        QMessageBox.critical(self, "Hata", message)

    def format_duration(self, seconds: float) -> str:
        """SÃ¼reyi HH:MM:SS formatÄ±nda dÃ¶ndÃ¼rÃ¼r."""
        if seconds is None or math.isnan(seconds): 
            return "00:00:00"
        h, m, s = int(seconds // 3600), int((seconds % 3600) // 60), int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"

    def closeEvent(self, event):
        """Uygulama kapatÄ±lÄ±rken temizlik iÅŸlemleri yapar"""
        try:
            self.log_message("ğŸ”„ Uygulama kapatÄ±lÄ±yor, temizlik iÅŸlemleri yapÄ±lÄ±yor...", "info")
            
            # Thread'leri gÃ¼venli ÅŸekilde durdur
            if hasattr(self, 'processor_thread') and self.processor_thread and self.processor_thread.isRunning():
                self.log_message("ğŸ›‘ Ä°ÅŸlem thread'i durduruluyor...", "info")
                self.processor_thread.request_stop()
                self.processor_thread.wait(3000)  # 3 saniye bekle
                if self.processor_thread.isRunning():
                    self.processor_thread.terminate()
                    
            if hasattr(self, 'exporter_thread') and self.exporter_thread and self.exporter_thread.isRunning():
                self.log_message("ğŸ“¤ Export thread'i durduruluyor...", "info")
                self.exporter_thread.wait(3000)
                if self.exporter_thread.isRunning():
                    self.exporter_thread.terminate()
            
            # Live camera'yÄ± durdur
            if hasattr(self, 'live_timer') and self.live_timer.isActive():
                self.live_timer.stop()
                
            if hasattr(self, 'live_camera') and self.live_camera:
                self.live_camera.release()
                
            # Video capture'Ä± serbest bÄ±rak
            if hasattr(self, 'video_capture') and self.video_capture:
                self.video_capture.release()
                
            # Playback timer'Ä± durdur
            if hasattr(self, 'playback_timer') and self.playback_timer.isActive():
                self.playback_timer.stop()
                
            self.log_message("âœ… Temizlik iÅŸlemleri tamamlandÄ±. GÃ¼le gÃ¼le!", "success")
            
        except Exception as e:
            print(f"Kapatma hatasÄ±: {e}")
            
        finally:
            event.accept()

    def get_stylesheet(self) -> str:
        return """
            QMainWindow, QWidget {
                background-color: #2b3e50; color: #ecf0f1; font-family: 'Segoe UI', Arial;
            }
            QGroupBox {
                background-color: #34495e; border: 2px solid #3498db;
                border-radius: 10px; margin-top: 8px; padding: 8px;
                font-weight: bold; color: #ecf0f1;
            }
            QGroupBox::title {
                subcontrol-origin: margin; subcontrol-position: top left;
                padding: 2px 8px; left: 8px; color: #3498db; font-size: 14px; font-weight: bold;
                background-color: #2b3e50; border-radius: 4px;
            }
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #3498db, stop:1 #2980b9);
                color: white; border: 1px solid #2980b9;
                border-radius: 6px; padding: 4px 8px; font-size: 11px; font-weight: bold;
                text-align: center;
            }
            QPushButton:hover { 
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #3cb4f0, stop:1 #3498db);
                border: 1px solid #3498db;
            }
            QPushButton:pressed { 
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #2980b9, stop:1 #1f618d);
                border: 1px solid #1f618d;
            }
            QPushButton:disabled { 
                background-color: #7f8c8d; color: #bdc3c7; border: 1px solid #95a5a6;
            }
            
            /* Analiz butonlarÄ± iÃ§in Ã¶zel stil */
            QPushButton[text*="Analiz"] {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #27ae60, stop:1 #229954);
                border: 1px solid #229954; font-weight: bold;
            }
            QPushButton[text*="Analiz"]:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #2ecc71, stop:1 #27ae60);
                border: 1px solid #27ae60;
            }
            
            /* Video dÃ¶ndÃ¼rme butonlarÄ± iÃ§in Ã¶zel stil */
            QPushButton[text*="Â°"], QPushButton[text*="SÄ±fÄ±rla"] {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #e74c3c, stop:1 #c0392b);
                border: 1px solid #c0392b; font-weight: bold;
            }
            QPushButton[text*="Â°"]:hover, QPushButton[text*="SÄ±fÄ±rla"]:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #ec7063, stop:1 #e74c3c);
                border: 1px solid #e74c3c;
            }
            
            QLabel { 
                color: #ecf0f1; font-size: 13px; padding: 2px;
            }
            #videoDisplay { 
                border: 3px solid #3498db; border-radius: 8px; 
                background-color: #2c3e50;
            }
            QProgressBar {
                border: 2px solid #34495e; border-radius: 8px; text-align: center;
                font-size: 12px; color: white; background-color: #2c3e50; height: 20px;
            }
            QProgressBar::chunk { 
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0, stop:0 #27ae60, stop:1 #2ecc71);
                border-radius: 6px; 
            }
            QTextEdit {
                background-color: #2c3e50; color: #ecf0f1; border: 2px solid #34495e;
                border-radius: 6px; font-family: 'Consolas', 'Courier New', monospace; 
                font-size: 11px; selection-background-color: #3498db;
            }
            QRadioButton { 
                font-size: 12px; padding: 3px; color: #ecf0f1; font-weight: bold;
            }
            QRadioButton::indicator {
                width: 16px; height: 16px;
            }
            QRadioButton::indicator:unchecked {
                border: 2px solid #7f8c8d; border-radius: 8px; background-color: #34495e;
            }
            QRadioButton::indicator:checked {
                border: 2px solid #3498db; border-radius: 8px; background-color: #3498db;
            }
            QListWidget {
                background-color: #2c3e50; color: #ecf0f1; border: 2px solid #34495e;
                border-radius: 6px; font-size: 12px; selection-background-color: #3498db;
            }
            QListWidget::item {
                padding: 6px; border-bottom: 1px solid #34495e;
            }
            QListWidget::item:hover {
                background-color: #34495e; color: #ecf0f1;
            }
            QListWidget::item:selected {
                background-color: #3498db; color: white; font-weight: bold;
            }
        """

# =============================================================================
# --- RAPOR OLUÅTURUCU ---
# =============================================================================

class ReportGenerator:
    def generate_dav_report(self, output_path: str) -> bool:
        """DAV formatÄ±nda (JSON tabanlÄ±) analiz raporu oluÅŸturur."""
        try:
            import json
            dav_data = {
                "video_file": os.path.basename(self.video_path),
                "analysis_date": self.analysis_date.strftime('%Y-%m-%d %H:%M:%S'),
                "sensitivity": self.sensitivity,
                "duration": self.video_info.get('duration', 0),
                "fps": self.video_info.get('fps', 0),
                "total_frames": self.video_info.get('total_frames', 0),
                "events": [],
            }
            # OlaylarÄ± ekle
            for idx, (start, end) in enumerate(self.events):
                event = {
                    "event_id": idx + 1,
                    "start_time": start,
                    "end_time": end,
                    "duration": end - start,
                    "detections": []
                }
                # Bu olay sÃ¼resindeki tespitleri ekle
                for frame_num, detections in self.detected_objects.items():
                    frame_time = frame_num / self.video_info.get('fps', 1)
                    if start <= frame_time <= end:
                        for det in detections:
                            event["detections"].append({
                                "frame": int(frame_num),
                                "time": frame_time,
                                "box": det.get('box', []),
                                "confidence": det.get('conf', 0),
                                "area": det.get('area', 0)
                            })
                dav_data["events"].append(event)
            # Dosyaya yaz
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(dav_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"DAV raporu oluÅŸturma hatasÄ±: {e}")
            return False
    """GeliÅŸmiÅŸ raporlama sistemi - Excel ve grafik Ã§Ä±ktÄ±larÄ±."""
    
    def __init__(self, video_path: str, events: list, detected_objects: dict, video_info: dict, sensitivity: str):
        self.video_path = video_path
        self.events = events
        
        # detected_objects'in doÄŸru tipte olduÄŸunu kontrol et
        if isinstance(detected_objects, dict):
            self.detected_objects = detected_objects
        else:
            print(f"ReportGenerator: detected_objects list olarak geldi: {type(detected_objects)}")
            # List'i dict'e dÃ¶nÃ¼ÅŸtÃ¼r
            converted_objects = {}
            for i, obj in enumerate(detected_objects):
                if isinstance(obj, dict):
                    converted_objects[i] = [obj]
                else:
                    converted_objects[i] = obj
            self.detected_objects = converted_objects
            
        self.video_info = video_info
        self.sensitivity = sensitivity
        self.analysis_date = datetime.now()
    
    def format_duration(self, seconds: float) -> str:
        """SÃ¼reyi HH:MM:SS formatÄ±nda dÃ¶ndÃ¼rÃ¼r."""
        if seconds is None or (isinstance(seconds, float) and math.isnan(seconds)): 
            return "00:00:00"
        try:
            h, m, s = int(seconds // 3600), int((seconds % 3600) // 60), int(seconds % 60)
            return f"{h:02d}:{m:02d}:{s:02d}"
        except:
            return "00:00:00"
    
    def generate_excel_report(self, output_path: str) -> bool:
        """Excel raporu oluÅŸturur - geliÅŸmiÅŸ grafikler ile."""
        try:
            try:
                import xlsxwriter
            except ImportError:
                print("xlsxwriter kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil!")
                print("LÃ¼tfen 'pip install xlsxwriter' Ã§alÄ±ÅŸtÄ±rÄ±n")
                return False
            
            # Debug: Veri tiplerini kontrol et
            print(f"detected_objects tipi: {type(self.detected_objects)}")
            print(f"detected_objects iÃ§eriÄŸi: {self.detected_objects}")
            
            # detected_objects'in doÄŸru formatta olduÄŸunu kontrol et
            if isinstance(self.detected_objects, list):
                print("detected_objects list olarak geldi, dict'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
                # List'i dict'e dÃ¶nÃ¼ÅŸtÃ¼r
                converted_objects = {}
                for i, obj in enumerate(self.detected_objects):
                    if isinstance(obj, dict):
                        converted_objects[i] = [obj]
                    else:
                        converted_objects[i] = obj
                self.detected_objects = converted_objects
                print(f"DÃ¶nÃ¼ÅŸtÃ¼rÃ¼len detected_objects: {self.detected_objects}")
            
            # Excel dosyasÄ±nÄ± oluÅŸtur
            workbook = xlsxwriter.Workbook(output_path)
            
            # Genel bilgiler sayfasÄ±
            overview_sheet = workbook.add_worksheet('Genel Bilgiler')
            
            # FormatlarÄ± tanÄ±mla
            header_format = workbook.add_format({
                'bold': True,
                'font_size': 16,
                'align': 'center',
                'valign': 'vcenter',
                'bg_color': '#1ABC9C',
                'font_color': 'white',
                'border': 1
            })
            
            title_format = workbook.add_format({
                'bold': True,
                'font_size': 14,
                'align': 'center',
                'valign': 'vcenter',
                'bg_color': '#3498DB',
                'font_color': 'white',
                'border': 1
            })
            
            data_format = workbook.add_format({
                'font_size': 12,
                'align': 'left',
                'valign': 'vcenter',
                'border': 1
            })
            
            number_format = workbook.add_format({
                'font_size': 12,
                'align': 'center',
                'valign': 'vcenter',
                'border': 1,
                'num_format': '#,##0'
            })
            
            # BaÅŸlÄ±k
            overview_sheet.merge_range('A1:F1', 'M.SAVAÅ - VÄ°DEO ANALÄ°Z RAPORU', header_format)
            overview_sheet.set_row(0, 25)
            
            # Genel bilgiler - gÃ¼venli eriÅŸim
            overview_sheet.write('A3', 'Video DosyasÄ±:', title_format)
            overview_sheet.write('B3', os.path.basename(self.video_path), data_format)
            overview_sheet.write('A4', 'Analiz Tarihi:', title_format)
            overview_sheet.write('B4', self.analysis_date.strftime('%d.%m.%Y %H:%M:%S'), data_format)
            overview_sheet.write('A5', 'Video SÃ¼resi:', title_format)
            
            # Video sÃ¼resini gÃ¼venli ÅŸekilde al
            duration = self.video_info.get('duration', 0)
            overview_sheet.write('B5', self.format_duration(duration), data_format)
            
            overview_sheet.write('A6', 'Toplam Kare:', title_format)
            total_frames = self.video_info.get('total_frames', 0)
            overview_sheet.write('B6', int(total_frames), number_format)
            
            # Tespit istatistikleri
            overview_sheet.write('A8', 'Tespit Ä°statistikleri:', title_format)
            overview_sheet.write('A9', 'Toplam Tespit:', title_format)
            overview_sheet.write('B9', len(self.detected_objects), number_format)
            overview_sheet.write('A10', 'Olay SayÄ±sÄ±:', title_format)
            overview_sheet.write('B10', len(self.events), number_format)
            
            if self.events and duration > 0:
                total_event_duration = sum([end - start for start, end in self.events])
                overview_sheet.write('A11', 'Toplam Olay SÃ¼resi:', title_format)
                overview_sheet.write('B11', self.format_duration(total_event_duration), data_format)
                
                coverage_percentage = (total_event_duration / duration) * 100
                overview_sheet.write('A12', 'Video KapsamÄ±:', title_format)
                overview_sheet.write('B12', f"{coverage_percentage:.1f}%", data_format)
            
            # Tespit edilen nesneler sayfasÄ±
            detections_sheet = workbook.add_worksheet('Tespit DetaylarÄ±')
            
            # BaÅŸlÄ±k
            detections_sheet.merge_range('A1:F1', 'TESPIT EDÄ°LEN NESNELER DETAYLI', header_format)
            detections_sheet.set_row(0, 25)
            
            # Tablo baÅŸlÄ±klarÄ±
            headers = ['Kare No', 'Zaman (sn)', 'Nesne Tipi', 'GÃ¼ven Skoru', 'Konum (X,Y)', 'Boyut (W,H)']
            for col, header in enumerate(headers):
                detections_sheet.write(2, col, header, title_format)
            
            # Tespit verilerini yaz
            row = 3
            fps = self.video_info.get('fps', 30)  # VarsayÄ±lan FPS
            
            # detected_objects'in dict olduÄŸunu kontrol et
            if isinstance(self.detected_objects, dict):
                for frame_num, detections in self.detected_objects.items():
                    time_sec = frame_num / fps
                    # detections bir liste olabilir, kontrol edelim
                    if isinstance(detections, list):
                        for detection in detections:
                            detections_sheet.write(row, 0, frame_num, number_format)
                            detections_sheet.write(row, 1, f"{time_sec:.2f}", data_format)
                            
                            # detection dict mi liste mi kontrol et
                            if isinstance(detection, dict):
                                detections_sheet.write(row, 2, detection.get('class', 'person'), data_format)
                                detections_sheet.write(row, 3, f"{detection.get('confidence', 0):.2f}", data_format)
                                detections_sheet.write(row, 4, f"({detection.get('x', 0)}, {detection.get('y', 0)})", data_format)
                                detections_sheet.write(row, 5, f"{detection.get('width', 0)}x{detection.get('height', 0)}", data_format)
                            else:
                                # detection [x, y, w, h] formatÄ±nda
                                detections_sheet.write(row, 2, 'person', data_format)
                                detections_sheet.write(row, 3, '0.90', data_format)
                                if len(detection) >= 4:
                                    detections_sheet.write(row, 4, f"({detection[0]}, {detection[1]})", data_format)
                                    detections_sheet.write(row, 5, f"{detection[2]}x{detection[3]}", data_format)
                                else:
                                    detections_sheet.write(row, 4, "N/A", data_format)
                                    detections_sheet.write(row, 5, "N/A", data_format)
                            row += 1
                    else:
                        # detections doÄŸrudan bir detection objesi
                        detections_sheet.write(row, 0, frame_num, number_format)
                        detections_sheet.write(row, 1, f"{time_sec:.2f}", data_format)
                        
                        if isinstance(detections, dict):
                            detections_sheet.write(row, 2, detections.get('class', 'person'), data_format)
                            detections_sheet.write(row, 3, f"{detections.get('confidence', 0):.2f}", data_format)
                            detections_sheet.write(row, 4, f"({detections.get('x', 0)}, {detections.get('y', 0)})", data_format)
                            detections_sheet.write(row, 5, f"{detections.get('width', 0)}x{detections.get('height', 0)}", data_format)
                        else:
                            # detections [x, y, w, h] formatÄ±nda
                            detections_sheet.write(row, 2, 'person', data_format)
                            detections_sheet.write(row, 3, '0.90', data_format)
                            if len(detections) >= 4:
                                detections_sheet.write(row, 4, f"({detections[0]}, {detections[1]})", data_format)
                                detections_sheet.write(row, 5, f"{detections[2]}x{detections[3]}", data_format)
                            else:
                                detections_sheet.write(row, 4, "N/A", data_format)
                                detections_sheet.write(row, 5, "N/A", data_format)
                        row += 1
            else:
                # EÄŸer list ise dict'e dÃ¶nÃ¼ÅŸtÃ¼r
                print(f"detected_objects list olarak geldi: {type(self.detected_objects)}")
                for i, detection in enumerate(self.detected_objects):
                    detections_sheet.write(row, 0, i, number_format)
                    detections_sheet.write(row, 1, f"{i/fps:.2f}", data_format)
                    detections_sheet.write(row, 2, detection.get('class', 'person'), data_format)
                    detections_sheet.write(row, 3, f"{detection.get('confidence', 0):.2f}", data_format)
                    detections_sheet.write(row, 4, f"({detection.get('x', 0)}, {detection.get('y', 0)})", data_format)
                    detections_sheet.write(row, 5, f"{detection.get('width', 0)}x{detection.get('height', 0)}", data_format)
                    row += 1
            
            # Grafik sayfasÄ± oluÅŸtur
            if self.detected_objects:
                chart_sheet = workbook.add_worksheet('Grafikler')
                
                # Zaman serisi grafiÄŸi iÃ§in veri hazÄ±rla
                time_series = {}
                if isinstance(self.detected_objects, dict):
                    for frame_num, detections in self.detected_objects.items():
                        time_sec = int(frame_num / fps)
                        # detections bir liste mi kontrol et
                        if isinstance(detections, list):
                            time_series[time_sec] = time_series.get(time_sec, 0) + len(detections)
                        else:
                            time_series[time_sec] = time_series.get(time_sec, 0) + 1
                else:
                    # List ise basit iÅŸlem
                    for i, detection in enumerate(self.detected_objects):
                        time_sec = int(i / fps)
                        time_series[time_sec] = time_series.get(time_sec, 0) + 1
                
                # Grafik verilerini yaz
                chart_sheet.write('A1', 'Saniye', title_format)
                chart_sheet.write('B1', 'Tespit SayÄ±sÄ±', title_format)
                
                row = 2
                for time_sec in sorted(time_series.keys()):
                    chart_sheet.write(row, 0, time_sec, number_format)
                    chart_sheet.write(row, 1, time_series[time_sec], number_format)
                    row += 1
                
                # Ã‡izgi grafik oluÅŸtur
                if row > 2:
                    line_chart = workbook.add_chart({'type': 'line'})
                    line_chart.add_series({
                        'name': 'Tespit SayÄ±sÄ±',
                        'categories': ['Grafikler', 2, 0, row-1, 0],
                        'values': ['Grafikler', 2, 1, row-1, 1],
                        'line': {'color': '#1ABC9C', 'width': 2}
                    })
                    line_chart.set_title({'name': 'Zaman Ä°Ã§inde Tespit SayÄ±sÄ±'})
                    line_chart.set_x_axis({'name': 'Saniye'})
                    line_chart.set_y_axis({'name': 'Tespit SayÄ±sÄ±'})
                    chart_sheet.insert_chart('D2', line_chart)
                
                # Olay sÃ¼releri iÃ§in pasta grafiÄŸi
                if self.events:
                    # Olay sÃ¼relerine gÃ¶re kategoriler
                    duration_categories = {'KÄ±sa (0-5s)': 0, 'Orta (5-15s)': 0, 'Uzun (15s+)': 0}
                    for start, end in self.events:
                        event_duration = end - start
                        if event_duration <= 5:
                            duration_categories['KÄ±sa (0-5s)'] += 1
                        elif event_duration <= 15:
                            duration_categories['Orta (5-15s)'] += 1
                        else:
                            duration_categories['Uzun (15s+)'] += 1
                    
                    # Pasta grafiÄŸi verileri
                    chart_sheet.write('A20', 'Olay SÃ¼resi', title_format)
                    chart_sheet.write('B20', 'Olay SayÄ±sÄ±', title_format)
                    
                    row = 21
                    for category, count in duration_categories.items():
                        if count > 0:
                            chart_sheet.write(row, 0, category, data_format)
                            chart_sheet.write(row, 1, count, number_format)
                            row += 1
                    
                    # Pasta grafiÄŸi oluÅŸtur
                    if row > 21:
                        pie_chart = workbook.add_chart({'type': 'pie'})
                        pie_chart.add_series({
                            'name': 'Olay SÃ¼re DaÄŸÄ±lÄ±mÄ±',
                            'categories': ['Grafikler', 21, 0, row-1, 0],
                            'values': ['Grafikler', 21, 1, row-1, 1],
                            'data_labels': {'percentage': True}
                        })
                        pie_chart.set_title({'name': 'Olay SÃ¼re DaÄŸÄ±lÄ±mÄ±'})
                        chart_sheet.insert_chart('D20', pie_chart)
            
            # SÃ¼tun geniÅŸliklerini ayarla
            overview_sheet.set_column('A:A', 20)
            overview_sheet.set_column('B:B', 40)
            detections_sheet.set_column('A:A', 10)
            detections_sheet.set_column('B:B', 12)
            detections_sheet.set_column('C:C', 15)
            detections_sheet.set_column('D:D', 12)
            detections_sheet.set_column('E:E', 15)
            detections_sheet.set_column('F:F', 15)
            
            workbook.close()
            return True
            
        except ImportError:
            print("xlsxwriter kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil!")
            return False
        except Exception as e:
            print(f"Excel raporu oluÅŸturma hatasÄ±: {e}")
            return False
    
    def generate_charts(self, output_dir: str) -> bool:
        """GeliÅŸmiÅŸ grafikler ve Ã§izelgeler oluÅŸturur."""
        try:
            if not MATPLOTLIB_AVAILABLE:
                print("Grafik desteÄŸi yok! 'pip install matplotlib numpy' Ã§alÄ±ÅŸtÄ±rÄ±n")
                return False
            
            # Matplotlib ayarlarÄ±
            try:
                plt.style.use('seaborn-v0_8')
            except OSError:
                try:
                    plt.style.use('seaborn')
                except OSError:
                    plt.style.use('default')
            plt.rcParams['figure.facecolor'] = 'white'
            plt.rcParams['axes.facecolor'] = 'white'
            plt.rcParams['font.size'] = 12
            
            # Video bilgilerini gÃ¼venli ÅŸekilde al
            duration = self.video_info.get('duration', 0)
            fps = self.video_info.get('fps', 30)
            
            # 1. Zaman Ã‡izelgesi GrafiÄŸi (GeliÅŸmiÅŸ)
            if self.events:
                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
                
                # Ãœst panel: Olay Ã§ubuklarÄ±
                for i, (start, end) in enumerate(self.events):
                    ax1.barh(i, end - start, left=start, height=0.8, 
                            color='darkgreen', alpha=0.7, edgecolor='black')
                    ax1.text(start + (end - start) / 2, i, f'#{i+1}', 
                            ha='center', va='center', fontweight='bold', color='white')
                
                ax1.set_xlabel('Zaman (saniye)', fontsize=14, fontweight='bold')
                ax1.set_ylabel('Olay NumarasÄ±', fontsize=14, fontweight='bold')
                ax1.set_title('Tespit Edilen Olaylar - Zaman Cizelgesi', fontsize=16, fontweight='bold')
                ax1.grid(True, alpha=0.3)
                ax1.set_ylim(-0.5, len(self.events) - 0.5)
                
                # Alt panel: YoÄŸunluk grafiÄŸi
                if self.detected_objects:
                    time_density = {}
                    if isinstance(self.detected_objects, dict):
                        for frame_num, detections in self.detected_objects.items():
                            time_sec = frame_num / fps
                            time_density[int(time_sec)] = time_density.get(int(time_sec), 0) + len(detections)
                    else:
                        # List ise basit iÅŸlem
                        for i, _ in enumerate(self.detected_objects):
                            time_sec = int(i / fps)
                            time_density[time_sec] = time_density.get(time_sec, 0) + 1
                    
                    if time_density:
                        times = sorted(time_density.keys())
                        densities = [time_density[t] for t in times]
                        
                        ax2.plot(times, densities, 'b-', linewidth=2, alpha=0.8, label='Tespit YoÄŸunluÄŸu')
                        ax2.fill_between(times, densities, alpha=0.3, color='blue')
                        ax2.set_xlabel('Zaman (saniye)', fontsize=14, fontweight='bold')
                        ax2.set_ylabel('Tespit SayÄ±sÄ±', fontsize=14, fontweight='bold')
                        ax2.set_title('Tespit YoÄŸunluÄŸu DaÄŸÄ±lÄ±mÄ±', fontsize=16, fontweight='bold')
                        ax2.grid(True, alpha=0.3)
                        ax2.legend()
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'olay_zaman_analizi.png'), dpi=300, bbox_inches='tight')
                plt.close()
            
            # 2. Pasta GrafiÄŸi - Olay SÃ¼re Kategorileri
            if self.events:
                durations = [end - start for start, end in self.events]
                
                # Kategori tanÄ±mlarÄ±
                short_events = sum(1 for d in durations if d <= 5)
                medium_events = sum(1 for d in durations if 5 < d <= 15)
                long_events = sum(1 for d in durations if d > 15)
                
                if short_events + medium_events + long_events > 0:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
                    
                    # Pasta grafiÄŸi
                    labels = ['KÄ±sa (â‰¤5s)', 'Orta (5-15s)', 'Uzun (>15s)']
                    sizes = [short_events, medium_events, long_events]
                    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
                    explode = (0.05, 0.05, 0.05)
                    
                    # Sadece sÄ±fÄ±r olmayan deÄŸerleri gÃ¶ster
                    filtered_labels = []
                    filtered_sizes = []
                    filtered_colors = []
                    filtered_explode = []
                    
                    for i, size in enumerate(sizes):
                        if size > 0:
                            filtered_labels.append(labels[i])
                            filtered_sizes.append(size)
                            filtered_colors.append(colors[i])
                            filtered_explode.append(explode[i])
                    
                    if filtered_sizes:
                        _, _, _ = ax1.pie(filtered_sizes, labels=filtered_labels, 
                                         autopct='%1.1f%%', startangle=90,
                                         colors=filtered_colors, explode=filtered_explode,
                                         shadow=True, textprops={'fontsize': 12})
                        
                        ax1.set_title('Olay SÃ¼re Kategorileri', fontsize=16, fontweight='bold')
                    
                    # Histogram
                    ax2.hist(durations, bins=min(15, len(durations)), color='skyblue', 
                            alpha=0.7, edgecolor='black', linewidth=1)
                    ax2.axvline(np.mean(durations), color='red', linestyle='--', 
                               linewidth=2, label=f'Ortalama: {np.mean(durations):.1f}s')
                    ax2.axvline(np.median(durations), color='green', linestyle='--', 
                               linewidth=2, label=f'Medyan: {np.median(durations):.1f}s')
                    ax2.set_xlabel('Olay SÃ¼resi (saniye)', fontsize=14, fontweight='bold')
                    ax2.set_ylabel('Olay SayÄ±sÄ±', fontsize=14, fontweight='bold')
                    ax2.set_title('Olay SÃ¼resi DaÄŸÄ±lÄ±mÄ±', fontsize=16, fontweight='bold')
                    ax2.grid(True, alpha=0.3)
                    ax2.legend()
                    
                    plt.tight_layout()
                    plt.savefig(os.path.join(output_dir, 'olay_sure_analizi.png'), dpi=300, bbox_inches='tight')
                    plt.close()
            
            # 3. Radar GrafiÄŸi - Tespit PerformansÄ±
            if self.detected_objects and self.events and duration > 0:
                fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
                
                # Performans metrikleri
                total_frames = self.video_info.get('total_frames', 1)
                event_duration = sum([end - start for start, end in self.events])
                
                # GÃ¼venlik kontrolÃ¼ iÃ§in try-except
                try:
                    if isinstance(self.detected_objects, dict):
                        avg_confidence = np.mean([np.mean([d.get('confidence', 0) for d in dets]) 
                                                  for dets in self.detected_objects.values() if dets])
                    else:
                        avg_confidence = np.mean([d.get('confidence', 0) for d in self.detected_objects])
                except:
                    avg_confidence = 0
                
                metrics = {
                    'Tespit OranÄ±': min(100, (len(self.detected_objects) / total_frames) * 100),
                    'Olay KapsamÄ±': min(100, (event_duration / duration) * 100),
                    'Ortalama GÃ¼ven': avg_confidence * 100,
                    'Tespit YoÄŸunluÄŸu': min(100, (len(self.detected_objects) / len(self.events)) * 10) if len(self.events) > 0 else 0,
                    'Olay SÄ±klÄ±ÄŸÄ±': min(100, (len(self.events) / (duration / 60)) * 10),
                    'Sistem VerimliliÄŸi': min(100, (len(self.events) / max(1, len(self.detected_objects))) * 100)
                }
                
                # Radar grafik verileri
                angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
                values = list(metrics.values())
                
                # GrafiÄŸi kapat
                angles += angles[:1]
                values += values[:1]
                
                ax.plot(angles, values, 'o-', linewidth=2, color='#1E88E5')
                ax.fill(angles, values, alpha=0.25, color='#1E88E5')
                
                ax.set_xticks(angles[:-1])
                ax.set_xticklabels(metrics.keys(), fontsize=12)
                ax.set_ylim(0, 100)
                ax.set_title('Sistem Performans Radari', fontsize=16, fontweight='bold', pad=20)
                ax.grid(True)
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'performans_radar.png'), dpi=300, bbox_inches='tight')
                plt.close()
            
            # 4. IsÄ± HaritasÄ± - Tespit YoÄŸunluÄŸu
            if self.detected_objects and duration > 0:
                fig, ax = plt.subplots(figsize=(15, 8))
                
                # Video sÃ¼resini 100 bÃ¶lÃ¼me ayÄ±r
                segments = min(100, max(10, int(duration)))
                segment_duration = duration / segments
                segment_counts = np.zeros(segments)
                
                if isinstance(self.detected_objects, dict):
                    for frame_num, detections in self.detected_objects.items():
                        time_sec = frame_num / fps
                        segment_idx = min(int(time_sec / segment_duration), segments - 1)
                        segment_counts[segment_idx] += len(detections)
                else:
                    # List ise basit iÅŸlem
                    for i, _ in enumerate(self.detected_objects):
                        time_sec = i / fps
                        segment_idx = min(int(time_sec / segment_duration), segments - 1)
                        segment_counts[segment_idx] += 1
                
                # IsÄ± haritasÄ± matrisini oluÅŸtur
                heat_matrix = segment_counts.reshape(1, -1)
                
                im = ax.imshow(heat_matrix, cmap='YlOrRd', aspect='auto', interpolation='bilinear')
                
                # Eksen etiketleri
                ax.set_xlabel('Video Zaman Dilimleri', fontsize=14, fontweight='bold')
                ax.set_ylabel('YoÄŸunluk', fontsize=14, fontweight='bold')
                ax.set_title('Tespit YoÄŸunluÄŸu Isi Haritasi', fontsize=16, fontweight='bold')
                
                # Zaman etiketleri
                tick_count = min(10, segments)
                time_labels = [f'{int(i * segment_duration)}s' for i in range(0, segments, max(1, segments//tick_count))]
                ax.set_xticks(range(0, segments, max(1, segments//tick_count)))
                ax.set_xticklabels(time_labels)
                ax.set_yticks([])
                
                # Renk Ã§ubuÄŸu
                cbar = plt.colorbar(im, ax=ax, shrink=0.8)
                cbar.set_label('Tespit SayÄ±sÄ±', fontsize=12, fontweight='bold')
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'tespit_isi_haritasi.png'), dpi=300, bbox_inches='tight')
                plt.close()
            
            # 5. Basit Dashboard
            if self.events and self.detected_objects:
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
                fig.suptitle('M.SAVAS - VIDEO ANALIZ DASHBOARD', fontsize=20, fontweight='bold')
                
                # Dashboard bileÅŸenleri
                durations = [end - start for start, end in self.events]
                
                # 1. Olay sayÄ±sÄ±
                ax1.text(0.5, 0.5, f'{len(self.events)}', ha='center', va='center', 
                        fontsize=48, fontweight='bold', color='#2E8B57')
                ax1.text(0.5, 0.2, 'Toplam Olay', ha='center', va='center', 
                        fontsize=14, fontweight='bold')
                ax1.set_xlim(0, 1)
                ax1.set_ylim(0, 1)
                ax1.axis('off')
                
                # 2. Tespit sayÄ±sÄ±
                ax2.text(0.5, 0.5, f'{len(self.detected_objects)}', ha='center', va='center', 
                        fontsize=48, fontweight='bold', color='#FF6347')
                ax2.text(0.5, 0.2, 'Tespit Edildi', ha='center', va='center', 
                        fontsize=14, fontweight='bold')
                ax2.set_xlim(0, 1)
                ax2.set_ylim(0, 1)
                ax2.axis('off')
                
                # 3. Ortalama sÃ¼re
                ax3.text(0.5, 0.5, f'{np.mean(durations):.1f}s', ha='center', va='center', 
                        fontsize=48, fontweight='bold', color='#4169E1')
                ax3.text(0.5, 0.2, 'Ortalama SÃ¼re', ha='center', va='center', 
                        fontsize=14, fontweight='bold')
                ax3.set_xlim(0, 1)
                ax3.set_ylim(0, 1)
                ax3.axis('off')
                
                # 4. Kapsam yÃ¼zdesi
                ax4.text(0.5, 0.5, f'{(sum(durations) / duration) * 100:.1f}%', ha='center', va='center', 
                        fontsize=48, fontweight='bold', color='#8A2BE2')
                ax4.text(0.5, 0.2, 'Video KapsamÄ±', ha='center', va='center', 
                        fontsize=14, fontweight='bold')
                ax4.set_xlim(0, 1)
                ax4.set_ylim(0, 1)
                ax4.axis('off')
                # 6. IsÄ± haritasÄ± (her segmentteki tespit yoÄŸunluÄŸu)
                # (Varsa, bir alt subplot olarak ekle)
                # EÄŸer segment_counts ve segments tanÄ±mlÄ±ysa, heatmap ekle
                # (Bu kodun Ã¼st kÄ±smÄ±nda segment_counts ve segments tanÄ±mlÄ± olmalÄ±)
                # Bu Ã¶rnekte, heatmap ayrÄ± bir ÅŸekilde kaydedildiÄŸi iÃ§in burada tekrar eklemeye gerek yok.
                pass
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'dashboard.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            return True
            
        except Exception as e:
            print(f"Grafik oluÅŸturma hatasÄ±: {e}")
            return False
    
    def generate_word_report(self, output_path: str, detection_images: list = None) -> bool:
        """DetaylÄ± Word raporu oluÅŸturur."""
        try:
            if not DOCX_AVAILABLE:
                print("Word desteÄŸi yok! 'pip install python-docx' Ã§alÄ±ÅŸtÄ±rÄ±n")
                return False
            
            doc = Document()
            
            # GÃ¶rsel listesi kontrolÃ¼
            if detection_images is None:
                detection_images = []  # BoÅŸ liste olarak baÅŸlat
            
            # Stil ayarlarÄ±
            styles = doc.styles
            
            # BaÅŸlÄ±k stili
            try:
                title_style = styles.add_style('CustomTitle', WD_STYLE_TYPE.PARAGRAPH)
                title_font = title_style.font
                title_font.name = 'Calibri'
                title_font.size = Pt(24)
                title_font.bold = True
                title_font.color.rgb = RGBColor(26, 188, 156)  # Turkuaz
                title_style.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER
            except:
                # Stil zaten varsa devam et
                pass
            
            # Alt baÅŸlÄ±k stili
            try:
                subtitle_style = styles.add_style('CustomSubtitle', WD_STYLE_TYPE.PARAGRAPH)
                subtitle_font = subtitle_style.font
                subtitle_font.name = 'Calibri'
                subtitle_font.size = Pt(16)
                subtitle_font.bold = True
                subtitle_font.color.rgb = RGBColor(52, 152, 219)  # Mavi
            except:
                # Stil zaten varsa devam et
                pass
            
            # ğŸ“‹ KAPAK SAYFASI
            try:
                title = doc.add_paragraph('M.SAVAS', style='CustomTitle')
                title.add_run('\nMotion Surveillance and Video Analysis System').font.size = Pt(14)
            except:
                title = doc.add_paragraph('M.SAVAS')
                title.alignment = WD_ALIGN_PARAGRAPH.CENTER
                title.runs[0].font.size = Pt(24)
                title.runs[0].font.bold = True
            
            doc.add_paragraph()
            try:
                subtitle = doc.add_paragraph('DETAYLI VIDEO ANALIZ RAPORU', style='CustomSubtitle')
                subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
            except:
                subtitle = doc.add_paragraph('DETAYLI VIDEO ANALIZ RAPORU')
                subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
                subtitle.runs[0].font.size = Pt(16)
                subtitle.runs[0].font.bold = True
            
            doc.add_paragraph()
            
            # Kapak bilgileri tablosu
            info_table = doc.add_table(rows=7, cols=2)
            info_table.style = 'Table Grid'
            
            info_data = [
                ('ğŸ“ Video DosyasÄ±:', os.path.basename(self.video_path)),
                ('ğŸ“… Analiz Tarihi:', self.analysis_date.strftime('%d.%m.%Y %H:%M:%S')),
                ('âš™ï¸ Hassasiyet Seviyesi:', self.sensitivity),
                ('â±ï¸ Video SÃ¼resi:', self.format_duration(self.video_info.get('duration', 0))),
                ('ğŸ¯ Tespit SayÄ±sÄ±:', f"{len(self.detected_objects)} kare"),
                ('ğŸš¨ Olay SayÄ±sÄ±:', f"{len(self.events)} olay"),
                ('ğŸ“· GÃ¶rsel SayÄ±sÄ±:', f"{len(detection_images) if detection_images else 0} gÃ¶rÃ¼ntÃ¼")
            ]
            
            for i, (label, value) in enumerate(info_data):
                info_table.cell(i, 0).text = label
                info_table.cell(i, 1).text = str(value)
                info_table.cell(i, 0).paragraphs[0].runs[0].font.bold = True
            
            doc.add_page_break()
            
            # ğŸ“Š Ä°STATÄ°STÄ°KLER BÃ–LÃœMÃœ
            try:
                doc.add_paragraph('ANALIZ ISTATISTIKLERI', style='CustomSubtitle')
            except:
                stats_title = doc.add_paragraph('ANALIZ ISTATISTIKLERI')
                stats_title.runs[0].font.size = Pt(16)
                stats_title.runs[0].font.bold = True
            
            if self.events:
                total_event_duration = sum([end - start for start, end in self.events])
                avg_event_duration = total_event_duration / len(self.events)
                coverage_percentage = (total_event_duration / self.video_info.get('duration', 1)) * 100
                
                stats_table = doc.add_table(rows=6, cols=2)
                stats_table.style = 'Light Shading Accent 1'
                
                stats_data = [
                    ('ğŸ“ˆ Toplam Olay SÃ¼resi:', self.format_duration(total_event_duration)),
                    ('â±ï¸ Ortalama Olay SÃ¼resi:', self.format_duration(avg_event_duration)),
                    ('ğŸ“Š Video KapsamÄ±:', f"{coverage_percentage:.1f}%"),
                    ('ğŸ¯ Tespit YoÄŸunluÄŸu:', f"{len(self.detected_objects) / (self.video_info.get('total_frames', 1) / 100):.1f} tespit/100 kare"),
                    ('âš¡ Analiz VerimliliÄŸi:', f"{len(self.events) / (self.video_info.get('duration', 1) / 60):.1f} olay/dakika"),
                    ('ğŸ” Saniye BaÅŸÄ±na Tespit:', f"{len(self.detected_objects) / self.video_info.get('duration', 1):.2f} tespit/saniye")
                ]
                
                for i, (label, value) in enumerate(stats_data):
                    stats_table.cell(i, 0).text = label
                    stats_table.cell(i, 1).text = str(value)
                    stats_table.cell(i, 0).paragraphs[0].runs[0].font.bold = True
            
            doc.add_paragraph()
            
            # ğŸ“· DETAYLI GÃ–RSEL TESPÄ°TLER BÃ–LÃœMÃœ
            if detection_images:
                doc.add_paragraph('ğŸ“· DETAYLI TESPÄ°T GÃ–RÃœNTÃœLERÄ°', style='CustomSubtitle')
                doc.add_paragraph('AÅŸaÄŸÄ±da videoda tespit edilen hareketlerin saniye bazÄ±nda detaylÄ± gÃ¶rÃ¼ntÃ¼leri yer almaktadÄ±r:')
                
                # GÃ¶rÃ¼ntÃ¼leri saniye bazÄ±nda grupla
                second_groups = {}
                for img_info in detection_images:
                    second = img_info.get('second', int(img_info['time']))
                    if second not in second_groups:
                        second_groups[second] = []
                    second_groups[second].append(img_info)
                
                for second in sorted(second_groups.keys()):
                    group_images = second_groups[second]
                    
                    # Saniye baÅŸlÄ±ÄŸÄ±
                    doc.add_paragraph()
                    second_title = doc.add_paragraph()
                    second_title.add_run(f"â° {second}. Saniye - ").font.bold = True
                    second_title.add_run(f"Zaman: {self.format_duration(second)} - ")
                    
                    total_detections = sum(img['detections'] for img in group_images)
                    second_title.add_run(f"Toplam {total_detections} tespit")
                    
                    for i, img_info in enumerate(group_images):
                        try:
                            # Resim baÅŸlÄ±ÄŸÄ±
                            img_title = doc.add_paragraph()
                            img_title.add_run(f"ğŸ¯ Kare {img_info['frame']}: ").font.bold = True
                            img_title.add_run(f"Zaman: {self.format_duration(img_info['time'])} - ")
                            img_title.add_run(f"{img_info['detections']} kiÅŸi tespit edildi")
                            
                            # Orijinal ve tespit edilmiÅŸ gÃ¶rÃ¼ntÃ¼ karÅŸÄ±laÅŸtÄ±rmasÄ±
                            if 'original_path' in img_info and os.path.exists(img_info['original_path']):
                                doc.add_paragraph("ğŸ“¸ Orijinal GÃ¶rÃ¼ntÃ¼:")
                                doc.add_picture(img_info['original_path'], width=Inches(6.0))
                                doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER
                            
                            # Tespit edilmiÅŸ gÃ¶rÃ¼ntÃ¼
                            if os.path.exists(img_info['path']):
                                doc.add_paragraph("ğŸ¯ Tespit EdilmiÅŸ GÃ¶rÃ¼ntÃ¼:")
                                doc.add_picture(img_info['path'], width=Inches(6.0))
                                doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER
                            
                            # AÃ§Ä±klama
                            description = doc.add_paragraph()
                            description.add_run("ğŸ“‹ AÃ§Ä±klama: ").font.bold = True
                            if img_info['detections'] == 1:
                                description.add_run("Sahnede tek kiÅŸi tespit edildi.")
                            elif img_info['detections'] > 1:
                                description.add_run(f"Sahnede {img_info['detections']} kiÅŸi tespit edildi.")
                            else:
                                description.add_run("Hareket tespit edildi ancak kiÅŸi tanÄ±mlanamadÄ±.")
                            
                            doc.add_paragraph("â”€" * 50)
                            
                        except Exception as e:
                            print(f"Resim ekleme hatasÄ±: {e}")
                    
                    # Sayfa sonu (her 3 saniyede)
                    if (second + 1) % 3 == 0:
                        doc.add_page_break()
                        doc.add_paragraph()  # BoÅŸluk ekle
            
            doc.add_page_break()
            
            # ğŸ“‹ DETAYLI OLAY LÄ°STESÄ°
            try:
                doc.add_paragraph('DETAYLI OLAY LISTESI', style='CustomSubtitle')
            except:
                events_title = doc.add_paragraph('DETAYLI OLAY LISTESI')
                events_title.runs[0].font.size = Pt(16)
                events_title.runs[0].font.bold = True
            
            if self.events:
                events_table = doc.add_table(rows=len(self.events) + 1, cols=6)
                events_table.style = 'Table Grid'
                
                # BaÅŸlÄ±k satÄ±rÄ±
                header_cells = events_table.rows[0].cells
                headers = ['Olay No', 'BaÅŸlangÄ±Ã§', 'BitiÅŸ', 'SÃ¼re', 'Tespit SayÄ±sÄ±', 'AÃ§Ä±klama']
                for i, header in enumerate(headers):
                    header_cells[i].text = header
                    header_cells[i].paragraphs[0].runs[0].font.bold = True
                
                # Olay verileri
                for i, (start, end) in enumerate(self.events):
                    row_cells = events_table.rows[i + 1].cells
                    duration = end - start
                    
                    # Bu olay sÃ¼resinde kaÃ§ tespit var
                    detection_count = 0
                    for frame_num, detections in self.detected_objects.items():
                        frame_time = frame_num / self.video_info.get('fps', 30)
                        if start <= frame_time <= end:
                            detection_count += len(detections)
                    
                    row_cells[0].text = str(i + 1)
                    row_cells[1].text = self.format_duration(start)
                    row_cells[2].text = self.format_duration(end)
                    row_cells[3].text = f"{duration:.1f}s"
                    row_cells[4].text = str(detection_count)
                    
                    # AÃ§Ä±klama
                    if duration < 2:
                        description = "KÄ±sa sÃ¼reli hareket"
                    elif duration < 10:
                        description = "Orta sÃ¼reli aktivite"
                    else:
                        description = "Uzun sÃ¼reli aktivite"
                    
                    if detection_count > 10:
                        description += " (YoÄŸun tespit)"
                    elif detection_count > 5:
                        description += " (Orta tespit)"
                    else:
                        description += " (Az tespit)"
                    
                    row_cells[5].text = description
            
            # ï¿½ ZAMAN BAZLI ANALÄ°Z
            doc.add_page_break()
            doc.add_paragraph('ğŸ“Š ZAMAN BAZLI ANALÄ°Z', style='CustomSubtitle')
            
            if self.detected_objects:
                # Saniye bazÄ±nda tespit sayÄ±larÄ±
                second_detections = {}
                for frame_num, detections in self.detected_objects.items():
                    second = int(frame_num / self.video_info.get('fps', 30))
                    if second not in second_detections:
                        second_detections[second] = 0
                    second_detections[second] += len(detections)
                
                # En yoÄŸun 10 saniye
                top_seconds = sorted(second_detections.items(), key=lambda x: x[1], reverse=True)[:10]
                
                doc.add_paragraph("ğŸ”¥ En YoÄŸun Tespit Edilen Anlar:")
                for i, (second, count) in enumerate(top_seconds, 1):
                    para = doc.add_paragraph()
                    para.add_run(f"{i}. ").font.bold = True
                    para.add_run(f"Zaman: {self.format_duration(second)} - {count} tespit")
            
            # ï¿½ğŸ” SONUÃ‡ VE DEÄERLENDÄ°RME
            doc.add_page_break()
            doc.add_paragraph('ğŸ” SONUÃ‡ VE DEÄERLENDÄ°RME', style='CustomSubtitle')
            
            if self.events:
                conclusion_text = f"""
Bu video analizi {self.sensitivity} hassasiyet seviyesinde gerÃ§ekleÅŸtirilmiÅŸtir. 

ğŸ“Š Analiz SonuÃ§larÄ±:
â€¢ Video sÃ¼resinin %{(sum([end - start for start, end in self.events]) / self.video_info.get('duration', 1) * 100):.1f}'inde hareket tespit edilmiÅŸtir
â€¢ Toplam {len(self.events)} ayrÄ± olay kaydedilmiÅŸtir
â€¢ {len(detection_images) if detection_images else 0} adet detaylÄ± gÃ¶rÃ¼ntÃ¼ oluÅŸturulmuÅŸtur
â€¢ En uzun olay sÃ¼resi: {max([end - start for start, end in self.events]):.1f} saniye
â€¢ En kÄ±sa olay sÃ¼resi: {min([end - start for start, end in self.events]):.1f} saniye

ğŸ¯ Ã–neriler:
â€¢ GÃ¼venlik aÃ§Ä±sÄ±ndan kritik zaman dilimlerine odaklanÄ±lmasÄ± Ã¶nerilir
â€¢ Uzun sÃ¼reli aktiviteler detaylÄ± incelenmelidir
â€¢ YoÄŸun tespit edilen anlar Ã¶zel dikkat gerektirir
â€¢ Sistem {self.sensitivity} seviyesinde baÅŸarÄ±lÄ± tespit performansÄ± gÃ¶stermiÅŸtir

ğŸ” Detay Analizi:
â€¢ Ortalama saniye baÅŸÄ±na tespit: {len(self.detected_objects) / self.video_info.get('duration', 1):.2f}
â€¢ Toplam tespit sayÄ±sÄ±: {sum(len(detections) for detections in self.detected_objects.values())}
â€¢ Rapor kalitesi: YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte {len(detection_images) if detection_images else 0} gÃ¶rÃ¼ntÃ¼
                """
            else:
                conclusion_text = """
Bu video analizinde herhangi bir hareket tespit edilmemiÅŸtir.

ğŸ” OlasÄ± Nedenler:
â€¢ Video statik bir sahne iÃ§eriyor olabilir
â€¢ Hassasiyet seviyesi Ã§ok yÃ¼ksek ayarlanmÄ±ÅŸ olabilir
â€¢ Video kalitesi analiz iÃ§in uygun olmayabilir

ğŸ’¡ Ã–neriler:
â€¢ Hassasiyet seviyesini dÃ¼ÅŸÃ¼rerek tekrar analiz yapabilirsiniz
â€¢ Video kalitesini ve iÃ§eriÄŸini kontrol ediniz
â€¢ FarklÄ± zaman dilimlerini test edebilirsiniz
            """
            
            doc.add_paragraph(conclusion_text.strip())
            
            # Alt bilgi
            doc.add_paragraph()
            footer = doc.add_paragraph()
            footer.add_run('Bu detaylÄ± rapor M.SAVAÅ (Motion Surveillance and Video Analysis System) tarafÄ±ndan otomatik olarak oluÅŸturulmuÅŸtur.').font.italic = True
            footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            doc.save(output_path)
            return True
            
        except Exception as e:
            print(f"Word raporu oluÅŸturma hatasÄ±: {e}")
            return False

    # =============================================================================
    # --- YENÄ° Ã–ZELLÄ°K: CANLI KAMERA FONKSÄ°YONLARI ---
    # =============================================================================
    
    def start_live_camera(self):
        """CanlÄ± kamera akÄ±ÅŸÄ±nÄ± baÅŸlatÄ±r"""
        try:
            # Ã–nce webcam'i dene
            self.camera_capture = cv2.VideoCapture(0)
            if not self.camera_capture.isOpened():
                # Ä°kinci kamerayÄ± dene
                self.camera_capture = cv2.VideoCapture(1)
                if not self.camera_capture.isOpened():
                    self.show_error_message("Kamera bulunamadÄ±! LÃ¼tfen webcam'inizin baÄŸlÄ± olduÄŸundan emin olun.")
                    return
            
            # Kamera ayarlarÄ±
            self.camera_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera_capture.set(cv2.CAP_PROP_FPS, 30)
            
            self.is_live_camera = True
            self.live_camera_timer.start(33)  # ~30 FPS
            
            # UI gÃ¼ncelleme
            self.btn_start_camera.setEnabled(False)
            self.btn_stop_camera.setEnabled(True)
            self.video_info_label.setText("ğŸ“¹ CanlÄ± Kamera Aktif\nğŸ¯ GerÃ§ek zamanlÄ± analiz iÃ§in 'Analiz Et' butonuna basÄ±n")
            
            self.log_message("ğŸ“¹ CanlÄ± kamera baÅŸlatÄ±ldÄ±! GerÃ§ek zamanlÄ± gÃ¶rÃ¼ntÃ¼ akÄ±ÅŸÄ± baÅŸladÄ±.", "success")
            self.log_message(f"  â€¢ Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: 640x480", "info")
            self.log_message(f"  â€¢ FPS: 30", "info")
            self.log_message(f"  â€¢ GerÃ§ek zamanlÄ± analiz: {self.current_sensitivity}", "info")
            
        except Exception as e:
            self.show_error_message(f"Kamera baÅŸlatma hatasÄ±: {e}")
            self.log_message(f"âŒ Kamera hatasÄ±: {e}", "error")

    def stop_live_camera(self):
        """CanlÄ± kamera akÄ±ÅŸÄ±nÄ± durdurur"""
        try:
            self.is_live_camera = False
            self.live_camera_timer.stop()
            
            if self.camera_capture:
                self.camera_capture.release()
                self.camera_capture = None
            
            # UI gÃ¼ncelleme
            self.btn_start_camera.setEnabled(True)
            self.btn_stop_camera.setEnabled(False)
            self.video_info_label.setText("ğŸ“¹ Video seÃ§ilmedi")
            self.video_display_label.setText("LÃ¼tfen bir video dosyasÄ± yÃ¼kleyin veya canlÄ± kamerayÄ± baÅŸlatÄ±n.")
            
            self.log_message("ğŸ“¹ CanlÄ± kamera durduruldu.", "info")
            
        except Exception as e:
            self.log_message(f"Kamera durdurma hatasÄ±: {e}", "warning")

    def update_live_camera_frame(self):
        """CanlÄ± kamera frame'lerini gÃ¼nceller"""
        if not self.camera_capture or not self.is_live_camera:
            return
            
        try:
            ret, frame = self.camera_capture.read()
            if ret and frame is not None:
                # Frame'i iÅŸle ve gÃ¶ster
                self.display_cv_frame(frame, 0)
                
                # EÄŸer canlÄ± analiz aktifse tespit yap
                if self.live_detection_enabled:
                    self.detect_live_objects(frame)
                    
            else:
                self.log_message("Kamera frame'i okunamadÄ±", "warning")
                self.stop_live_camera()
                
        except Exception as e:
            self.log_message(f"CanlÄ± kamera frame hatasÄ±: {e}", "error")
            self.stop_live_camera()

    def detect_live_objects(self, frame):
        """CanlÄ± kamera iÃ§in nesne tespiti yapar"""
        try:
            # Basit hareket tespiti (daha performanslÄ±)
            if not hasattr(self, 'background_subtractor'):
                self.background_subtractor = cv2.createBackgroundSubtractorMOG2(
                    detectShadows=True, varThreshold=50)
            
            # Hareket maskesi oluÅŸtur
            motion_mask = self.background_subtractor.apply(frame)
            
            # GÃ¼rÃ¼ltÃ¼yÃ¼ azalt
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel)
            
            # KonturlarÄ± bul
            contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detection_count = 0
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 500:  # Minimum alan
                    x, y, w, h = cv2.boundingRect(contour)
                    # Tespit kutusunu Ã§iz
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    cv2.putText(frame, "Hareket", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                    detection_count += 1
            
            # Status gÃ¼ncelle
            if detection_count > 0:
                self.status_label.setText(f"ğŸ”´ CANLI: {detection_count} hareket tespit edildi")
            else:
                self.status_label.setText("ğŸŸ¢ CANLI: Ä°zleniyor...")
                
        except Exception as e:
            self.log_message(f"CanlÄ± tespit hatasÄ±: {e}", "warning")
    
    def toggle_live_detection(self):
        """CanlÄ± tespit modunu aÃ§ar/kapatÄ±r"""
        if self.is_live_camera:
            self.live_detection_enabled = not self.live_detection_enabled
            status = "AÃ‡IK" if self.live_detection_enabled else "KAPALI"
            self.log_message(f"ğŸ¯ CanlÄ± tespit modu: {status}", "info")
        else:
            self.log_message("âš ï¸ Ã–nce canlÄ± kamerayÄ± baÅŸlatÄ±n!", "warning")

    # =============================================================================
    # --- YENÄ° Ã–ZELLÄ°K: Ã‡OKLU NESNE TESPÄ°TÄ° FONKSÄ°YONLARI ---
    # =============================================================================
    
    def update_active_classes(self):
        """Aktif tespit sÄ±nÄ±flarÄ±nÄ± gÃ¼nceller"""
        global ACTIVE_CLASSES
        ACTIVE_CLASSES = []
        
        for class_name, checkbox in self.object_checkboxes.items():
            if checkbox.isChecked():
                if class_name in TARGET_CLASSES:
                    ACTIVE_CLASSES.append(TARGET_CLASSES[class_name])
        
        # HiÃ§bir ÅŸey seÃ§ilmemiÅŸse person'u varsayÄ±lan yap
        if not ACTIVE_CLASSES:
            ACTIVE_CLASSES = [0]  # person
            self.object_checkboxes['person'].setChecked(True)
        
        # Log mesajÄ±
        selected_names = [name for name, checkbox in self.object_checkboxes.items() if checkbox.isChecked()]
        self.log_message(f"ğŸ¯ Tespit edilecek nesneler gÃ¼ncellendi: {', '.join(selected_names)}", "info")
    
    def show_advanced_object_selection(self):
        """GeliÅŸmiÅŸ nesne seÃ§imi dialogu gÃ¶sterir"""
        try:
            # Import'lar zaten Ã¼stte yapÄ±ldÄ±
            
            dialog = QDialog(self)
            dialog.setWindowTitle("ğŸ¯ GeliÅŸmiÅŸ Nesne SeÃ§imi")
            dialog.setFixedSize(600, 400)
            dialog.setStyleSheet(self.get_stylesheet())
            
            layout = QVBoxLayout(dialog)
            
            # AÃ§Ä±klama
            info_label = QLabel("ğŸ¯ Tespit edilecek nesneleri seÃ§in (YOLO sÄ±nÄ±flarÄ±):")
            info_label.setStyleSheet("font-weight: bold; color: white; margin: 10px;")
            layout.addWidget(info_label)
            
            # TÃ¼m nesne kategorileri
            scroll_area = QScrollArea()
            scroll_widget = QWidget()
            grid_layout = QGridLayout(scroll_widget)
            
            self.advanced_checkboxes = {}
            row, col = 0, 0
            
            for class_name, class_id in TARGET_CLASSES.items():
                checkbox = QCheckBox(f"{class_name} (ID: {class_id})")
                checkbox.setChecked(class_id in ACTIVE_CLASSES)
                checkbox.setStyleSheet("color: white; margin: 5px;")
                
                self.advanced_checkboxes[class_name] = checkbox
                grid_layout.addWidget(checkbox, row, col)
                
                col += 1
                if col >= 3:  # 3 sÃ¼tun
                    col = 0
                    row += 1
            
            scroll_area.setWidget(scroll_widget)
            scroll_area.setStyleSheet("background-color: #2c3e50; border: 1px solid #34495e;")
            layout.addWidget(scroll_area)
            
            # Butonlar
            button_layout = QHBoxLayout()
            
            select_all_btn = QPushButton("âœ… TÃ¼mÃ¼nÃ¼ SeÃ§")
            select_none_btn = QPushButton("âŒ HiÃ§birini SeÃ§me")
            apply_btn = QPushButton("ğŸ’¾ Uygula")
            cancel_btn = QPushButton("ğŸš« Ä°ptal")
            
            for btn in [select_all_btn, select_none_btn, apply_btn, cancel_btn]:
                btn.setFixedHeight(35)
                btn.setStyleSheet("""
                    QPushButton {
                        background-color: #3498db;
                        color: white;
                        border: none;
                        border-radius: 5px;
                        font-weight: bold;
                        padding: 5px;
                    }
                    QPushButton:hover {
                        background-color: #2980b9;
                    }
                """)
            
            select_all_btn.clicked.connect(lambda: self.set_all_checkboxes(True))
            select_none_btn.clicked.connect(lambda: self.set_all_checkboxes(False))
            apply_btn.clicked.connect(lambda: self.apply_advanced_selection(dialog))
            cancel_btn.clicked.connect(dialog.reject)
            
            button_layout.addWidget(select_all_btn)
            button_layout.addWidget(select_none_btn)
            button_layout.addWidget(apply_btn)
            button_layout.addWidget(cancel_btn)
            
            layout.addLayout(button_layout)
            
            dialog.exec_()
            
        except Exception as e:
            self.log_message(f"GeliÅŸmiÅŸ nesne seÃ§imi hatasÄ±: {e}", "error")
    
    def set_all_checkboxes(self, checked):
        """TÃ¼m geliÅŸmiÅŸ checkboxlarÄ± seÃ§er/temizler"""
        for checkbox in self.advanced_checkboxes.values():
            checkbox.setChecked(checked)
    
    def apply_advanced_selection(self, dialog):
        """GeliÅŸmiÅŸ seÃ§imi uygular"""
        global ACTIVE_CLASSES
        ACTIVE_CLASSES = []
        
        # Ana checkboxlarÄ± temizle
        for checkbox in self.object_checkboxes.values():
            checkbox.setChecked(False)
        
        # GeliÅŸmiÅŸ seÃ§imi uygula
        for class_name, checkbox in self.advanced_checkboxes.items():
            if checkbox.isChecked():
                if class_name in TARGET_CLASSES:
                    ACTIVE_CLASSES.append(TARGET_CLASSES[class_name])
                    
                    # Ana paneldeki ilgili checkbox'Ä± da iÅŸaretle
                    if class_name in self.object_checkboxes:
                        self.object_checkboxes[class_name].setChecked(True)
        
        # HiÃ§bir ÅŸey seÃ§ilmemiÅŸse person'u varsayÄ±lan yap
        if not ACTIVE_CLASSES:
            ACTIVE_CLASSES = [0]
            self.object_checkboxes['person'].setChecked(True)
        
        # Log mesajÄ±
        selected_count = len(ACTIVE_CLASSES)
        self.log_message(f"ğŸ¯ GeliÅŸmiÅŸ nesne seÃ§imi uygulandÄ±: {selected_count} farklÄ± nesne tÃ¼rÃ¼ aktif", "success")
        
        dialog.accept()
    
# =============================================================================
# --- UYGULAMA GÄ°RÄ°Å NOKTASI ---
# =============================================================================

def main():
    """UygulamayÄ± baÅŸlatÄ±r."""
    try:
        # Temel kÃ¼tÃ¼phaneleri kontrol et
        print("M.SAVAÅ Video Analiz Sistemi baÅŸlatÄ±lÄ±yor...")
        
        # BaÄŸÄ±mlÄ±lÄ±k kontrolÃ¼
        if not check_dependencies():
            print("UYARI: BazÄ± baÄŸÄ±mlÄ±lÄ±klar eksik. Temel fonksiyonlarla devam ediliyor.")
        
        # PyQt5 uygulamasÄ± baÅŸlat
        app = QApplication(sys.argv)
        app.setApplicationName("M.SAVAÅ Video Analiz Sistemi")
        app.setApplicationVersion("1.1.0")
        
        # Meta type kaydet
        try:
            from PyQt5.QtCore import qRegisterMetaType
            qRegisterMetaType(QTextCursor)
        except (ImportError, NameError, AttributeError):
            pass # Eski versiyonlarda sorun olabilir

        # Ana pencereyi oluÅŸtur ve gÃ¶ster
        print("Ana pencere oluÅŸturuluyor...")
        window = MainWindow()
        window.show()
        
        print("Uygulama baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
        
        # Uygulama dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlat
        sys.exit(app.exec_())

    except ImportError as e:
        print(f"Kritik baÄŸÄ±mlÄ±lÄ±k hatasÄ±: {e}")
        try:
            app = QApplication(sys.argv)
            QMessageBox.critical(None, "Kritik BaÄŸÄ±mlÄ±lÄ±k HatasÄ±", 
                               f"Gerekli kÃ¼tÃ¼phaneler bulunamadÄ±:\n\n{e}\n\n"
                               "LÃ¼tfen gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin ve tekrar deneyin.")
            sys.exit(1)
        except:
            print("GUI hata mesajÄ± gÃ¶sterilemedi.")
            sys.exit(1)
            
    except Exception as e:
        import traceback
        error_details = f"Beklenmedik bir hata oluÅŸtu:\n\n{e}\n\n{traceback.format_exc()}"
        print(error_details)
        try:
            app = QApplication(sys.argv)
            QMessageBox.critical(None, "Beklenmedik Hata", error_details)
        except: 
            pass
        sys.exit(1)

if __name__ == "__main__":
    main()
